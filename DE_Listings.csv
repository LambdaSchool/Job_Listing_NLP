title,company,location,meta,description,url
Data Engineer - SQL,"PRIMUS Global Services, Inc","Menlo Park, CA",,"We have an immediate opportunity for a Data Engineer at Menlo Park with one of our largest clients.

The potential candidate should have experience in advance SQL, Python, ETL, Data Modelling, Tableau or any BI tool. Should be well versed in creating data pipelines using Python. Should be very strong in writing advance SQL queries. Should be in BI Engineer. Nice to have Python experience.

For immediate consideration, please contact:
Manish Gupta
PRIMUS Global Services
(972) 753-6500 x411
Email: jobs@primusglobal.com",http://www.indeed.com/rc/clk?jk=1fa1e1321bdd7ea9&fccid=a1c580f8e420853d&vjs=3
"Data Engineer, Data Sciences",Johnson & Johnson Family of Companies,"Raritan, NJ",,"Janssen Pharmaceuticals, Inc., a member of Johnson & Johnson's Family of Companies, is recruiting for Data Engineer to support our Commercial Insights & Innovation team within Janssen Data Sciences and Data Management.
At the Janssen Pharmaceutical Companies of Johnson & Johnson, what matters most is helping people live full and healthy lives. We focus on treating, curing and preventing some of the most devastating and complex diseases of our time. And we pursue the most promising science, wherever it might be found.
The position will be responsible for but limited to:

Design, develop and implement the data infrastructure with scalable service to enable data science work and related research functionality.
Deliver flexible & scalable solutions to collect, Ingest and transform data into a data warehouse.
Provide leadership and guidance on design and management of data for data applications, formulate best practices and organize processes for data management, governance and evolution. Build processes and tools to maintain high data availability, quality and maintainability.
Drive the design, build and implementation of new data models in a production environment.
Lead the design and development of the data and service architecture including data lake, data warehouse, ETL processes, and APIs.
Define and implement processes required to achieve high system reliability.
Evaluate interfaces between various solutions, develop technical specifications and develop programs and resolve problems.
Engage with Data Platform customers/partners to understand their needs and provide suggestions/guidance on what data platform techniques are appropriate to solve their problems with pros/cons articulated clearly.
Perform database administration work including access control, sizing, performance optimization & monitoring.
Work cross-functionally with stakeholders to gather requirements.
Work with documentation professionals in developing user manuals.
Ability to understand requirements from business & technology teams and translate them into functional specifications.
Troubleshooting and resolve system issues and escalate to service providers as needed.


Qualifications

Bachelor's degree in Computer Science, Information Systems, etc.
A minimum of 7 years of experience in the implementation, design, and support in Data warehouses
A minimum of 5 years of administration/development experience with AWS Redshift
Experience in migrating database system from on-premises to AWS Cloud platform
Expertise in relational and columnar databases/Data warehouse including AWS Redshift, AWS RDS such as PostgreSQL, MS SQL Server, MySQL, Oracle.
Extensive hands on experience in data warehousing design, tuning and ETL/ELT process development.
Experience in ETL tools such as Talend Big Data Studio, MSBI SSIS package
Demonstrated experience in Cloud Computing, AWS services such as RedShift Cluster, AWS CLI, S3, EMR, RDS, DMS, EC2, Redshift Spectrum, AWS Glue, VPC, AWS SDK etc. and proven knowledge of AWS cloud architecture
Coding proficiency in scripting languages such as Python, PowerShell.
Ability to write complex SQL query using AWS Redshift SQL/ANSI-SQL /PostgreSQL/Amazon Aurora to meet business requirement
Good oral and written communication and ability to write organized technical documentation, i.e. system process flows, user operation manuals, etc.
Ability to automate end-to-end workflow for data pipeline .


Primary Location
United States-New Jersey-Titusville-
Other Locations
North America-United States-New Jersey-Raritan, North America-United States-Pennsylvania-Spring House
Organization
Johnson & Johnson Services Inc. (6090)
Job Function
R&D
Requisition ID
1968200320",http://www.indeed.com/rc/clk?jk=685edbcbc8f04f58&fccid=0bed8e17bc113980&vjs=3
Data Engineer,"ePromptus,Inc","Richmond, VA",,"Data Engineer
Location: Richmond, VA (remote until further notice)
Duration: 6 Months contract- likely to extend
Required Skills:
Making updates. Mostly maintenance and enhancement work on existing systemsLooking for production support and data engineersManaging all data pipelines. Mainly maintenance, some enhancements. Moving data through into data lake.Abinitio footprint. Trying to modernize. Rewrite abinitio jobs.Spark, Scala, AWS, Lambda",http://www.indeed.com/rc/clk?jk=63f2e99dcee2fc9d&fccid=0c8a6dcf2e060d2c&vjs=3
Big Data Engineer- Intuit Again Returnship,Intuit,"Mountain View, CA 94041",,"“Intuit Again” is a returnship program at Intuit for professionals returning to the workforce after taking time off from their careers for caregiving. During this returnship you’ll receive 16 weeks of paid employment doing work you love for one of the world’s most innovative companies. You’ll have the chance to update your skills, add new work experience to your resume, and make professional connections.

After completing the 16 weeks of the returnship program, there will be the potential opportunity for a full time offer. The program is open to anyone who has at least five (5) years of professional experience and have been out of the paid workforce for at least eighteen months (18) to focus on caregiving. If you meet these criteria and your skills match our needs, we welcome you to apply.

In this role, you can help engineer solutions that empower millions of businesses/customers worldwide. Your role is to work in small agile scrum teams to deliver awesome products that not only delight customers, but that are highly scalable and reliable. Using your detailed understanding of technologies and applying your intellectual curiosity you will help design, develop, and improve the features that help our customers run their businesses easily every day.",http://www.indeed.com/rc/clk?jk=a67385e0e33634fa&fccid=9784ae78e9834539&vjs=3
Data Engineer,Berkley,"Wilmington, DE 19809",,"Company Details:
Berkley Technology Services (BTS) is a dynamic company committed to providing world class IT services. We offer a unique culture, enabling our team members to be on the cutting edge of technology while delivering high quality solutions. Our functions include working with various third parties to develop, integrate, and support insurance systems of WRBC's operating units. BTS strives to provide these functions in a holistic manner including helpdesk support, system connectivity, and operational support. Additional responsibilities include coordinating communications regarding best practices in the use of our supported systems and researching new technology. BTS is constantly growing and expanding to meet the changing demands of one of the most successful insurance organizations in the world.
Responsibilities:
This position will be providing data development at a moderately complex level such as ETL, cube creation, adhoc and management reporting, dashboard and data extract creation. This individual will work within a team environment that provides data resource development and support for several companies. They will be responsible for analyzing, designing and coding solutions for rapidly growing companies supporting the insurance industry.
Qualifications:
Primary Duties & Responsibilities:
Demonstrates a robust understanding of all business data processes/processing for a system, and the related data structures.
Can produce significant new system functionality or defect resolution with minimal direction.
Creates design specifications that demonstrate an understanding of most interfacing systems and supported business processes.
Routinely proposes improvements to a data process and/or structure to improve supportability or usability.
Can perform adequate peer review on any changes in the system.
Can be consulted to provide recommendations to solve business issues based on experience and knowledge of current technology.
Demonstrates understanding of data processes and/or structures.
Will be required to communicate with employees primarily up to the mid-level within both company and client companies.
May begin to develop sphere of influence with other teams.
Will be required to communicate and coordinate within the team.
May be responsible for on-call rotation.
Some travel required up to 20%.
Minimum Qualifications:
5 – 10 yrs - reasonable single system / single technology knowledge.
5 + yrs SQL experience. (queries, stored procedures, functions)
Must have demonstrated the capability of meeting the key accountabilities, or have the ability to learn/perform them.
A self-motivated individual with a passion for success.
Needs to be able to determine how changes impact customer and other systems.
Excellent communication and organizational skills.
Ability to work in a fast-paced team environment.
Ability to quickly adapt and learn new technologies.
Ability to work independently.
Strong customer and business focus.
Bachelor’s degree from four year college or university with emphasis in related field.
Working Conditions and Physical Requirements:
Ability to sit at a desk and work on a computer for extended periods of time.
May occasionally lift and/or move up to 10 pounds.
Vision abilities required by this job include close vision and ability to adjust focus.",http://www.indeed.com/rc/clk?jk=a11394d042b3dc55&fccid=8e547279469474b7&vjs=3
Data Engineer,S3b Global Inc,"Richmond, VA",,"Required Skills: Spark, PySpark, Python
Responsibilities:
Data background currently working with spark, python and pySpark
Must have excellent communication skills",http://www.indeed.com/rc/clk?jk=cf5b6898f0cb9605&fccid=3c4a69a4f4120f01&vjs=3
Data Engineer,VoxTech,United States,,"Position Available
You should have superior SQL development experience along with the ability to interface with customers (though there will be no significant travel required). This position requires top technical skills, business communication skills, excellent attention to detail and follow-up, and the ability to self-manage. You will get exposure as you work directly with our customers to tackle tough business challenges.

We are looking for ‘full stack’ Data Engineers to work with our customers. You should be able to talk to a customer, work with raw data, design a schema, do data transformation, write automated tests, and manage deployment and operations. Your work will be 80% in code, primarily SQL. Some Python coding experience and experience building Docker containers is a plus. AWS and Amazon Redshift experience is a plus. You will work with a team of world-class data engineers on challenging data. We work weekly sprints and have the freedom to achieve and expect to own the results of your work.

Bachelor Degree in Computer Science or equivalent with 3+ years experience or Masters Degree in Computer Science or equivalent required.",http://www.indeed.com/rc/clk?jk=c7ecb78a833dbfbb&fccid=c24c6e12431afc23&vjs=3
ETL Data Engineer,"TalentMovers, Inc.","San Jose, CA",,"Position ETL Data Engineer
Location San Jose, CA
Duration 24 months
Job Description
Informatica ETL
Oracle SQL
Linux
Must be able to bring up new architecture/design for ETL processing
Minimum 8+ years' experience in Data/Warehousing
Python or Scala with good ETL/ELT skills.
Good exposure and knowledge on using HIVE and MPP databases (like REDSHIFT, Vertica etc..)
Candidate must be able to use Python/Scala with Spark and AWS for writing ETLs
Good exposure on writing ETL using Spark
Good SQL query writing skills
AWS Services like REDIS,EMR,EC2,Glue,s3,Cloudwatch etc
Thanks
Sid
703-349-5365
sid@talentmoversinc.com
for more positions please visit our website
www.talentmoversinc.com",http://www.indeed.com/rc/clk?jk=ae6285c34fa6c3bf&fccid=01267275e4614eb0&vjs=3
"Data Engineer, West Palm Beach",LOCKHEED MARTIN CORPORATION,"Jupiter, FL 33478",,"The flight test data engineer is responsible for all aspects of real time and post-flight processing of aircraft data, including on-board processing computer, cockpit display, and data servers.


Work hours are set by flight test schedule and can be somewhat variable from day to day.


Overtime work is often required.

Travel may be required to support offsite testing activities.
Basic Qualifications:
Bachelors degree from an accredited college in a related discipline, or equivalent experience/combined education, with 2 years of professional experience; or no experience required with a related Masters degree.

Basic understanding of data gathering processes.Must be proficient in the use of large data servers and computer peripherals for the purposes of data downloading, processing, managing, backup and recovery.Knowledge of instrumentation devices to develop, test, and troubleshoot data processing algorithms for aircraft data.Demonstrate strong analytical and troubleshooting skills;Demonstrate ability to work independently.Experience in computer programming and windows servers.Must be able to work effectively across several different disciplines in a collaborative environmentMust be able to communicate effectively (both orally and written)
Must be well-organized and able to handle multiple assignments
Desired Skills:
Experience in installation, testing, operating, troubleshooting, and maintenance of hardware and software systemsExperience in monitoring and maintaining computer system or network hardware or software applicationsExperience in data processing
BASIC QUALIFICATIONS:
job.Qualifications

Lockheed Martin is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.
Join us at Lockheed Martin, where your mission is ours. Our customers tackle the hardest missions. Those that demand extraordinary amounts of courage, resilience and precision. They’re dangerous. Critical. Sometimes they even provide an opportunity to change the world and save lives. Those are the missions we care about.

As a leading technology innovation company, Lockheed Martin’s vast team works with partners around the world to bring proven performance to our customers’ toughest challenges. Lockheed Martin has employees based in many states throughout the U.S., and Internationally, with business locations in many nations and territories.
EXPERIENCE LEVEL:
Experienced Professional",http://www.indeed.com/rc/clk?jk=5a53cce7e94c217a&fccid=aeb15e43a6800b9d&vjs=3
Data Engineer,McDonald's Corporation,"Chicago, IL 60607",,"Company Description

McDonald’s is proud to be one of the most recognized brands in the world, with restaurants in over 100 countries and billions of customers served each year. As the global leader in the food service industry, we have a legacy of innovation and hard work that continues to drive us. Today, we are growing with velocity and are focused on modernizing our experiences, not to make a different McDonald’s, but to build a better McDonald’s.
We are moving fast and are adding to our best-in-class team. Joining McDonald's means thinking big every day and preparing for a career that can have impact around the world. We are customer obsessed, committed to being leaders, and believe we are better when we work together. Over the last couple years, we’ve launched home delivery, modernized our restaurant experience through digital enhancements and have so much more to come.
We are dedicated to using our scale for good: good for people, our industry and the planet. From ambitious recycling initiatives and balanced sourcing efforts to our partnership with Ronald McDonald House Charities, we are constantly improving. We see every single day as a chance to have a genuine impact on our customers, our people and our partners.
Our new, state-of-the-art headquarters is located in the booming West Loop area in the heart of downtown Chicago. It's set up to be a global hub that cultivates innovation. Take a class at Hamburger University, sample future menu items in our Test Kitchen, and utilize the latest technology to communicate with your team around the globe! Our office helps us connect with each other like never before. Participate in monthly organized events, enjoy massive outdoor spaces, an 8000 square foot gym, and an onsite McDonald's serving international favorites. Needless to say, you’ll be lovin’ it here!

Job Description

McDonald's is looking to hire a Data Engineer. The role will work closely with data architects and includes designing, architecting, and building data pipeline to support business use cases. Responsibilities also include collaborating with business leaders to translate business requirements into technical, scale-able solution.

Qualifications
Bachelor’s or Master’s Degree in Computer Science, or Information technology preferred.Ability to present to senior leadership and partnersExperience managing applications in cloud based technologies and pipelining and familiarity with core servicesExperience in ETL and data warehouse technologies (Oracle, SQL Server, etc.)Skilled manipulating Big Data using HDFS/Hadoop eco system toolsFamiliarity with modern Machine Learning techniquesExperience and desire to work in a Global delivery environment is a plusStrong knowledge of relational and multi-dimensional database architectureStrong verbal and written communication skills, and ability to synthesize technical information for a business audience
Additional Information

McDonald’s is committed to providing qualified individuals with disabilities reasonable accommodations to perform the essential functions of their jobs. Additionally, if you (or another applicant of whom you are aware) require assistance accessing or reading this job posting or otherwise seek assistance in the application process, please contact recruiting.supportteam@us.mcd.com
McDonald’s provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to sex, sex stereotyping, pregnancy (including pregnancy, childbirth, and medical conditions related to pregnancy, childbirth, or breastfeeding), race, color, religion, ancestry or national origin, age, disability status, medical condition, marital status, sexual orientation, gender, gender identity, gender expression, transgender status, protected military or veteran status, citizenship status, genetic information, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.
Nothing in this job posting or description should be construed as an offer or guarantee of employment.",http://www.indeed.com/rc/clk?jk=5c0d244253f821c2&fccid=f753bb1a40104d82&vjs=3
Big Data Engineer,Acestack LLC,"Houston, TX",,"Job Details
Position : Big Data Engineer
Big Data Engineer
Technology Stack
Hadoop
Hive
MQ
Big Data
Green Plum",http://www.indeed.com/rc/clk?jk=3b94e813ae44f60c&fccid=41a3a93df3c370e2&vjs=3
Data Engineer Apprentice | Associates Degree Candidates,Digital Creative Institute,"Dallas, TX 75215",,"Job Description

Are you passionate about data and technology? Would you like to be on the forefront of innovation, working in a fast-paced environment with the resources of an established brand? Then you might be a perfect fit at one of our partner company’s offices in Dallas, Charlotte, Seattle, Atlanta, or Chicago.

In the role of Data Engineering Apprentice, you will be providing support to consulting and technical teams across various stages of the Software Development Life Cycle. You will play a critical role by contributing to the knowledge management process while interfacing with internal teams to ensure high-quality deliverables.

What is the Apprenticeship experience like?

As a way to accelerate your growth, you'll participate in DCI's Data Analyst Apprenticeship Program remotely while working at a partner company. Prior to the apprenticeship program start date, you’ll receive three months of in-demand skills acceleration, coaching, and interview preparation in the Pre-Apprenticeship program which is also remote.

As an apprentice, you'll start in a cohort of 10+ apprentices and complete the program over 12 months where you can earn 24 college credit hours to transfer towards a bachelor's degree online. *(select colleges apply)

You’ll attend remote evening sessions twice a week where you’ll dive deep into all things data including business analysis using various techniques, e.g. statistical analysis, explanatory and predictive modeling, python, coding, and data mining. You'll complete milestones along the way like earning data certifications to validate your skills, module portfolio projects, etc.

You will also receive support from top industry coaches and mentors to progress through your personal and professional goals, skills roadmap, while also demonstrating new knowledge and competencies through hands-on application with your portfolio project.

Furthermore, DCI’s Data Analyst Apprenticeship Program is an official registered apprenticeship recognized by the Department of Labor (DOL). Every graduate of a Registered Apprenticeship program receives a nationally-recognized credential from the DOL.

Key qualifications for the Data Engineering Apprentice Role:

Because we understand that you’re just beginning your career, we’re committed to your learning and growth. We’re seeking candidates who have the following requirements.

Associate degree or equivalent
Adventurers needed. You'll have the opportunity to be placed in one of our partner company’s offices in Dallas, Charlotte, Seattle, Atlanta, or Chicago.
Strong computer skills, including experience with programming languages (Python, Java, SQL, R, etc.)
Experience with Microsoft Office tools, especially creating/ maintaining Excel spreadsheets
High level of attention to detail and problem-solving ability
Ability to accurately sort and analyze data
Ability to communicate ideas both verbally and in writing
Must be willing to learn additional data engineering and analytics toolsets

Key Responsibilities:

Architect, design and detail processes
Troubleshoot issues, document process, review checklists, and develop a reference implementation
Develop and implement databases, data collection systems, data analytics and other strategies that optimize efficiency and quality
Acquire data from primary or secondary data sources and maintain databases/data systems
Support technical team deployment with activities to ensure a smooth go-live of new processes, products, or systems
Understand the existing system and processes to document
Reverse knowledge transfer to document the process of support and maintenance

This job entails sitting as well as working at a computer for extended periods of time. You should be able to communicate by telephone, email, or face to face. Travel may be required based on job requirements. Adventurers needed. You'll have the opportunity be placed in one of our partner company's locations throughout the US.

U.S. citizens and those authorized to work in the U.S. are encouraged to apply. We are unable to sponsor at this time.

Important Note:

Learn more about the Data Analyst Apprenticeship program on our website before you apply. http://bit.ly/DCIDataAnalyst

After, submit your apprenticeship application to get started: http://bit.ly/32pnswk",http://www.indeed.com/rc/clk?jk=bce9e02ca3c603ce&fccid=33d673c0979492ae&vjs=3
Cloud Data Engineer,Fidelity TalentSource,"Merrimack, NH 03054",,"Fidelity TalentSource is your destination for discovering your next temporary role at Fidelity Investments. We are currently sourcing for a Senior Cloud Data Engineer to work in Fidelity’s Asset Management Technology in Merrimack, NH.
Build a data platform to support Asset Management’s data analytics and discovery needs. If you have a passion for working with data using multiple emerging technologies on the cloud, this might be the right opportunity for you!
The Expertise We’re Looking For
Expertise in application development using Python using AWS services
Expertise in AWS services (EC2, Lambda, S3, Cloudformation template, SQS, SNS, Elastic Search etc.)
Experience in database design and development (preferably Oracle)
Experience in automating data movement pipelines
Experience in release automation and CI/CD (Jenkins, Concourse, Stash etc.)
At least 5 years of software development experience with at least 2 years working on cloud/big data technologies
BS in Computer Science or related degree, or equivalent experience

Good to have:
Exposure to Snowflake database
Exposure to Big Data technologies (Hadoop, Spark, Hive, Athena, Presto etc.)
Good understanding of overall AWS security services like KMS, IAM etc.
Experience in building Rest APIs

The Purpose of Your Role
The Cloud Data Engineer will be working as part of a core team building the data analytics platform for Asset Management. This will involve building a data lake using Snowflake as the data store for structured data and AWS S3 for unstructured data.
The Skills You Bring
You have strong expertise building applications using Python
You have hands on experience building solutions using AWS services
You have hands on experience building data lake sourcing data from heterogeneous sources and experience working with structured and unstructured data.
You enjoy working on different technologies to solve business problems
You have excellent programming skills (Python, Java, Scala etc.) and have good SQL skills
You have experience in UNIX shell script
You enjoy learning new technologies, data analysis, identifying data patterns and trends
You can independently figure out technical challenges, identify options and come up with innovative solutions
You have good communication skills

The Value You Deliver
Technical expertise in building our next generation data platform on AWS
Building quality solutions that align with the technology blueprint and best practices to solve business problems by driving design, development and ongoing support.
Work with our global team and provide technical direction in building solutions.
Actively participating in knowledge sharing sessions, code and design reviews etc.

How Your Work Impacts the Organization
Asset Management Technology (AMT) provides worldwide technology and support to all the Investment Management, Research, Trading and Investment Operations functions. AMT is an integral partner for Asset Management to deliver innovative, scalable, industry-leading investment tools that enable Asset Management to achieve competitive advantage globally.
Company Overview
Fidelity TalentSource, formerly Veritude, is the in-house temporary staffing provider for Fidelity Investments, one of the largest and most diversified global financial services firms in the industry. We recruit individuals from a variety of backgrounds, including technology and customer service, to fill assignments across Fidelity’s U.S.-based regional and investor center locations. If you would like to experience Fidelity’s diverse and inclusive workplace while expanding your skillset and developing your professional network, consider a role with Fidelity TalentSource.
For information about working at Fidelity TalentSource, visit FTSJobs.com.",http://www.indeed.com/rc/clk?jk=9e1a68faa391e7b2&fccid=7df8513443c7134a&vjs=3
Sr. Data Engineer / DWH / ETL : W2 Only : : REMOTE,Neev Systems,"United, PA",,"Data Engineer / DWH 100 % Remote Job Description : 10 years of Total IT ExperienceHaving good experience with Data Warehouse (DWH) environment with data integration.Experience working with Agile methodologiesAny kind of knowledge on scripting language (e.g. Python/Perl/shell scripting) on Unix/Linux Platforms.Good communication skillsA Bachelors degree or higher in computer.Responsibilities: Build and maintain the infrastructure to answer questions with data, using software engineering best practices, data management fundamentals, data storage principles, recent advances in distributed systems, and operational excellence best practices.Work closely with stakeholders to understand their requirements and design the right solutionWork closely with other teams, analyze source systems, define underlying data sources and transformation requirements, design suitable data models and document the design/specifications.Build/maintain systems and datasets that analysts and scientists use to generate actionable insights.Demonstrate passion for quality and productivity by use of efficient development techniques,standards and guidelinesPeer reviews of work. Actively mentor more junior members of the team, improving their skills,their knowledge of our systems and their ability to get things doneJob Types: Full-time, Contract",http://www.indeed.com/rc/clk?cmp=Sr-Java-Developer-with-AWS-exp-%3A-NYC&ti=Senior+Data+Engineer&jk=e4c2bcc1b535a745&fccid=d4f7aca840d0da49&vjs=3
Jr. Data Engineer,The Lead Group,"Leawood, KS 66206",,"The Lead Group – Data Engineer

The Lead Group, a rapidly growing digital marketing agency with offices in Atlanta and Kansas City, is looking to expand operations in the Kansas City office. We are looking for a Data Engineer, who will work within The Lead Group’s Data Science team. The Lead Group’s Data Science team creates value through consolidation and analysis of operational data and development of systems that utilize that data. To do this we are building and owning a high-volume data pipeline—from the frontend event code all the way back to the data warehouse. This requires constant collaboration with the brightest people in the organization. You will be a part of that and will be responsible for the creation, delivery and maintenance of analysis and reporting ready datasets to our teams.

What you’ll do:
Replicate data from MySQL, application & system logs, and various other 3rd party sources into multiple Redshift data warehouses utilizing AWS DataPipeline
Craft Python code as needed to extract, transform, or load data
Write SQL to create easily consumable datasets for team-members’ use in reporting and analysis
Monitor and tune Redshift
Organize our data warehouse to be a self-explanatory, self-documenting, and performant resource for product managers, engineers, and business analysts
Maintain existing Redshift cluster & ETLs
Investigate new technologies for incorporation into our architecture

What you’ll bring:
A strong interest in data, analytics, and technology
A self-directed, can-do attitude
Great SQL skills
An understanding of Python
Familiarity with Amazon Web Services
Experience with Pentaho a plus

Benefits:
Small-team, you will have big opportunities to learn and make an impact
Competitive Salary
Medical, Dental, and Vision Insurance for employee is 100% covered by employer
401(k) Plan
Paid time off
Casual working environment
Off-site events (Happy Hours, Annual Retreat, Charity Events)",http://www.indeed.com/rc/clk?jk=daf6ab0be3a4f43c&fccid=c9569ce7e3be7a37&vjs=3
Data Engineer Analyst,Experian,United States,,"At Experian Health, our employees have the opportunity to shape more than products – they shape the future of U.S. healthcare. Experian Health is a pioneer for innovations leading the way in revenue cycle management, identity management, patient engagement, and care management for hospitals, physician groups, labs, pharmacies and other risk-bearing entities. Our success relies on people who are given the freedom to imagine new frontiers in the rapidly changing healthcare space and push the boundaries of innovation. Help us realize our vision of applying data for good and changing the healthcare landscape for the better – for all of us.

Experian Health is looking for a Data Engineer Analyst to join their Identity & Care Management Development Team. The Data Engineer Analyst will analyze data requirements, study complex source data, interpret data, create data models and variables, and assist to determine the best methods to extract and handle large datasets. The candidate will conduct analysis and produce reports based on data generated from a number of different sources and data formats, both internal and external to the company. In addition to information and data reporting projects, the Candidate will also be heavily involved in documentation and quality assurance work; operational improvement; documenting processes; developing and maintaining reference and technical guides. This position will also interact on a consistent basis with other business/functional analysts, programmer/analysts, database/data warehouse administrators, and data stewards/functional owners. The ideal candidate should be able to work well under direct supervision as well as independently by executing a variety of established procedures to accomplish assigned tasks. He/she will use basic and some advanced analytical, information management, programming, technical and statistical skills to solve a variety of problems.


Key Responsibilities
Translate complex business requirements into technical solutions. Perform data analysis and data modeling to create source to target mappings.Create documentation, specifications, diagrams, and charts to provide direction to business and development teamGenerates reports following quality control procedures to document analysis and model findings.Participate in design sessions with business and development teams. Collaborates in the planning, design, development, and deployment of new functionality, and enhancements.
Collaborates in the elaboration of complex data structures and programs.Analyzes and confirms the integrity of source data to be evaluated.Collaborates with internal and external clients to provide project support as needed.Meet with decision makers, systems owners, and end users to define business, financial, and operations requirements and goals, and identify and resolve data related issues.Analyzes algorithm performance to identify outliers and make improvement recommendations

Job Requirements
Ability to interpret data and to communicate it in both technical and user-friendly language.
Expert analytical skills to evaluate understand and interpret data from both an internal and client perspective
Experience in developing best practices and excellent logical, analytical, and creative problem-solving skills.
High level understanding of data and analytical procedures
Lead and fulfill projects with minimal oversight
Ability to work directly with clients
Highly self-motivated and directed.
Ability to effectively prioritize and execute tasks in a high-pressure environment.
Experience working in a team-oriented, collaborative environment.
Proven experience working with SQL, PostgreSQL, PL/SQL and/or PL/pgSQL scripting is preferred.
Proven experience working with Mongo is preferred.
Proven experience working with Linux is a plus.
Experian is an Equal Opportunity Employer. Anyone needing accommodation to complete the interview process should notify the talent acquisition partner. The word ""Experian"" is a registered trademark in the EU and other countries and is owned by Experian Ltd. and/or its associated companies.
EOE including Disability/Veterans",http://www.indeed.com/rc/clk?jk=b19c39ec0bbbfe0b&fccid=75a3a5a15b202084&vjs=3
Data Engineer,Saama Technologies Inc,"Campbell, CA 95008",,"What your role and responsibilities will be
Collaborate with Integration team to build ETL processes to ingest data into BI stores.Work with the internal teams in understanding the client requirements and convert
them into technical solutions.
Be a team player in performing development work during the production life cycle.Experience with building stream and batch data processing systems.Gather and process complex raw data at scale (including writing scripts, calling APIs,
write SQL queries, etc.).
Design and develop data processing solutions that support high performing and scalable
analytic solutions.
What you’ll need to succeed
 3+ years in a data engineering role.
 Advanced knowledge of SQL and SQL queries performance tuning.
 Good experience with RDBMS (Potgres, MS SQL Server, Oracle, DB2 ... etc)
 Good experience with REST APIs
 Good Experience with NOSQL databases (HBase, Mongo DB … etc)
 Experience with Impala, Hive & Presto is an asset.
 Good knowledge of the Spark/Hadoop ecosystem.
 Good knowledge of Scala/Java is an asset
 Good knowledge of Python and Shell scripting.
 Familiarity with micro-services and lambda architecture is an asset.",http://www.indeed.com/rc/clk?jk=3b0ddcbd17c781c0&fccid=f7cbfaf9ddc3fe8a&vjs=3
Data Engineer,Fidelity TalentSource,"Boston, MA 02210",,"Fidelity TalentSource is your destination for discovering your next temporary role at Fidelity Investments. We are currently sourcing for a Lead Data Engineer to work in Fidelity’s Asset Management Technology in Boston, MA.
The Advanced Data Analytics Technology Team in Fidelity’s Asset Management organization is an embedded team passionate about unlocking the potential of new technologies, techniques and data sets, to assist our Investment Professionals in generating alpha for our investment products and customers.
The role is ideal for someone with an enterprise development background, with a strong technology and coding skills, looking to operate in a less constrained environment, as part of an accelerated development team.
We are targeting a skilled technical leader with strong design, collaboration and influencing skills.
Ideally the candidate is a full stack developer, but this role will be primarily focused on processing and generating Analytics from structured and unstructured data sets with the ability of parallel processing potentially in the cloud.
The candidate will have a strong technology background with a demonstrated ability to quickly adapt to new technologies, a self-starter, a validated ability to work with quantitative concepts and data, and a validated understanding and experience with the investment management business.
The Team
The team is comprised of a diverse set of technology professionals including application developers, database engineers, data scientists and tool prototypers with quantitative backgrounds who work collectively with our business partners to take ideas from a whiteboard, through prototypes that garner feedback to be rapidly deployed to our users, all the way through to integration with enterprise applications both on-prem and on the cloud.
The Expertise You Have
Bachelor’s or Master’s Degree in a technology related field (e.g. Engineering, Computer Science, etc.) required.
10+ years of enterprise development and a desire to work on a fast paced development team with the experience of handling multiple tracks concurrently
C# or Java, Python or R, AWS / Cloud, Oracle / RDBMS, REST APIs

The Skills You Bring
You have a track record of engineering perfection with a strong understanding of processing large datasets and building scalable applications. You’re not intimidated by Conceptual Design to Rapid Prototyping
You have a proven background with enterprise development and a confirmed ability rapidly bring projects from inception to delivery in meaningful timeframes. Using C# or Java, Angular 2.0+, MVC frameworks
You are familiar with extracting data from REST APIs and parallel processing large datasets using C# or Java
You are familiar with developing custom Data Pipelines to extract data, map data, transform data, and to load data in various data stores like RDBMS, Oracle, S3, and / or shared drives.
Your experience developing scripting in Linux and Windows
Any experience with migrating applications to AWS (Cloud) will be an added advantage.

The Value You Deliver
You will be crafting, developing, and delivering applications from Conceptual Design to Rapid Prototyping using C# and / or Java and / or Python and / or Scala or Oracle / RDBMS
You will be acting as a mentor to team members in ensuring strong design practices.
Participating in problem solving, troubleshooting, performance turning, production support, and maintenance of applications
Your ability to multi-tasking and tracking multiple projects as a Tech Lead

Company Overview
Fidelity TalentSource, formerly Veritude, is the in-house temporary staffing provider for Fidelity Investments, one of the largest and most diversified global financial services firms in the industry. We recruit individuals from a variety of backgrounds, including technology and customer service, to fill assignments across Fidelity’s U.S.-based regional and investor center locations. If you would like to experience Fidelity’s diverse and inclusive workplace while expanding your skillset and developing your professional network, consider a role with Fidelity TalentSource.

For information about working at Fidelity TalentSource, visit FTSJobs.com.",http://www.indeed.com/rc/clk?jk=8dfe509b7e3414f7&fccid=7df8513443c7134a&vjs=3
Data Engineer,Amazon.com Services LLC,"Seattle, WA",,"3+ years of experience as a Data Engineer or in a similar roleExperience with data modeling, data warehousing, and building ETL pipelinesExperience in SQL

Do you want to build the premium shopping experiences for millions of Amazon customers? Do you want to work on performance challenges for providing the best recommendations in less than 200 milliseconds, given millions of customers and millions of products? Are you interested in working on Machine Learning and data science, believing every customer should not have the same experience? Amazon has a role or you.
As an Amazon.com Data Engineer you will be working in one of the world's largest and most complex data warehouse environments. You should be an expert in the architecture of DW solutions for the Enterprise using multiple technologies (RDBMS, Columnar, Cloud). You should excel in the design, creation, management, and business use of extremely large datasets. You should have excellent business and communication skills to be able to work with business owners to develop and define key business questions, and to build data sets that answer those questions. Above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive change.

Industry experience as a Data Engineer or related specialty (e.g., Software Engineer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting value from large datasets.Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data setsExperience building data products incrementally and integrating and managing datasets from multiple sourcesQuery performance tuning skills using Unix profiling tools and SQLExperience leading large-scale data warehousing and analytics projects, including using AWS technologies – Redshift, S3, EC2, Data-pipeline and other big data technologiesExperience providing technical leadership and mentor other engineers for the best practices on the data engineering spaceLinux/UNIX including to process large data sets.Some experience leveraging SAS, R or matlab to manipulate data and set up automated processes as per business requirementStrong ability to interact, communicate, present and influence within multiple levels of the organizationExcellent communication skills to be able to work with business owners to develop and define key business questions and to build data sets that answer those questionsA desire to work in a collaborative, intellectually curious environment.
Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation / Age.",http://www.indeed.com/rc/clk?jk=810385fe8e79d995&fccid=fe2d21eef233e94a&vjs=3
Junior Data Engineer,Applied Information Sciences,"Austin, TX 78731",,"Location: Austin, Texas, United States

Requisition Number: 330
Position Title: Data Architect
External Description:
Now Hiring a Data Engineer

Ability to maintain an Interim Secret Clearance is Required

As a Data Engineer you will use cutting edge cloud and data technologies to streamline services to our clients. Join our team of Data and Cloud professionals and accomplish what others only dream of. Must be able to maintain an Interim Secret Clearance. Must be able to commute to Austin, Texas.

Conduct preliminary data evaluation and database structure, optimize and standardize if necessary.
Work with SME and ATF EDW team to build the scripts for the CGI Dashboard view
Importing NESS data into EDW
Creating Reports in PowerBI that are high value for field or executives
NESS data visualized in the CGI Dashboard
NESS Data Validation ‐ with emphasis on data from other ATF databases
Work with NESS Dev team to identify best solutions for incorporating RMS data into NESS
Translate business needs into long‐term architecture solutions
Review, simplify and optimize existing data import process from various sources such as NIBIN, etrace and various RMS imports
Evaluate re usability of current data for additional analyses.
Review object and data models and the metadata repository to structure the data for better management and quicker access

Profile of Success

Bachelor's degree in an IT-related field and two years of experience
Proven experience developing Big Data solutions in the Azure space
Extensive experience with the Azure suite (Azure Data Lake, Azure Data Factory, Azure SQL Data Warehouse, Data Lake Analytics, HDInsight, Machine Learning, and Stream Analytics)
SQL Server 2014/2016 experience
Experience using Spark, Hive, Pig, and Scala
Comfortable with Microsoft Full Stack (SSAS/SSIS/SSRS)
In-depth knowledge of Data Warehousing and ETL/ELT
Proven ability to work with clients to understand requirements and to envision solutions
Possess DoD 8570 security certification

Desirable Skills

Background with Data Science tools such as R, Python, and SAS is a plus
Microsoft related certifications such as the MCSD/MCSE
Experience with Tableau
Experience working with Hadoop ecosystem
City:
State:
Community / Marketing Title: Junior Data Engineer
Company Profile:
About AIS
AIS, Dedicated to Our People

AIS employees can spend their entire career at AIS doing challenging, rewarding work and reach their desired level of achievement and responsibility. We offer the opportunity to move up, without the obligation to move out of a position where one excels. We are committed to our employee’s success; however, they define it.

It’s our dedication to our employees that inspired our leadership to invest in our future and become partially employee-owned through an Employee Stock Ownership Program (ESOP).

Our employees are our greatest strength, and we do all that we can to serve them. We invest in technology as early adopters, allowing us to create transformative and innovative solutions for our customers while exposing our team to cutting edge technology.

We hire outstanding individuals who are committed to curiosity, passionate about emerging technology, and who are excited to find innovative solutions for the biggest tech challenges facing international brands and government agencies today.

We Invest in Individuals Committed to Innovation

AIS is seeking professionals of a certain character and level of excellence. People that we can learn from and that we can help grow to achieve their personal career goals. We are looking for:

Smart people with a passion for technology
Strong technical capabilities with a consultancy mindset
Close involvement with local technical communities
A willingness to think outside of the box to provide innovative solutions to clients
Ability to solve challenging technical business problems
Self-directed professionals
Our Core Values
Client Success
Continued Learning and Technical Excellence
Strong Client Relationships
Citizenship and Community
AIS is an Equal Opportunity Employer
Location_formattedLocationLong: Austin, Texas US
CountryEEOText_Description: Applied Information Sciences is an Equal Opportunity Employer and does not discriminate on the basis of race, national origin, religion, color, gender, sexual orientation, age, disability, protected veteran status or any other basis covered by law. Employment decisions are based solely on qualifications merit, and business need.",http://www.indeed.com/rc/clk?jk=a7b8b54930902dc4&fccid=edbbf93fc5210a17&vjs=3
Jr. Data Engineer,NBCUniversal,"Seattle, WA",,"Possess an understanding of the underlying data, data structures, and business uses of said data
Demonstrate fundamental knowledge of modern cloud computing platforms and concepts
Work with modern schema-less big data storage solutions
Work closely with machine learning and data science teams to create scale and efficiency
Demonstrate critical thinking for potential roadblocks; comprehend a bigger picture of the business and effectively communicate these issues to the greater BI organization
Work closely with internal stakeholders to implement solutions that adhere to solution designs and schema
Qualifications/Requirements
Passion for media and newsB.S. degree in Computer Science, Information
Technology, or equivalent experience

Minimum of 1 years’ experience in a developer roleProficient with Javascript and PythonProficient with Linux environment
Proficient with data layers, and other modern
implementation concepts
Familiarity with Presto and SQLExperience with Serverless cloud platforms a plus
(AWS)
Experience working with Tag management solutions a
plus
Experience with distributed data technologies (e.g.
Spark)
Sub-Business
News Digital
Career Level
Entry-Level
City
Seattle
State/Province
Washington
Country
United States
About Us
At NBCUniversal, we believe in the talent of our people. It’s our passion and commitment to excellence that drives NBCU’s vast portfolio of brands to succeed. From broadcast and cable networks, news and sports platforms, to film, world-renowned theme parks and a diverse suite of digital properties, we take pride in all that we do and all that we represent. It’s what makes us uniquely NBCU. Here you can create the extraordinary. Join us.

This is an opportunity to play a critical role in the digital evolution of NBC News, one of the world’s best known and most trusted news organizations. We are looking for a software engineer for the Business Intelligence team, a part of NBC News Digital Technology.

You will be responsible for designing and maintaining efficient, flexible, and extensible BI analytic frameworks to build advanced analytics and applications across the business. You will operate as a center of excellence with other development teams to facilitate analytics implementations across the NBC News Digital portfolio on web, mobile and OTT platforms.


This position reports to the Head of Business Intelligence and is based in Seattle, WA.
Notices
NBCUniversal’s policy is to provide equal employment opportunities to all applicants and employees without regard to race, color, religion, creed, gender, gender identity or expression, age, national origin or ancestry, citizenship, disability, sexual orientation, marital status, pregnancy, veteran status, membership in the uniformed services, genetic information, or any other basis protected by applicable law. NBCUniversal will consider for employment qualified applicants with criminal histories in a manner consistent with relevant legal requirements, including the City of Los Angeles Fair Chance Initiative For Hiring Ordinance, where applicable.",http://www.indeed.com/rc/clk?jk=6a955d039736c4d0&fccid=35d653c09c2712b6&vjs=3
Data Engineer,Autodesk,"San Francisco, CA",,"Autodesk is seeking a Data Engineer with experience building production data pipelines to join our Data Platforms and Insights team. The Data Platforms and Insights team is chartered with building robust and resilient pipelines that create the master data sets that serve as the building blocks for all data scientists and data analysts throughout the organization. In addition, this team establishes and promotes the data engineering standards and best practices across Autodesk and help to lead the effort to make data an integral part of decision making at Autodesk. The ideal candidate will be responsible for designing, developing, implementing and documenting data solutions for complex ETL data pipelines, and lending technical expertise within the group. The ideal applicant will be able to thrive in a highly collaborative workplace and actively engage in the development process.

Responsibilities

Map and automate data flow from a variety sources including desktop, web, and mobile product feeds and business systems
Develop workflows for data science workloads utilizing orchestration tools (e.g. Airflow) to manage Spark workloads
Deploy data science pipelines to support production data science models (e.g. Sagemaker)
Deploy solutions via automated CI/CD processes to execute data pipelines running in batch
Work with programming languages used for data manipulation, including Scala, PySpark, Spark SQL, R, or Java
Design, develop, execute and document software solutions to address complex data collection, processing, transformation and reporting issues
Collaborate with peer organizations, dev ops, support organizations on technical issues and provide guidance
Interpret and translate business needs to technical requirements
Work with team to troubleshoot code level problems quickly and efficient on as need basis
Develop, refine and educate the data community on coding standards and best practices
Participate in code and document reviews

Minimum Qualifications

Bachelor’s Degree or relevant experience in the field of Computer Science, Mathematics or Statistics
2 to 3 years of experience in big data technologies including Spark, Hadoop, RedShift, Vertica, Snowflake, Hive, Lambda, Glue, S3, Airflow
Proficiency in executing analysis using SQL, Hive, R, Spark Data frames, Scala, and/or Python
Strong SQL skills
Details-oriented with a focus on best practices for design and implementation of scalable data engineering solutions
Fluency with one or more of the scripting languages: Python, Java, Scala, etc.
Working knowledge and experience with basic and complex data structures
Good communication skills and ability to explain complex topics to a non-technical audience
Knowledge and experience with large data sets, event streams and distributed computing (Hive/Hadoop, Spark etc.)
Experience working with Agile Scrum Teams
Experience in Version control management - tracking and coordinating engineering work
Proven experience of finding bugs and vulnerabilities with automated tools
Expertise in data research/analysis with a focus on data quality and consistency
Experience with algorithms, distributed storage & compute to solve complex business problems

Preferred Qualifications

Experience with container systems like Docker and container orchestration like
EC2 Container Service, Kubernetes, Terraform.
An advanced school degree

About Autodesk
With Autodesk software, you have the power to Make Anything. The future of making is here, bringing with it radical changes in the way things are designed, made, and used. It's disrupting every industry: architecture, engineering, and construction; manufacturing; and media and entertainment. With the right knowledge and tools, this disruption is your opportunity. Our software is used by everyone - from design professionals, engineers and architects to digital scientists, students and hobbyists. We constantly explore new ways to integrate all dimensions of diversity across our employees, customers, partners, and communities. Our ultimate goal is to expand opportunities for anyone to imagine, design, and make a better world.

At Autodesk, we're building a diverse workplace and an inclusive culture to give more people the chance to imagine, design, and make a better world. Autodesk is proud to be an equal opportunity employer and considers all qualified applicants for employment without regard to race, color, religion, age, sex, sexual orientation, gender, gender identity, national origin, disability, veteran status or any other legally protected characteristic. We also consider employment for all qualified applicants regardless of criminal histories, consistent with applicable law.
To all recruitment agencies: Autodesk does not accept unsolicited headhunter and agency resumes. Autodesk will not pay fees to any third-party agency or company that does not have a signed agreement with Autodesk, Inc.",http://www.indeed.com/rc/clk?jk=136aa3b4bcaa745c&fccid=7136762d065a5ad7&vjs=3
Data Engineer,Cerner Corporation,"Kansas City, MO",,"Cerner Intelligence is a new, innovative organization within Cerner focusing on creating contextual, intelligent experiences by leveraging the power of data to discover new evidence-based insights and workflow interventions that drive client value and help achieve the quadruple aim in healthcare. We seek the best and brightest talent to join the team – individuals who thrive on analytical problem solving and data-driven analysis who are smart, ambitious, and inquisitive.

As a Data Engineer, you will build and automate scalable components within Cerner’s machine learning ecosystem that manage the flow of data, features, and predictions—in real-time and batch—as well as components related to the operations of the overall prediction model lifecycle.
Back to Description
Cerner Technical Jobs and Careers

Client Services
Working directly with our clients is one of the most impactful careers you will find. Whether your background is in health care, business or technology you can help transform the quality of care for all of us.
Qualifications
Basic Qualifications:

Bachelors degree in Computer Science, Computer Engineering or Information Systems or related field, or equivalent relevant work experience
3 years of Software engineering work experience
1 year of Big data or cloud technology work experience including data analysis, data ingestion, data modeling and/or machine learning

Expectations:

Must be currently residing in or willing to relocate to the Kansas City metro area
Willing to work additional or irregular hours as needed and allowed by local regulations
Work in accordance with corporate and organizational security policies and procedures, understand personal role in safeguarding corporate and client assets, and take appropriate action to prevent and report any compromises of security within scope of position
Additional Information

Applicants for U.S. based positions with Cerner Corporation must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire. Visa sponsorship may be available for this position.

Some Cerner positions may be obligated to comply with client-facing requirements and occupational health requests, including but not limited to, an immunization set, an annual flu shot, an annual TB screen, an updated background check, and/or an updated drug screen.
Relocation Assistance Available for this Job:
Yes - Domestic/Regional
Virtual Eligible Job
No
Cerner is a place where people are encouraged to innovate with confidence and focus on what is important – people’s health and the care they receive. We are transforming health care by developing tools and technologies that make it more efficient for care providers and patients to navigate the complexity of our health. From single offices to entire countries, Cerner solutions are licensed at more than 25,000 facilities in over 35 countries.

Cerner’s policy is to provide equal opportunity to all people without regard to race, color, religion, national origin, ancestry, marital status, veteran status, age, disability, pregnancy, genetic information, citizenship status, sex, sexual orientation, gender identity or any other legally protected category. Cerner is proud to be a drug-free workplace.",http://www.indeed.com/rc/clk?jk=bf4d34c2952b4535&fccid=95fa2b94b684ec6b&vjs=3
RCT Data Engineer,First Republic Bank,"San Francisco, CA 94111",,"Â :
Overview:
At First Republic, we care about our people. Founded in 1985, we offer extraordinary client service in private banking, private business banking and private wealth management. We believe that personal connections are everything and our success is driven by the relationships we form with our colleagues and clients. You’ll always feel empowered and valued here.

Incredible teams doing exceptional work, every day
In Technology, we support First Republic’s employees and clients through the acquisition, integration and management of the Bank’s information technology systems and services. We drive innovation and explore emerging technologies so our people can be productive and focus on what matters most – providing extraordinary service.

As a Data Engineer in Regulatory and Corporate technology you will be responsible for designing data model working with data architects. Involved in data pipeline development leveraging various methodology. Help modernize the current technology stack to be more cloud native with higher focus around data quality and security.
Â :
What you’ll do as a RCT Data Engineer:
Design, develop and maintain various data model for regulatory and compliance domain.
Develop Pipelines, ensuring the best practice are implemented for data governance, data quality, data lineage and data cleansing.
Perform detailed analysis to troubleshoot and resolve identified issues and maintain data integrity.
Responsible for driving and managing data source integration between various vendor systems.
Â :
You could be a great fit if you have:
Hands-On experience with in data modeling, data visualization, pipeline design and development.
Experience with both SQL and NoSQL as well as their relevant data modeling patterns.
Demonstrated experience working in large-scale data environments which included real-time and batch processing requirements.
Strong skills in python and knowledge of various frameworks like pandas, pyspark.
Experience in building cloud native data lakes, pipelines and stream processing.
Familiar with Data Virtualization concepts ideally with Denodo/Composite experience.
Experience with cloud services preferably AWS and Snowflake.
Background in data science, analytics or data mining.
Experience in DevSecOps and automation using CICD tools and process.
Proven history of learning and implementing new technology in fast moving environment.

Job demands:
Must be able to review and analyze data reports and manuals; must be computer proficient.
Must be able to communicate effectively via telephone and in person.

Own your work and your career — apply now
Are you willing to go the extra mile because you love what you do and how you can contribute as a team? Do you want the freedom to grow and the opportunity to take charge of your own career? If so, then come join us.

We want hard working team players. You’ll have the independence to learn, lead and drive change. A culture of extraordinary service, empowerment and stability — that’s the First Republic way.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records, to the extent consistent with applicable federal and/or state law.",http://www.indeed.com/rc/clk?jk=fe94ca917afce6ce&fccid=e228a3c78d0f7f13&vjs=3
Data Engineer - Data,Slack,"San Francisco, CA",,"Slack is looking for a data engineer to join our Data Modeling & Architecture team. In this role, you will be working cross-functionally with business domain experts, analytics, and engineering teams to design and implement our Data Warehouse model. You will design, implement and scale data pipelines that transform billions of records into actionable data models that enable data insights.

You will work on initiatives to formalize data governance and management practices, rationalize our information lifecycle and key company metrics. You will provide hands-on technical support to build trusted and reliable metrics.

You have strong technical skills, you are comfortable contributing to a nascent data ecosystem, and you can build a strong data foundation for the company. You are a self-starter, detail and quality oriented, and passionate about having a huge impact at Slack.

What you will be doing
You'll translate business requirements into data models that are easy to understand and used by different disciplines across the company
You'll design, implement and build pipelines that deliver data with measurable quality under the SLA
You'll partner with business domain experts, data analysts and engineering teams to build foundational data sets that are trusted, well understood, aligned with business strategy and enable self-service
You'll be a champion of the overall strategy for data governance, security, privacy, quality and retention that will satisfy business policies and requirements
You'll own and document foundational company metrics with a clear definition and data lineage
You'll identify, document and promote best practices
What you should have
You have 2+ years of data engineering experience in the industry working in data architecture, data modeling, master data management, metadata management
You have recent accomplishments working with relational as well as NoSQL data stores, methods and approaches (logging, columnar, star and snowflake, dimensional modeling)
You have a proven track record in scaling and optimizing schemas, performance tuning SQL and ETL pipelines in OLAP and Data Warehouse environments
You have demonstrated skills with either Python or Java programming language
You are familiar with data governance frameworks, SDLC, and Agile methodology
You have excellent written and verbal communication and interpersonal skills, and ability to effectively collaborate with technical and business partners
You have hands-on experience with Big Data technologies (e.g Hadoop, Hive, Spark) is a big plus
You have a bachelor's degree in Computer Science, Engineering or a related field, or equivalent training, fellowship, or work experience

Slack has a positive, diverse, and supportive culture—we look for people who are curious, inventive, and work to be a little better every single day. In our work together we aim to be smart, humble, hardworking and, above all, collaborative. If this sounds like a good fit for you, why not say hello?

Slack is registered as an employer in many, but not all, states. If you are not located in or able to work from a state where Slack is registered, you will not be eligible for employment.
Slack is an Equal Opportunity Employer and participant in the U.S. Federal E-Verify program. Women, minorities, individuals with disabilities and protected veterans are encouraged to apply. Slack will consider qualified applicants with criminal histories in a manner consistent with the San Francisco Fair Chance Ordinance.

Slack is a layer of the business technology stack that brings together people, data, and applications – a single place where people can effectively work together, find important information, and access hundreds of thousands of critical applications and services to do their best work. From global Fortune 100 companies to corner markets, businesses and teams of all kinds use Slack to bring the right people together with all the right information. Slack is headquartered in San Francisco, CA and has offices around the world. For more information on how Slack makes teams better connected, visit slack.com.
Ensuring a diverse and inclusive workplace where we learn from each other is core to Slack’s values. We welcome people of different backgrounds, experiences, abilities and perspectives. We are an equal opportunity employer and a pleasant and supportive place to work.
Come do the best work of your life here at Slack.",http://www.indeed.com/rc/clk?jk=691c4b617fa6da3f&fccid=8d0ce3817d129779&vjs=3
Data Engineer,Modern Health,"San Francisco, CA 94111",,"Modern Health-

Modern Health is a mental health benefits platform for employers. We are the first solution to cover the full spectrum of mental well-being needs through both evidence-based technology and professional support from a certified coach or therapist. Whether someone wants to proactively manage stress or treat depression, Modern Health guides people to the right care at the right time. We empower companies to help all of their employees be the best version of themselves, and believe in meeting people wherever they are in their mental health journey.

We are a female-founded company, backed by investors like Kleiner Perkins, Founders Fund, John Doerr, and Y Combinator, and partner with companies like Pixar, Gusto, Okta, EA, and Nextdoor that are taking a proactive approach to mental health care for their employees. Modern Health has raised more than $42 million and is looking for driven, creative, and passionate individuals to join in our mission.

An inclusive and diverse culture are key components of mental well-being in the workplace, and that starts with how we build our own team. If you're excited about this role, we'd love to hear from you!

The Role-

Using data to make informed decisions is a strategic imperative and competitive advantage for Modern Health. As a Data Engineer, your role is integral in ensuring we have the infrastructure and systems in place to make this possible across the company. You will own our data pipelining end-to-end and work cross-functionally to help us achieve our goals. The ideal candidate should be comfortable using Looker, SQL, Postgres, AWS (RDS, ECS, EC2), and Terraform.

What You'll Do-
Partner with people across the company (PM, engineering, data analysts, operations, care, customer success) to understand data needs and pain points.
Build systems, tools, and documentation to enable and empower data customers from around the company to confidently build accurate dashboards, run data research projects, instrument features, and support outcome studies.
Define and iterate on our data models and pipelining to best support engineering, product, and business goals.
Own data integrity for our key product and company health KPIs.
Experience using SQL to explore data and build dashboards.
Who You Are-
Experience in ETL design and implementation.
Experience in data modeling and schema design.
You are a self-starter and see projects through from inception to completion with minimal oversight.
You have experience working cross-functionally and partnering with stakeholders across departments of varying levels.
You care deeply about product experience and quality.
Health tech experience is preferred, but not required.
Bonus points if you have experience with AWS.
Benefits-
100% coverage for Medical / Dental / Vision
Stipend towards mental health benefits
401k plan
Flexible PTO
Passionate team dedicated to making a positive impact
Awesome office with snacks and catered lunch in the Financial District
Generous parental leave policy
Unlimited career growth opportunity",http://www.indeed.com/rc/clk?jk=6cfd070eca173029&fccid=f5f38e6ca00f718e&vjs=3
,,,,,http://www.indeed.com/rc/clk?jk=6c2348d4bc194bf5&fccid=4ad99f4742c25b6e&vjs=3
Data Engineer I,Blue Cross and Blue Shield of Kansas City,"Kansas City, MO",,"Are you interested in learning about healthcare professions and the latest healthcare innovations in the KC area? Become part of an organization that is dedicated to making a difference in both your career and community.

Job Description Summary :
The Data Engineer I works collaboratively to mine and evaluate internal and external data to create insights, solutions, and visualizations for strategic Blue KC analytical priorities. This individual will develop a deep understanding of analytical technologies in order to enable Blue KC to create valuable models and insights for both internal and external stakeholders.
Job Description
Build and maintain an enterprise data ecosystem including ingestion, storage, organization, and interface
Ensures quality and accuracy of data used by performing data quality measurement and analysis.
Works closely with, architects, DBA's. Solution Designer and Software engineers to ensure that we produce high-quality code and infrastructure.
Maintains the high quality of our data pipelines in production, ensuring data quality and performance.
Stays current with rapidly developing data technologies and tools.
Research emerging data technology, applications, and integration frameworks to continuously improve the data lake/warehouse platform and practices
Minimum Qualifications
Associate’s degree in Computer Science, Computer Engineering, Information Systems, or related field, or an equivalent combination of education, training, and experience.
Experience in programming languages such as Java/C++ and Python
Strong SQL skills.
Experience implementing data pipelines via methods such as ETL, ELT, EL/TL, Data Lake, or ODS or data warehouse
Understanding of DLM and Enterprise Platforms for managing data movement.
Preferred Qualifications
Bachelor’s degree in Computer Science, Computer Engineering, Information Systems, or related field.
1-3 years’ experience as a Data Engineer with hand-on implementing data pipeline . .
Experience in a Scrum and Agile development practice environment.
Experience designing, deploying, and supporting production cloud services in Microsoft Azure
1-3 years of Messaging/integration with tools such as Event Hub / Kafka
Basic understanding of insurance industry (including claims processes, how attribution works, and the core business concepts of insurance).
he core business concepts of insurance).",http://www.indeed.com/rc/clk?jk=8affc30833274db0&fccid=a1208edcf19bb616&vjs=3
Data Engineer SAS,"TalentMovers, Inc.","San Jose, CA",,"Position: SAS Data Engineer
Location: Mountain View, CA
Duration : 24 months
Project
The SBSEG Marketing Data Operations team uses SAS to manage a variety of data processes to support the business. These processes include SAS extracts and macros to streamline data extractions from various data warehouses for the team to easily obtain data for marketing use. There is an initiative to move away from SAS and use alternate industry standard methods to extract and house the data. We looking for a technical expert to help understand these processes and rebuild/rewrite the SAS programs using SQL (AWS EMR Hive).
Responsibilities
Partner with members of the team to develop a deep understanding of what & how data is used
Collaborate with others in building innovative data capture and real-time customer data analytic capabilities needed by the business (e.g. requirements identification, design specification, prototype testing)
Work side-by-side with cross-functional team including other members of the SAS community, SBSEG Analytics, and partner DBAs to develop the most optimal data experience.
Rewrite/rebuild processes existing in SAS using SQL (AWS EMR Hive)
Solid communication skills: Demonstrated ability to explain complex technical issues to both technical and non-technical audiences
Educates and provides guidance to business stakeholders on how best to harness available data in support of business needs, makes recommendations, and provides alternatives to meet business needs
Creates complex software programs and applications for management of massive quantities of data (big data) using high level programming languages
Develop and test automated data extractions and data feeds to our e-mail vendors in support of trigger-based e-mail marketing campaigns.
Develop and test ad hoc data extraction queries in support of one-time e-mail marketing campaigns and market research requests.
Automate repeat data requests to create sustainability and efficiencies
Extract and aggregate data for business analysts to enable measurement of key performance indicators.
Ensure all automated data routines run as scheduled with expected results and troubleshoot as necessary when outages occur.
Partner with cross-functional data teams to identify and implement new data capture and aggregation mechanisms to enable more efficient data processing.
Partner with immediate team to improve process, documentation, and data ingestion tools.
Qualifications
5+ years relevant experience
Advanced SQL skills to get the data you need from a warehouse (Vertica, Hive, SparkSQL, etc)
Advanced SAS skills
Experience with AWS EMR
Strong ETL experience
Experience using Github and Tidal
Ability to Clean/transform data from raw data inputs
Ability to deep dive into the data to meet stakeholders requirements Outstanding communication skills with the ability to influence decision makers and build consensus with teams
Development and execution of data movement tools using scripts in languages such as SQL, HQL, SAS
Familiar with Software engineering and programming methodologies (e.g., Agile)
Familiar with Vertica environment
Proficient in Microsoft Excel
Strong communications skills with both technical and non-technical audiences
Strong time and project management skills
Ability to prioritize own workload
Ability to work in a fast paced environment with changing priorities
Experience with Alteryx a plus
Experience with marketing automation email systems such Eloqua, Pardot, etc., a plus
BS, MS, or PhD (or equivalent experience) in an appropriate technology field (Computer Science, Statistics, Applied Math, Operations Research).
Thanks
Sid
703-349-5365
sid@talentmoversinc.com
for more positions please visit our website
www.talentmoversinc.com",http://www.indeed.com/rc/clk?jk=327a2944b9ad4a22&fccid=01267275e4614eb0&vjs=3
Data Engineer,Persivia,"Marlborough, MA 01752",,"Position Title: Data Engineer - Although desired to be on location in the Greater Worcester area, we are accepting applications for candidates that would be able to travel into the Marlborough office on a weekly or even monthly basis

Persivia is seeking Data Engineer who will help support our customer base as well as our development team. This position requires extracting data from Meditech, Mckesson, Epic and other hospital systems. Meditech experience desired. Proven Experience with extracting data from Meditech or other hospital systems is necessary. The qualified candidate will be a Data specialist who exhibits expertise in extracting data from Meditech, and possess strong knowledge focus on data extracts for a Quality Reporting perspective.


Key Activities:


Perform System setup and extraction of medical data from hospital’s databases.

Maintain XSLT, SQL, and Java scripts for mass loading and rendering of XML files.

Perform coding tasks using C#, .Net and SQL, Java.


Required Skills:


Experience working with hospital EMRs such as Meditech, McKesson, Epic and Cerner or with Ambulatory EMRs such as eClinicalWorks, Aprima, NextGen, PracticeFusion and Elation.

Expertise in extracting data from multiple hospital systems.

Ability to maintain and execute XSLT, SQL and Java scripts for batch loading and rendering of XML files.

Hands-on experience working with HL7 (V3 preferred), XML, and web services.

Knowledge of relation databases (SQL Server, Oracle) a huge plus .

Experience working in Java, C#, .Net and MS-SQL.

Bachelor’s degree in Computer Science, technical field, or equivalent experience.

Minimum 4 years of relevant work experience.",http://www.indeed.com/rc/clk?jk=0e1f9fed55d9f299&fccid=a3a0d94f41086ccf&vjs=3
BI Analytics Engineer,Credible,"San Francisco, CA",,"Who is Credible?

We believe life's changes create financial needs for people and that the traditional financial system often puts up unnecessary obstacles. People celebrate major milestones like going to college, getting married, and buying a home. And most of the time, these milestones come with financial implications.

At Credible, we have built a company with the mission of bringing transparency, choice, simple processes and savings to accessing credit for life's important moments. What you see is what you get. We are committed to being upfront, honest, and clear about your options. There are no mysteries, no hidden fees, and no secret clauses.

Credible is a fast-growing Fintech company that has world class management, has raised multiple rounds of funding, is generating significant revenue and is disrupting the lending market and helping people save money and get out of debt faster.

About the role

Our Business Intelligence team is looking for a BI Analytics Engineer who is passionate about data, analytics, and business strategy. You will help the team learn more about our business, teach others in the company about analytics, and improve the use of our data. You'll be an integral part of providing data-driven insights that inform significant company decisions.

You Will:

Build data pipelines and python-based ETL tools for getting, processing, and delivering data
Develop data models and schemas in our data warehouse that enable performant, intuitive analysis
Partner with teams across the organization to understand their analytics needs and create dashboards and reporting that allow them to execute more effectively
Work with business leaders to define key metrics and build reporting to monitor and understand performance along those metrics
Conduct in-depth data analyses that lead to actionable insights, owning the entire process from ideation to execution to presentation of findings to stakeholders
Become an expert on all aspects of Credible's data and analytics infrastructure
Be the driving force behind the adoption and effective use of our BI tool within every team at Credible

Education and Experience:

BA/BS in a quantitative field
1-3 years of work experience as a data analyst, data engineer, or in a highly analytical role
Experience writing SQL queries and using a BI tool
Experience with a scripting language (preferably Python) for data processing and analysis a plus
Experience using the command line and git
Strong grasp of statistics and experience conducting rigorous data analyses
Experience developing models and visualizations in Looker a plus
Experience at an e-commerce or fintech company a plus

 Personality and Values:

The capacity to juggle multiple priorities effectively within a fast-paced environment is critical
You're a highly motivated self-starter with the ability to work efficiently with minimal supervision.
Anticipate business needs and think with a business owner mindset – think critically about analyses, don't just complete them
Passion for spreading the value of data throughout the company and communicating insights to a broad audience with varying levels of technical expertise

Why work at Credible

We are a fast moving, fun-loving, seriously smart group of people who really care about impacting the lives of our customers. We empower our employees to make decisions, take risks, drive our business and make changes when we don't get it right. These are our values:

Exceed Customer Expectations: We provide an exceptional experience to each and every customer that compels them to share it with others.
Take Ownership: We are trusted to make decisions that are in the best interests of our customers and our business. We think and act like owners. We care – and that makes all the difference.
Be Curious: We are curious, ask questions, seek to understand and try new things.
Do the Right Thing: We earn trust by being transparent, respectful and honest with each person with whom we interact.
Get Results: Results fuel our excitement and we know how our personal accomplishments tie to the success of the company.
Be Bold: We are courageous and take risks that scare us. Our enthusiasm for experimenting is how we will find the next breakthrough.

Our benefits: We offer competitive compensation, generous benefits, free food and a flexible vacation policy.

But mainly, you want to work at Credible because you believe in our mission and want to have a major role in delivering on it! We look forward to getting to know you.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.",http://www.indeed.com/rc/clk?jk=fa093cb842309012&fccid=04e8134694cdee5a&vjs=3
Data Engineer,Auth0,Argentina,,"Auth0 is a pre-IPO unicorn. We are growing rapidly and looking for exceptional new team members to add to our teams and will help take us to the next level. One team, one score.

We never compromise on identity. You should never compromise yours either. We want you to bring your whole self to Auth0. If you’re passionate, practice radical transparency to build trust and respect, and thrive when you’re collaborating, experimenting and learning – this may be your ideal work environment. We are looking for team members that want to help us build upon what we have accomplished so far and make it better every day. N+1 > N.

The Data engineer will help build, scale and maintain the entire data platform. The ideal candidate will have a deep technical understanding, hands-on experience in distributed computing, big data, ETL, dimensional modeling , columnar databases and data visualization. The candidate should feed on challenges and love to be hands on with recent technologies.

This job plays a key role in data infrastructure, analytics projects, and systems design and development. You should be passionate for continuous learning, experimenting, applying and contributing towards cutting edge open source Data technologies and software paradigms.
Responsibilities:
Contributing at a senior-level to the data platform design by implementing a solid, robust, extensible design that supports key business flows.
Performing all of the necessary data transformations to populate data lake.
Establishing efficient design and programming patterns that beat SLAs and help easily manage the data platform.
Designing, integrating and documenting technical components for seamless data extraction and analysis.
Adopting best practices in our data systems and shared across teams.
Contributing to innovations and data insights that fuel Auth0’s mission.
Working in a team environment, interacting with multiple groups on a daily basis (very strong communication skills).
Skills and Abilities:
+ BA/BS in Computer Science, related technical field or equivalent practical experience.
At least 3 years of relevant work experience
Ability to write, analyze, and debug SQL queries.
Exceptional Problem solving and analytical skills.
Experience with Data Warehouse design, ETL (Extraction, Transformation & Load), architecting efficient software designs for DW platform.
Hands-on experience in Python, R, Apache Spark in production environments.
Strong skills in Apache Airflow, Luigi or similar tools.
Experience in Tableau, Apache SuperSet, Looker or similar BI tools.
Knowledge of AWS Redshift, Snowflake or similar databases
Preferred Locations:
#AR;
Auth0’s mission is to help developers innovate faster. Every company is becoming a software company and developers are at the center of this shift. They need better tools and building blocks so they can stay focused on innovating. One of these building blocks is identity: authentication and authorization. That’s what we do. Our platform handles 2.5B logins per month for thousands of customers around the world. From indie makers to Fortune 500 companies, we can handle any use case.

We like to think that we are helping make the internet safer. We have raised $210M to date and are growing quickly. Our team is spread across more than 35 countries and we are proud to continually be recognized as a great place to work. Culture is critical to us, and we are transparent about our vision and principles.

Join us on this journey to make developers more productive while making the internet safer!",http://www.indeed.com/rc/clk?jk=a8bbd0f9fc437357&fccid=9bafb2a1aee32e86&vjs=3
Data Engineer,Kroger General Office,"Blue Ash, OH 45242",,"Company Name: Kroger General Office
Position Type: Employee
FLSA Status: 87
Line of Business: Technology Strategy & Architecture
See what life is like at Kroger Technology
at https://www.kroger.com/livekt

Additional Technology Information:
The Systems Integration Solutions (SIS) team within Kroger Technology is looking for highly technical and progressive thinking Data Engineers to support both the operations of The Kroger Co and its forward-thinking Data Strategy organization. The Data Engineer position entails building strong relationships with business partners and other Kroger Technology teams while delivering sustainable solutions.The SIS team develops solutions leveraging a broad selection of technologies centered around Informatica and Microsoft Azure delivery platforms. Deep understanding of data integration and ETL tools is required. Experience with cloud or big data solutions is desired.The SIS team utilizes the following technologies:• Informatica (PowerCenter, IICS, Edge, EDC, IDQ)• Microsoft Azure (Data Factory, ADLS, SQL Data Warehouse)• AIX/Unix and Linux• Korn Shell Scripting• Tivoli Workload Scheduler (TWS)• Databases (DB2, Oracle, SQL Server, Netezza, Cassandra)• Connect Direct and MQFTE• SQL Scripting/Stored Procedures

Position Summary

Accountable for developing and delivering technological responses to targeted business outcomes. Analyze, design and develop enterprise data and information architecture deliverables, focusing on data as an asset for the enterprise. Understand and follow reusable standards, design patterns, guidelines, and configurations to deliver valuable data and information across the enterprise, including direct collaboration with 84.51, where needed. Demonstrate the companys core values of respect, honesty, integrity, diversity, inclusion and safety.
Essential Job Functions
Draft architectural diagrams, interface specifications and other design documents
Promote the reuse of data assets, including the management of the data catalog for reference
Analyze technology environments to detect critical deficiencies and recommend solutions for improvement
Contribute to the development of cost/benefit analysis for leadership to shape sound architectural decisions
Define high-level migration plans to address the gaps between the current and future state
Leverage innovative new technologies and approaches to renovate, extend, and transform the existing core data assets, including SQL-based, NoSQL-based, and Cloud-based data platforms
Ensure there is clarity between ongoing projects, escalating when necessary, including direct collaboration with 84.51
Leverage enterprise standards for data domains and data solutions, focusing on simplified integration and streamlined operational and analytical uses
Minimum Position Qualifications
4 years successful and applicable hands on experience in the data development and principles including end-to-end design patterns
4 years proven track record of delivering large scale, high quality operational or analytical data systems
4 years of successful and applicable experience building complex data solutions that have been successfully delivered to customers
Experience in two of the following technical disciplines: data warehousing, big data management, analytics development, data science, application programming interfaces (APIs), data integration, cloud, servers and storage, and database management
Excellent oral and written communication skills
Desired Previous Experience/Education
Any experience building solutions using elastic architectures (preferably Microsoft Azure and Google Cloud Platform)
Any direct experience with a variety of SQL, NoSQL and Big Data Platforms
Any direct experience with data science solutions or platforms
Bachelor's Degree in Computer Science or in a STEM major
Education Level: None
Required Certifications/Licenses: None
Position Type: Full-Time
Shift(s): [[mfield4]]
States: Indiana; Kentucky; Ohio",http://www.indeed.com/rc/clk?jk=9b4c5f3105d0ce96&fccid=50996180ba6219c2&vjs=3
Data Engineer,Coalition,"San Francisco, CA",,"About Us
Coalition is the leading provider of cyber insurance and security, combining comprehensive insurance and proactive cybersecurity tools to help businesses manage and mitigate cyber risk. Coalition’s unique product offerings combine best-in-class insurance and proactive cybersecurity tools to help keep businesses safe. Cyber losses cost the global economy upwards of $1.5 trillion each year, and yet the majority of businesses are under-insured and under-prepared to manage and mitigate the risks of an increasingly digital world. Coalition is addressing this gap by providing no-cost cybersecurity tools to prevent losses, security and incident response services to contain them, and comprehensive cyber insurance to help organizations recover. We have over 25,000 customers, ranging from small and mid-sized businesses to Fortune 500 companies.
Founded in 2017, Coalition has raised $125M from a number of top tier global investment firms including Ribbit Capital, Greenoaks Capital, Valor Equity Partners, Felicis Ventures, and Vy Capital. Headquartered in San Francisco, Coalition’s team is distributed across more than 15 locations globally, including Austin, Washington DC, Denver, Canada and Portugal.
About the role
The Coalition engineering team is growing rapidly, and we are looking for Data Engineers to work with the various data sources utilized in our business. The ideal candidate would have experience working with data engineering, data analysis, and statistical modeling, in the development of a real-time service. They would have experience working with structured and unstructured data systems, optimizing performance across large, disparate data sets, and streaming data systems. They would be a proficient developer who can deliver production-quality implementations.
This is a versatile role that will touch many aspects of data at Coalition, including network security data, actuarial data, and growth analytics data.
Responsibilities
Implement risk models for various insurance products
Evaluate, recommend, and implement data pipelines for a variety of data sources used at Coalition
Deliver production-quality software implementations for ETL and streaming pipelines
Explore new data sources and develop insights into existing data sources that improve business efficiency
Requirements
3+ years working with large disparate data sets
Deep understanding of ETL pipelines, statistical modeling, data analytics, and large scale data streaming
Expert-level knowledge of SQL, Python, R, or similar language used for data engineering
A proven track record of successfully automating business value from data insights
Experience with at least one big data search tool, such as Elastic
Excellent oral and written communications skills at all levels
Bachelor’s degree in Computer Science or a related field preferred
Bonus Points
Prior experience with insurance or network security technologies
In-depth knowledge of AWS or other cloud-hosted platforms relevant to data engineering
Experience with data visualization technologies
Perks
We have lots of them. Check them out at https://www.thecoalition.com/careers
Location
We are a semi-distributed team headquartered in San Francisco. This position will be in the San Francisco office.

Coalition is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.
Coalition is a security company. A successful background check is required for employment.",http://www.indeed.com/rc/clk?jk=b444fa78bf26ddf2&fccid=defc7c48ca50d393&vjs=3
Data Engineer ZCH8509,Zar Technology Services,"Newark, NJ",,"Title: Data Engineer
Location: Newark, NJ
Duration: 6 Months

Description:
We are seeking a highly talented Data Engineer (DE) within the Data Engineering group. We need your help to build systems to enable data-driven decision-making.

Our Data Engineering team owns and develops the technology platform that offers decision makers both performance metrics and analysis as well as the self-service capability to perform independent analysis on a wide array of internal and external datasets in order to identify opportunities, trends and issues, uncover new insights, and fine-tune operations to meet business goals.

Responsibilities:
Build and maintain the infrastructure to answer questions with data, using software engineering best practices, data management fundamentals, data storage principles, recent advances in distributed systems, and operational excellence best practices.
Work closely with stakeholders to understand their requirements and design the right solution
Work closely with other teams, analyze source systems, define underlying data sources and transformation requirements, design suitable data models and document the design/specifications.
Build/maintain systems and datasets that analysts and scientists use to generate actionable insights.
Demonstrate passion for quality and productivity by use of efficient development techniques, standards and guidelines
Peer reviews of work. Actively mentor more junior members of the team, improving their skills, their knowledge of our systems and their ability to get things done


Basic qualifications
Strong Computer science background required. A Bachelor's degree or higher in computer science or equivalent is required
10+ years of experience in a Data Warehouse (DWH) environment with data integration/ETL of large and complex data sets
Design and coding skills in a scripting language (e.g. Python/Perl/shell scripting) on Unix/Linux Platforms.
Proficiency in SQL and database technologies such as AWS Redshift
Data modeling skills such as Star/Snowflake schema design for DWH
Expertise in performance tuning and scaling in a DWH environment
Hands on experience with recent advances in distributed computing such as MapReduce, MPP architectures, NoSQL databases.
Familiarity with Business Intelligence (BI) platforms such as MicroStrategy, OBIEE or equivalent
Good interpersonal and communication skills. Ability to work with different teams for sourcing of data.
Ability to learn fast, work independently with little supervision and deliver on time quality products


Preferred qualifications
Extensive knowledge of BI platforms such as MicroStrategy, OBIEE or equivalent
Experience working with Agile methodologies in a DWH/BI environment",http://www.indeed.com/rc/clk?jk=48b76f35afbde2b1&fccid=07b2111b84e64498&vjs=3
Data Engineer,Larsen & Toubro Infotech Limited,"New York, NY",,"Data Engineer – • Must be able to do ETL (SSIS, Azure Data Factory, Informatica) • Hands-on experience in Azure Data Factory, Informatica and good understanding on data obfuscation or data masking techniques • Design, construct, install, test and maintain highly scalable data management systems • Build automated data delivery pipelines and services to integrate data • Build and deliver cloud-based deployment and monitoring capabilities consistent with DevOps models • Develop solutions in agile environment for the overall data domain • Deep experience with developing SQL • Must have Deep experience developing with MS SQL • Understand Data Security",http://www.indeed.com/rc/clk?jk=ae6c8676690cb0af&fccid=b5f9e2f53707b441&vjs=3
Data Engineer,Apple,"Austin, TX",,"Summary
Posted: Mar 10, 2020
Weekly Hours: 40
Role Number:200157377
At Apple, excellent ideas have a way of becoming extraordinary products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish. Would you like to work in a fast-paced environment where your technical abilities will be challenged on a day-to-day basis? If so, Apple's Global Business Intelligence (GBI) team is seeking a hardworking Data Engineer to build high quality, scalable and resilient distributed systems that power apple's analytics platform and data pipelines.
Apple's Enterprise Data warehouse system cater to a wide variety of real-time, near real-time and batch analytical solutions. These solutions are integral part of business functions like Sales, Operations, Finance, AppleCare, Marketing and Internet services enabling business drivers to make critical decisions. We use a diverse technology stack such as Teradata, HANA, Vertica, Hadoop, Kafka, Spark, and Cassandra and beyond. Designing, Developing and scaling these Big Data technologies are a core part of our daily job. The team member will be able think outside of the box and should have passion for building analytics solutions to enable business in making time sensitive and critical decisions.
Key Qualifications
We would like for you to have In-depth understanding of data structures and algorithms
We are looking for experience in designing and building dimensional data models to improve accessibility, efficiency, and quality of data
Database development experience with Relational or MPP/distributed systems such as Oracle/Teradata/Vertica/Hadoop
We are seeking programming experience in building high quality software in Java, Python or Scala preferred
Experience in designing and developing ETL data pipelines. Should be proficient in writing Advanced SQLs, Expertise in performance tuning of SQLs
You will demonstrate excellent understanding of development processes and agile methodologies
Strong analytical and interpersonal skills
Enthusiastic, highly motivated and ability to learn quick
Experience with or advance courses on data science and machine learning is ideal
Work/project experience with Big Data and advanced programming languages is a plus
Experience developing Big Data/Hadoop applications using java, Spark, Hive, Oozie, Kafka, and Map Reduce is a huge plus
Description
You will build and design data structures on MPP platform like Teradata, Hadoop to provide efficient reporting and analytics capability.
Design and build highly scalable data pipelines using new generation tools and technologies like Spark, Kafka to induct data from various systems.
Translate complex business requirements into scalable technical solutions meeting data warehousing design standards.
Strong understanding of analytics needs and proactive-ness to build generic solutions to improve the efficiency.
Build dashboards using Self-Service tools like Tableau and perform data analysis to support business.
Collaborate with multiple multi-functional teams and work on solutions which has larger impact on Apple business.
We seek a self starter, forward-thinking person with strong leadership capabilities.
Ability to communicate effectively, both written and verbal, with technical and non-technical multi-functional teams.
You will interact with many other group’s internal team to lead and deliver elite products in an exciting rapidly changing environment.
Education & Experience
Bachelors Degree",http://www.indeed.com/rc/clk?jk=6af7177108806203&fccid=c1099851e9794854&vjs=3
Data Engineer,Capital One - US,"McLean, VA",,"7900 Westpark Drive (12131), United States of America, McLean, Virginia
At Capital One, we’re building a leading information-based technology company. Still founder-led by Chairman and Chief Executive Officer Richard Fairbank, Capital One is on a mission to help our customers succeed by bringing ingenuity, simplicity, and humanity to banking. We measure our efforts by the success our customers enjoy and the advocacy they exhibit. We are succeeding because they are succeeding.

Guided by our shared values, we thrive in an environment where collaboration and openness are valued. We believe that innovation is powered by perspective and that teamwork and respect for each other lead to superior results. We elevate each other and obsess about doing the right thing. Our associates serve with humility and a deep respect for their responsibility in helping our customers achieve their goals and realize their dreams. Together, we are on a quest to change banking for good.
Data Engineer
What you’ll do:
Develop new ways to analyze and deliver experimentation on our site
Discover, ingest, and incorporate new sources of streaming, batch, and API-based data into our platform to enhance the insights we get from running tests and expand the ways and properties on which we can test
Help the team improve with the usage of data engineering best practices
Experiment with new tools to streamline the development, testing, deployment, and running of our pipelines
Learn and share by attending conferences and meetups
Collaborate with other data engineering teams to improve the data engineering ecosystem and talent within Capital One
Creatively solve problems when facing constraints, whether it is the number of developers, quality or quantity of data, compute power, storage capacity or just time
Some things that gets us excited:
Someone who has a good software engineering background and has some experience dealing with large datasets
Someone who understands some constraints working with data
Someone who has shown consistent growth in abilities and responsibilities
Someone who has learned about or used tools and techniques to process large datasets efficiently and is keen to continue learning
Someone who has been able to use various languages and platforms to get things done
Basic Qualifications:
Bachelor’s Degree
At least 2 years of experience in Data Engineering and object-oriented programming
At least 3 years of experience in using Git or another code version control system amongst multiple contributors
At least 3 years of professional experience working on data ETL pipelines that include stream processing interfaces with either Python, Apache Spark, Flink, Storm, or Kafka
At least three years of experience modeling and developing data warehousing applications using Snowflake Analytics, Presto, AWS Athena, or AWS Redshift
At least 1 year of experience in AWS, Azure, or GPC
Preferred Qualifications:
Bachelor’s Degree in Computer Science or related technical discipline
At least 5 years of professional programming experience in Python
3+ years of experience working within AWS
5+ years of experience contributing to open-source projects
5+ years of experience in working with creating and managing data ETL pipelines, including data collection, processing, correlation, transformation, and validation
3+ years of experience configuring and managing Oracle and Postgres databases
1+ years of experience working with data workflow tools such as NiFi, Luigi, or Airflow
1+ years of experience EMR, Spark, or Hadoop
1+ years of experience in AWS Batch or similar job-queueing system
1+ years of experience working with DevOps/monitoring tools such as Bogie, Jenkins, Enterprise ELK, Splunk, Data Dog, and Pager Duty
1+ years of experience building machine learning applications
3+ years of experience working with container runtimes (Docker, rkt, cri-o, etc.)
Experience with Change Data Capture (CDC) in various RDBMSes
AWS Certification, Hadoop/Spark Certification, or Docker Certification
At this time, Capital One will not sponsor a new applicant for employment authorization for this position.",http://www.indeed.com/rc/clk?jk=42def7e868127e0c&fccid=b85c5070c3d3d8c8&vjs=3
Data Engineer - 70182BR,AETNA,"Hartford, CT 06156",,"Description:

Participates in the design, build and management of large scale data structures and pipelines and efficient Extract/Load/Transform (ETL) workflows.
70182

Fundamental Components:

Assists in the development of large scale data structures and pipelines to organize, collect and standardize data that helps generate insights and addresses reporting needs. Applies understanding of key business drivers to accomplish own work. Uses expertise, judgment and precedents to contribute to the resolution of moderately complex problems. Leads portions of initiatives of limited scope, with guidance and direction. Writes ETL (Extract / Transform / Load) processes, designs database systems and develops tools for real-time and offline analytic processing. Collaborates with client team to transform data and integrate algorithms and models into automated processes. Uses knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries to build data pipelines. Uses programming skills in Python, Java or any of the major languages to build robust data pipelines and dynamic systems. Builds data marts and data models to support clients and other internal customers. Integrates data from a variety of sources, assuring that they adhere to data quality and accessibility standards.

Background Experience:

Strong problem solving skills and critical thinking ability.Strong collaboration and communication skills within and across teams.3 or more years of progressively complex related experience.Ability to leverage multiple tools and programming languages to analyze and manipulate data sets from disparate data sources.Ability to understand complex systems and solve challenging analytical problems.Experience with bash shell scripts, UNIX utilities & UNIX Commands.Knowledge in Java, Python, Hive, Cassandra, Pig, MySQL or NoSQL or similar.Knowledge in Hadoop architecture, HDFS commands and experience designing & optimizing queries against data in the HDFS environment.Experience building data transformation and processing solutions.Has strong knowledge of large scale search applications and building high volume data pipelines. Master’s degree or PhD preferred.Bachelor's degree or equivalent work experience in Computer Science, Engineering, Machine Learning, or related discipline.

Potential Telework Position:

No

Percent of Travel Required:

0 - 10%

EEO Statement:

Aetna is an Equal Opportunity, Affirmative Action Employer

Benefit Eligibility:

Benefit eligibility may vary by position.

Candidate Privacy Information:

Aetna takes our candidate's data privacy seriously. At no time will any Aetna recruiter or employee request any financial or personal information (Social Security Number, Credit card information for direct deposit, etc.) from you via e-mail. Any requests for information will be discussed prior and will be conducted through a secure website provided by the recruiter. Should you be asked for such information, please notify us immediately.

#LI-DT1",http://www.indeed.com/rc/clk?jk=1c32a8dc23b0a24a&fccid=7077d7e88049c02a&vjs=3
Data Engineer,W.L. Gore,"Elkton, MD 21921",,"Responsibilities
About Us: Gore is a materials science company focused on improving lives through discovery, product innovation and rewarding careers for our Associates. Learn More.
About the Industry: At Gore, our global support teams bring together extensive knowledge and collaborate closely to support our diverse portfolio of products that solve complex problems and perform in the most demanding environments. Learn more about Gore products.
About the Role: Our HR Analytics team in the US is looking for a Data Engineer who will help enable data analysis and insights on our most important asset across the Enterprise – our people. You will work with this virtual team to ensure optimal data flows across different systems and data sources to ensure easy access to the data. For the right candidate, we would also consider a remote work arrangement.
Responsibilities:
Building data models/flows and integration from different sources of people data
Preparing data to be easily accessed for visualization tools such as Cognos
Partnering with IT to design and build environments for HR Analytics team that allow for more self-service solutions
Translating reporting tool requirements to improvements in database design and data models
Using IT Analytics standard work processes (SWP) for demand requests and change management
Creating and maintaining optimal data pipeline architecture (partner with Enterprise Architecture)
Partnering with Business Analyst to build analytics tools that utilize the data pipeline to provide actionable insights into HR operations and performance metrics
Identifying, designing, and implementing internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc
Working with data and analytics experts to strive for greater functionality in our data systems
Partnering with security and data privacy as needed to secure and protect sensitive people data
Qualifications
Required Qualifications:
Minimum 5 years of experience using BI User reporting and analysis tools including Cognos OR a Bachelors or Masters’ degree in Analytics, Data Science or related field
Prior experience using business intelligence tools such as Cognos / PowerBI / Tableau
Demonstrated experience manipulating, processing and extracting value from unstructured and/or disconnected datasets
Advanced working knowledge of SQL and experience with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases
Working knowledge of Oracle and AWS data store and compute technologies such as S3, EC2, RDS, RedShift
Knowledge and experience applying ETL process and using ETL tools
Strong analytic skills with a basic understanding of analytical tools (e.g. SAS, JMP, R, Python) and modeling concepts (descriptive, diagnostic, predictive and prescriptive)
Excellent communication skills and ability to understand the end user questions and translate to appropriate data needed to answer those questions
Desired Qualifications:
Experience with Python/Jupyter notebooks and data prep tools such as Alteryx Designer or similar
Experience working with and producing analytics outcomes with IP sensitive and PII classified data
Advanced knowledge of Cognos including Report Studio, Framework Manager, Data Modules, Dashboarding
What We Offer: At Gore, we offer comprehensive, competitive rewards in the form of compensation and benefits. Among these are work-life balance and sports programs, 401(k) Plan with a gift, Associate Stock Ownership Plan, Health & Well-being program with full health plan, and a flexible working program. Within Gore, you will find a unique culture, diversity, equity, and inclusion initiatives, and opportunities for growth and development.
Learn more about: benefits, diversity, and growth & development.
We believe in the strength of a diverse workforce and inclusive work environment. In support of our values and continued success we are proud of Associates around the world who support an inclusive work environment, strive to reflect the diversity of the communities where we operate, and ensure all Associates and external partners are treated with fairness, dignity, and respect.
Gore is committed to a drug-free workplace. All employment is contingent upon successful completion of drug and background screening.
Gore requires all applicants to be eligible to work within the U.S. Gore generally will not sponsor visas unless otherwise noted on the position description.
Gore is a M/F, Disabled and Vet EEO/AA employer. (Applies to all positions in the U.S.)
gore.com/change-life
Our Talent Acquisition Team will be pleased to answer your questions via contact us.",http://www.indeed.com/rc/clk?jk=b7a128457f360459&fccid=d91ab1f015016afc&vjs=3
Data Engineer III,Inland Empire Health Plans,"Rancho Cucamonga, CA 91730",,"Position Summary/Position

Under the direction of the Data Warehouse Manager, the Data Engineer III manages the design, planning and development of Data Warehouse solutions. This role leads the ETL development, design and create procedures to acquire, harmonize, and consolidate the IEHP data assets. the Data Engineer III is expected to lead by example. The Data Engineer III leads and mentors coding activities throughout all aspects of the data warehouse function to produce efficient and high quality solutions. Major Functions (Duties and Responsibilities)

1. Design, develop and lead data warehouse Extraction, Transformation and Loading (ETL) solutions using Microsoft SQL Server Integration Services (SSIS)
2. Lead, design, develop and implement data collection processes in conjunction with the data warehouse. Source data from HSP and legacy systems supporting a centralized data warehouse and reporting platform.
3. Lead, design and implement technical solutions to meet the requirements for Data Science and Data Warehouse
4. Analyze user requirements and translate into database requirements and implement in database code
5. Manage and enforce standards on data modeling, data profiling, database design and metadata management
6. Lead and mentor tuning activities throughout all aspects of the data warehouse function to produce efficient and high quality solutions
7. Proactively design and build process to prevent potential data quality issues
8. Work closely with Data Warehouse Architect and Informatics Architect to design data and analytics solutions to increase the usability, completeness, and accuracy of enterprise data
9. Create, maintain and optimize SQL queries and routines
10. Develop, adopt, and enforce Data Warehouse and ETL standards and architecture
11. Monitor and support ETL processes ensuring integrity and proper integration of all data sources
12. Create high throughput historical and incremental ETL jobs
13. Facilitate change control, problem management, and communication among data architects, managers, informaticsts and analysts
14. Provide detailed analysis of data issues; data mapping; and the process for automation and enhancement of data quality
15. Perform development activities such as Source to target mapping validations, identify, document and execute unit test cases/scripts, peer and lead code reviews per code review checklist and document test and review results.
16. Collaborate and contribute to data integration strategies and visions
17. Ensure that all deliverables are thoroughly documented in Data Warehouse and ETL knowledge base documents
18. Provide ongoing proactive technical support for ETL and data warehouse system to ensure business continuity
19. Work with Informaticsts and Analysts to translate analytic requirements into technical solutions. Experience Qualifications

Five (5) years experience performing data warehouse development, modification and support. Three (3) years with SQL Server – SSIS. Five (5) years experience with knowledge of data warehouse technical architectures, ETL, data structures, and reporting tools and environments. Experience in code development, testing for QA, and data profiling. Must be able to perform SQL queries tuning activities. Experience in normalized, dimensional, star schema and snow flake schematic models. Experience and knowledge in logical, rational, dimensional, and physical data modeling. Experience working in a team-oriented, collaborative environment. Background in database systems. Education Qualifications

Bachelor's of Science degree from an accredited institution required. Preferred Education

Master’s of Science degree from an accredited institution preferred. Knowledge Requirement

An understanding of healthcare systems and healthcare databases desirable. Strong understanding of database structures, theories, principles, and practices. Knowledge of professional software engineering practices and best practices for the full software development life cycle (SDLC), including coding standards, code reviews, source control management, build processes, testing, and operations. Strong knowledge of SQL. Multi-server environment knowledge such as linked servers, data replication, backup/restore with MS SQL Server 2008+. Highly skilled in developing and optimizing T-SQL (DDL, DML, DCL) queries, stored procedures, functions, and views for various applications that involve numerous database tables and complex business logic. Knowledge of applicable data privacy practices and laws. Abilities Requirement

Ability to effectively prioritize and execute tasks in a high-pressure environment. Highly self motivated and directed. Keen attention to detail. Commitment to Team Culture

The IEHP Team environment requires a Team Member to participate in the IEHP Team Culture. A Team Member demonstrates support of the Culture by developing professional and effective working relationships that include elements of respect and cooperation with Team Members, Members and associates outside of our organization.

Starting Salary: $98,612.00 - $125,777.00
Pay rate will commensurate with experience

Inland Empire Health Plan (IEHP) is the largest not-for-profit Medi-Cal and Medicare health plan in the Inland Empire. We are also one of the largest employers in the region. With a provider network of more than 6,000 and a team of more than 2,000 employees, IEHP provides quality, accessible healthcare services to more than 1.2 million members. And our mission and core values help guide us in the development of innovative programs and the creation of an award winning workplace. As the healthcare landscape is transformed, we’re ready to make a difference today and in the years to come. Join our Team and Make a Difference with us! IEHP offers a Competitive salary and a benefit package with a value estimated at 35% of the annual salary, including medical, dental, vision, team bonus, and retirement plan.",http://www.indeed.com/rc/clk?jk=cafc77437aa2adf5&fccid=f23cfaf12528dbd0&vjs=3
Data Engineer,B12,New York State,,"Data Engineering at B12

B12's engineering team views software as a craft, but improving the world as the reason to practice it. Our engineers are responsible for prioritizing, conceptualizing, co-designing, building, testing, and engaging users for any concept we are building out. We're generalists in encouraging each other to experience the full stack, but we're also aware of each other's preferences in the stack. We mentor and teach where we can, both inside and outside of the company.

We value sharing our work with the outside world. Our team has published papers on forming expert flash teams and machine-mediated worker hierarchies. We've baked our research into Orchestra, the system that coordinates our expert and machine teams, and released Orchestra into open source to contribute our software back to the community.

We're looking for a Data Engineer to help us answer critical questions our business faces while improving our data systems and architecture to support greater variety, volume, and velocity of data and data sources. We hope our engineers have more longevity than any one tool we use, but here is a sampling of our current thoughts about technology:

We build our product on Python/Django and JavaScript/React.
We store blobs in Amazon's S3, munch on them in Amazon's EC2, develop in Docker, and deploy containers to Amazon's Elastic Beanstalk.
We believe Postgres should be the first system you consider when you think about persisting structured data.
We religiously clean and centralize data in Amazon's Redshift, and are able to answer most any question in SQL. We recently wrote our 1000th query in Metabase!
Before building complex statistical machine learning models, we build simple ones we can understand. Rarely, we build complex models.
We have near-full test coverage on the backend, and are making progress on our frontend and integration tests.
We set up continuous integration and deployment because, while this model comes with its own pains, we've disliked being on fixed release schedules on previous projects.
We like to move fast and support point-in-time recovery :).
As a Data Engineer, you will
Collaborate with operational teams including sales, marketing, and customer success.
Contribute to infrastructure that enables and informs B12's analytical efforts.
Write SQL queries and reusable views that enable various analyses including funnel, retention, and performance reporting.
Use Python to clean data, send it to various systems including our data warehouse and operational services, and perform feature engineering to power the creation of predictive models.
Build rules-based models and statistical machine learning models in Python using packages like scikit-learn.
You'd be a good fit if
You are fluent in SQL and Python.
You have experience building and using data infrastructure, including systems like Postgres and Redshift.
You've used reporting tools like Metabase, Tableau, or Looker in the past.
You know that no dataset is ever pristine, but love to interrogate, structure, and clean data.
You've contributed to extract-transform-load pipelines to collect data from disparate sources and centralize them in a data warehouse.
You feel comfortable managing your time and deciding amongst competing priorities.
You have worked with non-engineering teams and are comfortable explaining technical solutions to them.
You are passionate about the future of work.
You enjoy learning and teaching.
You have strong written and verbal communication skills in English.
You care about and want to contribute to our mission of helping people do meaningful work.
Don't fear
We don't have a minimum number of years of experience for this role. We highly favor talent and interest.
Some candidates may see this list and feel discouraged because they don't match all the items. Please apply anyway: there's a good chance you're more wonderful than you think you are.
B12 is a safe place for human beings. We are dedicated to building a diverse and inclusive team with a wide range of backgrounds and experiences, each helping us understand our customers better, and strengthen our team. We particularly encourage you to apply if you identify as a woman, are a person of color or other underrepresented minority, or are a member of the LGBTQIA community.
How to apply

Please provide:

A pointer to your CV, resume, LinkedIn profile, or any other summary of your career so far.
Some informal text introducing yourself and what you are excited about.
If you have a profile on websites like GitHub or other repositories of open source software, you can provide that as well. If you don't have one, it's still very possible for us to get along just fine!",http://www.indeed.com/rc/clk?jk=3e849de7150b299b&fccid=9f14318c7a12f807&vjs=3
Junior Data Engineer,Ipsos North America,"Culver City, CA",,"About Ipsos

Ipsos is the world’s third largest market research company, present in 90 markets and employing more than 18,000 people. Our passionately curious research professionals, analysts and scientists have built unique multi-specialist capabilities that provide true understanding and powerful insights into the actions, opinions and motivations of citizens, consumers, patients, customers or employees. We serve more than 5000 clients across the world with 75 business solutions.

Founded in France in 1975, Ipsos is listed on the Euronext Paris since July 1st, 1999. The company is part of the SBF 120 and the Mid-60 index and is eligible for the Deferred Settlement Service (SRD).

ISIN code FR0000073298, Reuters ISOS.PA, Bloomberg IPS:FP www.ipsos.com

Junior Data Engineer

Location: Culver City, Los Angeles California

Division: Global Science Organization (GSO), Data Science & AI Lab

The Data Science & AI Lab of the Ipsos GSO is a uniquely positioned group within Ipsos. We serve as the global R&D capability bridging data science with market research offerings. The team develops analytic tools, builds data science models for pilot studies and internal stakeholder analytics innovations, and consults on a broad range of data and research best practices. Working in a collaborative and supportive environment, we seek to expand what is possible in market research with data science.

We’re looking for someone with a deep interest in technology, cloud services, and data and the dedication to apply that passion. We need someone that possesses the technical ability to write production-level code and deploy data science pipelines and tools for a diverse set of applications. The developer in this role will help the team build full-stack data offerings and scale them to the cloud. The position calls for an observant attention to detail, the ability to work well on a small team, and a self-starter approach to problem-solving and debugging.


As a Data Engineer, you will:

Work closely with team members on design of large-scale modeling efforts, contributing to cloud pipelines, including the containerization of current tools
Collaborate on engineering new data science products by translating needs identified with stakeholders into analytic frameworks that can be built into polished user-facing tools
Build, maintain, and enhance existing codebases
Synthesize tech innovations and cloud scalability to elevate business value for clients, both current and prospective
Validate, test, and maintain staging and production analytics environments in the cloud for data science teams globally
Provide consulting for internal teams and clients on data architectures and schemas, data hygiene, and areas for improving process efficiency


Requirements:

High proficiency writing Python and JavaScript (preferably React), including the ability to produce and maintain reusable and modular codebases
Bachelor’s degree
Desire to work in a highly collaborative, fun, consensus-oriented environment.
Attentive learner with excellent time-management skills
Experience with deploying data models and processes in the cloud (e.g. GCP, AWS).


Pluses:

Experience with Linux server and system administration.
Working knowledge of SQL and experience with database design and administration.
Experience in analytics, extracting and surfacing value from quantitative data.
Professional or academic experience with modern techniques and algorithms in machine learning and statistical computing (e.g. deep learning).
Experience with collaboration tools (e.g. Atlassian suite) and version control systems (e.g. Git).
Large dataset manipulation. Experience in distributed storage and computing.
Experience with ReactJS, TypeScript/JavaScript, visualization libraries (e.g. d3.js).
Experience creating and deploying web apps (e.g. Electron).
Advanced degree (M.S., Ph.D.), but not required.
Experience in the field of Market Research

Ipsos is An Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to age, race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or any other protected class and will not be discriminated against on the basis of disability. For all future offer negotiations – please target April 6th or after for their start date.
Required Skills

Required Experience",http://www.indeed.com/rc/clk?jk=f608d77bb3256958&fccid=d73294b71d7f0354&vjs=3
Data Engineer Intern,Plansource,"Orlando, FL 32801",,"Summary:
PlanSource is a high-growth software company headquartered in Orlando, Florida, with offices in Salt Lake City, Minneapolis, Grand Rapids MI, and Charleston SC. We are looking to provide college students with an internship opportunity to gain real-world experience in developing, deploying, and maintaining data pipelines and enterprise data sets while receiving mentorship from highly experienced industry professionals.
PlanSource is part of the Vista Equity Partners portfolio of companies. Together, we are working to reinvent the employee benefits administration landscape. Our talented associates benefit from this partnership through increased capital for strategic investments, access to exceptional toolkits, best practices and resources for success, and strong cultural and value alignment focused on talent development and growth.
This is your time to shine. Our Data Engineer interns are considered full-time employees by their peers-in fact, in our collaborative culture, you find plenty of opportunities to make impactful contributions to our Development Team. Under the supervision of our staff, the Associate Data Engineer Intern can expect to support engineering and data science teams on our data initiatives, ensuring data is accurate and reliable and that pipelines are running regularly. You should be self-motivated and comfortable supporting the needs of multiple teams, systems, and products.
About You:
This is an ideal opportunity for someone who wants to learn our data engineering process from early concept to deployment, and to expand and optimize data and data pipeline architecture, data flow, and data collection for cross-functional teams. We foster an environment that empowers small teams to collaboratively set the direction of our solutions.
In addition, you’ll need the following:
Enrolled in junior year or higher at a college/university
Working towards a BS in a quantitative discipline such as statistics, mathematics, engineering, computer science, or physics
Strong problem-solving and communication skills
Some experience with SQL and at least one programming language
Some experience with Unix-like operating systems
A desire to take ambiguous problems and see them through to the finish line
It would be cool if you were/had:
Some experience with Python
Some experience with or understanding of the AWS tech stack
Organized and detail oriented. You have time management down to a science, great follow through on tasks, and superior organizational skills.
You pursue insights that provide thoughtful answers to complex problems.
Innovative and resourceful, you are constantly looking for ways to improve upon things.
Our collaborative environment fosters a supportive team dynamic based on continual feedback.
What We Offer:
The opportunity to work for a fast growing, established technology company, but work side-by-side with a small, dynamic team of talented professionals.
Fast-paced environment with big goals and the opportunity to make a big impact (no bureaucracy).
An awesome work environment for creative professionals.
Top ten reasons to come to PlanSource:
#10: Join the Vista Family. In March 2019, Vista Equity Partners acquired PlanSource, marking a new phase a growth. Vista’s portfolio of technology and software companies collectively make up the 4th largest software ecosystem in the world with “intraportfolio” career advancement opportunities and have structures in place to leverage shared learnings from across the ecosystem.
#9: We are on a roll. Be part of a winning team – Thousands of employers and millions of consumers use the PlanSource Platform for benefits shopping, enrollment, billing and ongoing administration.
#8: Success is rewarded. With more than just a pat on the back, your success is recognized and rewarded. We take care of our employees in every way we can, with comprehensive benefits, cool perks, fun offices … and no-holds-barred Nerf wars.
#7: You can grow and develop professionally. PlanSource has a great track record of internal promotions and also filling open positions within the company.
#6: We give you the support you need. Different departments support you and provide you with the access and tools you need to succeed.
#5: Our business model is strong. With a leveraged sales model, our network of partners helps the organization succeed.
#4: Strong partnerships fuel your success. National partnerships with leading insurance carriers such as Aflac, Cigna, Guardian, MetLife, Guardian and Unum provide a competitive advantage and added credibility.
#3: The benefits industry is on fire. Legislation including the ACA has created an urgent and pervasive need in the marketplace for our technology.
#2: PlanSource has the right product. Show off our sophisticated cloud-based technology that meets the needs of even the most complex benefit programs.
#1: PlanSource is the right company. Join an up-and-coming high-growth technology company that is well funded and values its employees and their families.",http://www.indeed.com/rc/clk?jk=54188df2f0524bd9&fccid=9b686e279ed2aaea&vjs=3
Sr. Cloud Data Engineer,Phyton Advisors,"Austin, TX 78701",,"As a data engineer, you will be working on a number of high-profile projects that will require you to collaborate with key partners and develop data solutions that enable insights into our clients through an evolving data architecture and drive our next generation data platform.
The role is key in designing and building out scalable data infrastructure and pipelines to enable the organization to gain value out of data quickly and efficiently.
You will work with software developers, data architects, data analysts, and data scientists to solve complex business problems.
As a data engineer, you will be able to transform data warehousing processes, modernize data integration to Snowflake platform, build out modern streaming architectures, and enable advanced analytics capabilities for event driven insights.",http://www.indeed.com/rc/clk?jk=2bae156057875433&fccid=2fb208a1dacd8d3c&vjs=3
Data Engineer Data Operations,"Cotiviti, Inc.",Remote,,"The Data Engineer will work with product and technical teams to understand the business requirements and build scalable and sustainable enterprise reporting solutions.
Principal Responsibilities and Essential Duties:
Bring customer centric focus to our Internal Benchmarking platform
Work with product and technical teams to understand the business requirements and build scalable and sustainable enterprise reporting solutions
Demonstrate through proof of concepts and present them to stakeholders. Formulate and provide recommendations.
Develop, construct, test and maintain Data Architecture for Business Intelligence Solutions
Develop complex, interdependent Data Load Processes, and managing execution of those plans
Identify opportunities for Process Automation using ETL tools like Streamsets, SSIS, Python ETL Framework, etc.
Analyze large and complex datasets using SQL queries and Business Intelligence tools like Tableau to provide actionable insights
Mentor, develop and train team members on various aspects of Data Architecture Implementation
Work as a team member in creation and maintenance of ETL scripts, tools, queries and applications used for data management, data validation, and program validation.
Manage Oracle or SQL Server databases hosting large and complex datasets in Healthcare domain
Program per data transformation specifications to convert source data to be loaded into target data warehouse tables using T-SQL and other Data Integration/ETL tools.
Review & test the data to ensure accuracy & validity of the data prior to uploading the data to the warehouse

Requirements:
Experience developing product/solutions using MS SQL Server, SSIS and SSRS
Knowledge of dimensional modelling and experience building reports in MicroStrategy (9.3.1 or above) or any other BI reporting tool (Tableau)
Experience working with large and complex datasets
Extensive knowledge in relational database design
Experience with data aggregation, standardization, linking, quality check mechanisms, and reporting.
Experience with RDBMS (SQL, Oracle, SQL, Vertica, etc.) and using T-SQL or other data integration/ETL tools.
3-5 years experience in the Analysis, design and development of solutions and strategies for creating extraction, transformation and loading (ETL) and real-time applications.
Excellent written and verbal communication skills, with the ability to multitask and prioritize projects to meet scheduled deadlines.
Ability to work well independently or in a team environment.
Bachelor’s degree required. Masters preferred.
Familiarity with Agile methodologies preferred.
Critical thinker with strong analytical and problem solving skills
#LI-ME1
Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities
The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)",http://www.indeed.com/rc/clk?jk=55cdbe0a77d41333&fccid=ee24dd71b9bf38cc&vjs=3
Application Security Engineer,JANUS Research Group,"Austin, TX",,"JANUS is seeking a talented Application Security Engineer to support the Army Futures Command (AFC) Modernization Application and Data Environment (MADE) program. This position allows for remote work, however, you must be able to travel to the client site in Austin, Texas if needed.
As a Application Security Engineer, you will use cutting edge cloud and data technologies to power the mission of our clients and have the ability to join our team of Data and Cloud professionals and accomplish what others only dream of.
Mandatory Requirement
The ability to hold a U.S. Department of Defense Secret Security Clearance is required.

Experience and Education
Participates as a core member of DevSecOps teams by performing security audits, risk analysis, application-level vulnerability testing, and security code reviews as well as developing and implementing solutions to mitigate new attack vectors.
Individuals must have experience serving as the security engineer of complex technology implementations in an end user-centric environment.
Comfortable with bridging the gap between legacy development or operations teams and working toward a shared culture and vision.
Works tirelessly to ensure help developers create the most secure systems in the world while enhancing the privacy of all system users.
Experience with white-hat hacking and fundamental computer science concepts strongly desired.
Requires an Associate’s degree in Computer Science, Information Systems, Engineering, or other Scientific/Technical discipline and 4 years of related application security engineer work experience.
Must meet IAT-II requirements as specified in DoD 8570.01-M.

Benefits and unique perks offered, but not limited to:
Medical, Dental, and Vision Insurance
Flexible Spending Accounts (FSA)
401(k) Matching Program
10 Paid Holidays
Paid Time Off (PTO)
Short-Term and Long-Term Disability
Basic and Voluntary Life Insurance
Education Assistance Program
Award Incentive Programs: Leader of the Year, Employee of the Quarter, Energy Award
Scholarship Award Program
Referral Incentive Program
Employee Longevity Recognition

JANUS Research Group provides reasonable accommodation so that qualified applicants with a disability may participate in the selection process. Please advise us of any accommodations you request in order to express interest in a position by e-mailing:
Judy Pagac
Director of Human Resources
judy.pagac@janusresearch.com

(706) 364-9100
Please state your request for assistance in your message. Only reasonable accommodation requests related to applying for a specific position within JANUS Research Group will be reviewed at the e-mail address and phone number supplied. Thank you for considering a career with JANUS Research Group.
Janus Research Group participates in the Electronic Employment Verification Program. Please click the E-Verify link below for more information.",http://www.indeed.com/rc/clk?jk=e6cfb3f32627f17a&fccid=193ab4ce9271c767&vjs=3
BI Engineer,MedeAnalytics,United States,,"Required skills

Strong knowledge and hands-on experience with SQL (it could be ANSI SQL, T-SQL, Oracle, etc.)
Proficient in ETL and hands-on experience with one of the ETL tools (like SSIS, Kettle or Talend).
Knowledge and experience with MS SQL Server or Oracle/MySQL/Postgress

As a plus

Being able to construct and troubleshoot very complex queries and handling big data (Data transfer, import/export, storage, performance and security) is highly desired
Experience in MS Analysis Services is highly desired
Experience in Data Migration from database and data warehouse application to Vertica
SaaS or cloud software development experience
Experience with Linux as a plus
Knowledge with Vertica, MongoDB and Hadoop a big plus
Experience in Scrum methodology
Ability to work effectively in a team.
Technical degree (Bachelors of Science, Computer Science or equivalent) strongly desired

We offer

Friendly team and enjoyable working environment.
Opportunity for self-realization. Career and professional growth.
Competitive compensation based on your qualifications, experience and skills
Paid sick leave and vacations
English classes with a certified English teacher.
Office in a comfortable business center, located near a subway station.
Official journeys abroad with expenses reimbursement.
Flexible working hours
Company-owned gym and shower
Convenient parking near the office building
Room for bicycle parking
Corporate events and meetings
Large recreation area
Not an open space office

Responsibilities

Development and maintaining systems that leverage big data and traditional BI technologies
Responsible for the setup, creation and support of MS SQL, Vertica, MongoDB, Hadoop and Mondrian databases.
Work with the product owners and business analysts in analyzing business requirements and design and implement database structures and fine tune performance to meet those requirements.
Work on engineering the Company data platform for scale, performance, and rock-solid reliability.
Work with engineering and product teams distributed across multiple locations.
Participate in establishing processes and best practices around development standards, version control, quality control, deployment, maintenance and change management

Project description

The big data engineer will work closely with the product managers and developers to create and maintain the big data systems for large scale, high performance, and rock-solid reliability.
This is a hands-on position that will require performing system development and maintenance activities for the exciting and dynamic medical fields.",http://www.indeed.com/rc/clk?jk=5d619ea430a52b2d&fccid=e0da9fa1dc69faed&vjs=3
Data Engineer,Charles Schwab Inc.,"Westlake, TX 76262",,"Your Opportunity:
Do you want to be part of a Data Warehouse team handling over 120 terabytes of data and building the next generation analytics platform for a leading financial firm with over $2.5 trillion in assets under management? At Schwab, the Global Data Technology (GDT) organization governs the strategy and implementation of the enterprise data warehouse and emerging data platforms. We help Marketing, Finance and executive leadership make fact-based decisions by integrating and analyzing data.
We are looking for a data engineer who has passion for data integration technologies and comes with data warehousing background. Someone who has experience in designing and coding ETL and one who wants to be part of a team that is actively delivering projects in Teradata, Big Data and working towards migrating to cloud technology.
What youâre good at:
You will be an ETL developer working with a large team that includes onshore and offshore developers using best-in-class technologies including Teradata, Informatica and Hadoop. You'll be responsible for the design, development and implementation of enterprise data integration solutions. You’ll have the opportunity to grow in responsibility, work on exciting and challenging projects, train on emerging technologies and work with other Developers to set the future of the Data Warehouse. Your detailed duties would include:
Creating/updating ETL specifications and supporting documentation
Developing ETL logic utilizing Informatica workflows, scripting and load utilities
Building and maintaining code for big data ingestion using Talend, Scoop, Hive etc
Implementing data flow scripts using Unix /Sqoop / Hive QL / Pig scripting
Designing, building and support data processing pipelines to transform data in Big Data or Teradata platforms
Developing and executing quality assurance and test scripts
Work with business analysts to understand business requirements and use cases
Problem solving and fixing technical issues
Working with technical lead and offshore development teams to ensure proper and efficient implementation of requirements
What you have:
Demonstrated development experience with enterprise ETL tools such as Informatica , Talend etc. (> 2 years)
Experience in Data Warehousing / Information Management (> 2 years)
Familiarity with data modeling (logical and/or physical) preferred (> 2 years)
Hands-on experience with Hadoop, MapReduce, Hive, SPARK and/or Teradata (At least 2 years)
Strong SQL experience with the ability to develop, tune and debug complex SQL applications is required
Experience with change data capture tool (CDC) preferred such as Attunity
Experience with scheduling tools (eg. Control M, ESP)
Familiarity with scripting / programming such as UNIX, Java, Python, Scala etc.
Validated experience in working in large environments such as RDBMS, EDW, NoSQL, etc. is preferred
Experience collaborating with business and technology partners and offshore development teams
Good interpersonal, analytical, problem-solving and organizational skills
Excellent written/verbal communication skills
Strong knowledge of MS Office suite and Visio Drawing tool along with general familiarity with Outlook and other MS Office applications is also required",http://www.indeed.com/rc/clk?jk=9453174c93cf8142&fccid=3c74eafe288fc8ca&vjs=3
Data Engineer IV,Capital Group,"Los Angeles, CA 90071",,Data Engineer IV,http://www.indeed.com/rc/clk?jk=877f0e896f8d896c&fccid=04c4d5d87ff27beb&vjs=3
Data Engineer,44bsquared,"Leawood, KS",,"This Leawood client is looking for Data Engineers to help build their data services team. These are full-time positions.

Strong demonstrated SQL and data modeling skills

 Requirements:
3 years of experience
Demonstrated proficiency in data analysis and pattern identification.
Advanced proficiency with Big Data streaming and processing technologies.
Experience using technologies in the Hadoop Ecosystem and Linux/Unix operating systems.
Proficiency with a JVM language or experience coding within a functional programming paradigm.
Experience with cloud-hosted computing.
Experience using a version control system.",http://www.indeed.com/rc/clk?jk=5e57ef1fa0eceeb8&fccid=5a397a8fe35e0940&vjs=3
Data Engineer I,3-GIS,"Birmingham, AL",,"As a top technology firm, 3-GIS helps the world's top telecommunications companies solve their toughest problems. Our work spans technology, analytics, strategy, product development, and engineering, across all geographies and many industries. We have thousands of users in 18 countries utilizing our technology to design and manage the next generation of telecommunications networks to power fiber densification projects to support the next generation 5G rollout that is already underway.

We take great pride in our culture and work hard to produce amazing products while also striving to be the best workplace for the world's top talent. We strive for great work-life balance and invest in helping our team members continue to grow personally and professionally.

The purpose of the Data Engineer is to migrate and convert data from foreign data models into our proprietary 3-GIS data model. In addition to data conversion, the data engineer supports existing 3-GIS accounts with data changes for system corrections and upgrade requirements.

Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Job Duties:

Responsible for supporting data migrations and data conversions from disparate systems into the 3-GIS Data Model.
Oversee data mapping exercises and work closely with customers to understand their data models and to provide mapping between systems.
Employ a variety of tools including but not limited to Python Scripting, Database Scripting languages such as SQL, advanced knowledge of ESRI applications, FME workbenches and internally developed tools, as the assignment dictates.
Exhibit strong communication skills to ensure customer understanding of data migrations and conversions and must work with various team members such as Solutions Engineers, Data Technicians, Sales Executives and Project Managers to ensure project success.
Must be detail oriented and maintain proper time management as projects generally have specific timelines and milestones required for project success
Ability to provide references for users by writing and maintaining documentation
Design, develop, and test data transformation, extraction, and migration activities.
Prepare technical reports by collecting, analyzing, and summarizing information
Perform tasks efficiently while validating methodology.
Interact directly (face-to-face and remotely) with clients and project teams
Provide best practice recommendations during data mapping and project exercises.

Required Qualifications:

Bachelor's Degree in Information Technology or related field
3-5 years of experience in data conversion, data mapping, and data analysis
3-5 years of experience using ESRI, FME, or a combination of both
Basic database experience including SQL relationship statements
Programming/Report Analysis experience
Communication skills, both oral and written
Strong organizational skills and attention to detail
Deadline driven, ability to work independently as well as a team player

Preferred Qualifications:

2-5 years of experience in data conversion, data mapping, and data analysis
Experience working with and authoring Python
Experience with telecommunications networks

3-GIS provides a competitive benefits package including health, dental, life, STD, LTD, 401(k), and generous paid leave.

3-GIS is an Equal Opportunity Employer.",http://www.indeed.com/rc/clk?jk=ca39535740e7c3e2&fccid=5278765092d86d5f&vjs=3
Data Engineer,Mode,"San Francisco, CA",,"Mode is a company built for analysts and data scientists. In addition to building a product to help them be great at their jobs, Mode aims to be a source of education and inspiration for analysts and data scientists of all experience levels.

Mode's own Data Science team is a critical part of this mission. The team has a dual mandate. First, we serve internal customers in all parts of the Mode organization to help guide and empower decision-making. Second, the team works to inspire others to be data-driven by ""open-sourcing"" the resources and analyses we create internally.

What you'll do

Help us scale our internal analytics and reporting infrastructure.

Ensure data pipelines are working harmoniously.

Identify opportunities to improve business outcomes by connecting teams to data that helps us make better decisions.

Create processes to manage governance across our various tools and services.

Share your work with the Mode community in the form of open-source resources, blog posts, and community talks.

What we look for

A creative problem solver — you aren't hindered by yesterday's limitations and you're continuously finding ways to make things work better.

Technical ability — you're comfortable deploying production code.

A professional background in data engineering or data science. You might not have been called a ""data engineer"" before, but you've implemented ETL tools, managed Airflow, or created Lambda functions.

Alignment with Mode's values

About Mode
Mode is a collaborative analytics platform that brings teams together around data to make game-changing decisions.

In everything we do, we strive to put the people we do it for first. This starts internally: together we're building a culture that embraces diversity and learning, humility and gratitude. At the same time, we try not to take ourselves too seriously and strive for a healthy balance between work and personal pursuits.

Benefits you can expect as a Mode employee:
Generous, flexible PTO and family leave

Flexible work schedules—we trust you to know what will make yourself most productive

Generous professional development policy that includes funds earmarked for each employee's discretionary professional growth—Have a conference you want to attend? A class you want to take? If it's helping take your career to the next level, it's on us.

Excellent health coverage for team members and their families (Mode pays the 100% of the premiums)

Supportive work environment and a manager who is focused on your professional growth

Company events that highlight our team's passions and hobbies

Snacks and in-office lunches shared at our ever-growing lunch table

Mode is committed to building an inclusive and diverse workforce. We are an Equal Opportunity Employer and welcome people from all backgrounds, experiences, abilities and perspectives.",http://www.indeed.com/rc/clk?jk=036a212a6776fdbc&fccid=91bbe5abd5c92a78&vjs=3
Intern: Data Engineer,Juniper Networks,"Cupertino, CA",,"The mission of the Data Science team at Mist, a Juniper Company, is to leverage state-of-art ML and AI technologies to build the next-generation self-driving network solution, which can take actions on behalf of or together with human experts to automatically monitor, detect and remediate common network issues. The team includes a group of experienced and talented data scientists and data science engineers, and builds the end-to-end data analytics infrastructure and ML models of the product.
The profile of a great candidate:
Pursuing a Bachelor or Master Degree in Computer Science, Electrical Engineering, or equivalent majors
Experience in software development (Python, Java, Scala)
Passionate learner and good team worker
Experience with big data tools (e.g., spark, flink, elasticsearch, Cassandra etc ) and cloud env (e.g., AWS, GCP) is a plus
This Juniper Internship position is for Summer 2020.",http://www.indeed.com/rc/clk?jk=53ed065bfa21dd9d&fccid=e9e363d6332bc1cd&vjs=3
Data Engineer,Workforce Logiq,"Newark, NJ 07102",,"Overview:
WorkforceLogiq is seeking a highly talented Data Engineer (DE) within the Data Engineering group. This position is a contract role in Newark, NJ area.

Responsibilities:
Our Data Engineering team owns and develops the technology platform that offers decision makers both performance metrics and analysis as well as the self-service capability to perform independent analysis on a wide array of internal and external datasets in order to identify opportunities, trends and issues, uncover new insights, and fine-tune operations to meet business goals.

Responsibilities:
Build and maintain the infrastructure to answer questions with data, using software engineering best practices, data management fundamentals, data storage principles, recent advances in distributed systems, and operational excellence best practices.
Work closely with stakeholders to understand their requirements and design the right solution
Work closely with other teams, analyze source systems, define underlying data sources and transformation requirements, design suitable data models and document the design/specifications.
Build/maintain systems and datasets that analysts and scientists use to generate actionable insights.
Demonstrate passion for quality and productivity by use of efficient development techniques, standards and guidelines
Peer reviews of work. Actively mentor more junior members of the team, improving their skills, their knowledge of our systems and their ability to get things done
Qualifications:
Strong Computer science background required. A Bachelor’s degree or higher in computer science or equivalent is required
10+ years of experience in a Data Warehouse (DWH) environment with data integration/ETL of large and complex data sets
Design and coding skills in a scripting language (e.g. Python/Perl/shell scripting) on Unix/Linux Platforms.
Proficiency in SQL and database technologies such as AWS Redshift
Data modeling skills such as Star/Snowflake schema design for DWH
Expertise in performance tuning and scaling in a DWH environment
Hands on experience with recent advances in distributed computing such as MapReduce, MPP architectures, NoSQL databases.
Familiarity with Business Intelligence (BI) platforms such as MicroStrategy, OBIEE or equivalent
Good interpersonal and communication skills. Ability to work with different teams for sourcing of data.
Ability to learn fast, work independently with little supervision and deliver on time quality products

Preferred qualifications
Extensive knowledge of BI platforms such as MicroStrategy, OBIEE or equivalent
Experience working with Agile methodologies in a DWH/BI environment",http://www.indeed.com/rc/clk?jk=1930812e5b9523a9&fccid=bdbc38ad07a162e4&vjs=3
Data Engineer,Trianz,"San Francisco, CA",,"Data Engineer
And who better than you to join the Trianz family?
At Trianz, we offer you an open and learning-oriented culture essential to emerge as a leader. Completely focused on the Digital Evolution philosophy and phenomenon, we view delivering our value proposition consistently as a non-negotiable commitment. Our enablers include Intelligent Team Formations, a Client-Centric Approach, Predictability in Execution, and establishing a Unique Relationship Experience. A culture of innovation, encouraging our people to create, and belief in the importance of training and development set us apart.
We are looking forward to see you bring the following to the table to craft your, and our, success story:
Location: San Francisco, CA
Terms: Full-time
Senior Data Engineer
About the Role

Trianz is looking for passionate Data Engineers who are looking to tackle challenges and build solutions
Job Description
Strong data engineer able to:
Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements,
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources,
Work with stakeholders including Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs,
Experience building and optimizing data pipelines, architectures and data sets,
A successful history of manipulating, processing and extracting value from large disconnected datasets.
A plus:
Experience in creating reports and dashboards in Tableau.
Technologies we use:
Dataswarm (data pipeline framework in Python), Hive, Presto, Python, Scuba (in-memory database), SQL, Oracle, Tableau
Your passion for execution and zeal to become a leader capable of taking on anything is enough reason for us to talk immediately!
Need more details?
Trianz is growing at a faster pace than the industry for the last five years. Read through some of the key industry recognitions we have received for our innovative execution and strategic client initiatives here.
About Trianz
Trianz simplifies digital evolutions through effective strategies and excellence in execution. Collaborating with business and technology leaders, we help formulate and execute operational strategies to achieve intended business outcomes by bringing the best of consulting, technology experiences and execution models. Powered by knowledge, research, and perspectives, we enable clients to transition to a digital enterprise by leveraging Cloud, Analytics, Digital, Infrastructure and Security paradigms. With offices in Silicon Valley, Washington DC Metro, Rosemont, Chicago, Austin, Boston, Denver, Irvine, Raleigh, San Francisco, Seattle, New York, Dubai, Bengaluru, Hyderabad and Chennai, we serve Fortune 1000 and emerging organizations across industries globally. For more information, visit www.trianz.com.
Trianz is an Equal Opportunity Employer and does not discriminate on the basis of race, color, creed, national or ethnic origin, gender, religion, disability, age, political affiliation or belief, disabled veteran, veteran of the Vietnam Era, or citizenship status (except in those special circumstances permitted or mandated by law).",http://www.indeed.com/rc/clk?jk=87459e23a275f95d&fccid=65a841a7f945806c&vjs=3
Staff Data Engineer,Intuit,"Mountain View, CA 94041",,"Intuit’s Small Business Self-Employed Group (SBSEG) develops and brings to market the products that small businesses and accounts depend on every day for their success. These products include accounting products (QuickBooks), payments, payroll and others.

The SBSEG Data Engineering team is looking for a Staff Data Engineer with a winning track record in Big Data, Data Warehousing, Visualization and Data Web Services. We’re using data in groundbreaking ways to uncover customer insights, personalize customer experiences, and provide a unified customer view across all SBG products.",http://www.indeed.com/rc/clk?jk=5135e0acc5a6a59b&fccid=9784ae78e9834539&vjs=3
Big Data Engineer,Avani Systems,"Seattle, WA",,"Job Description:

Ensure high throughput of development teams by identifying potential issues, removing impediments or guiding the team to remove impediments by collaborating with the appropriate resource
Manage sprint planning and execution which includes the management of project progress and provide status and visibility
Facilitate release planning and scheduling by providing empirical Scrum team statistics, identifying project dependencies, and creating velocity forecasts
Assist with internal and external communications to improve transparency and radiate information ensuring the team’s progress and successes are highly visible to all stakeholders including the team itself (e.g. backlogs, burn down/up charts, etc.)
Develop pipelines using copy activity from different sources like FTP, Windows Blob Storage, SQL SERVER, COSMOS big data etc. and scheduling the pipelines as per requirement using azure data factory.

Requirements:

Required minimum Bachelor’s degree in Computer Science",http://www.indeed.com/rc/clk?jk=af178c911ca9fb16&fccid=4e6bb1d1b2720186&vjs=3
Data Engineer,Cytiva,"Marlborough, MA 01752",,"Help us improve access to life-changing therapies that can transform human health

We are Cytiva, a global provider of technologies and services that advance and accelerate the development and manufacture of therapeutics. Formerly part of GE Healthcare, we have a rich heritage tracing back hundreds of years, and a fresh beginning since 2020.

Our customers undertake life-saving activities. These range from fundamental biological research to developing innovative vaccines, biologic drugs, and novel cell and gene therapies. Our job is to supply the tools and services - the pots, pans, soups and sauces - they need to work better, faster and safer, leading to better patient outcomes.

What you'll do

The Data Engineer will join the Digital team within the BioPharma organization of Life Sciences, who are responsible for driving the digital transformation of the organization and customers. The team is responsible for driving initiatives such as asset performance management, digital twin, augmented/virtual reality and data visualization.

The Data Engineer will work directly with product owners and collaborate with other teams to drive development of data pipelines and analytical model deployment methods within the organization and customer products and services. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys building data systems from the ground up and optimizing them. The Data Engineer will support our software developers, digital platform architects and data scientists on data initiatives and digital product development to ensure that optimal data delivery architecture is consistent throughout ongoing projects.
Create and maintain optimal data pipeline architectures
Assemble large, potentially complex data sets that meet functional and non-functional business requirements
Build the infrastructure required for optimal data extraction, transformation and loading from a wide variety of sources using SQL and AWS technologies, etc.
Work with data scientists to build and deploy analytical tools that utilize the pipelines to provide actionable insights to customers and business stakeholders
Create data tools for product developers and data scientists that assist them in building innovative products and services that lead the industry

Who you are
Bachelor’s Degree in Computer Science or another quantitative discipline like Physics, Mathematics, Statistics, InformaticCytivas, Information Systems or Computational Biology
Advanced working knowledge of SQL and experience working with relational databases
Experience building and optimizing data pipelines, architectures and data sets
Experience extracting data from lab and process equipment
Experience building processes supporting data transformation, data structures, metadata, dependency and workload management

Experience with the following or similar tools:
AWS Cloud Services – S3 and RDS
Object-oriented/object function scripting languages – Python, R, etc.

Additional Eligibility Requirement
Cytiva will only employ those who are legally authorized to work in the United States for this opening. Any offer of employment is conditioned upon the successful completion of a drug screen (as
applicable).

Desired Characteristics
Master’s Degree in any of the above fields
Certifications – 1 or more of the following – Cloudera Certified Professional, Google Cloud Certified Professional, Certificate in Engineering Excellence Big Data Analytics Optimization, IBM Certified Data Engineer
3+ years of professional data engineering experience
Strong project management and organizational skills with the ability to communicate key metrics to all levels of stakeholders
Knowledge of software development and agile methodologies
Ability to communicate across multiple teams and organizations
Ability to break down problems, document problem statements and drive issue resolution
Strong oral, written and interpersonal communication skills

Who we are

Whatever your role, we bring purpose and challenge into our everyday work. If you are driven to make the world a better place thanks to science and medicine, you’ll feel right at home here. If you’re flexible, curious and relentless, you’ll belong. If you are excited about a global culture, this can be the place to further your career.

Want to know more? Take a look at our Instagram, Twitter and LinkedIn pages!

Cytiva is a 3.5 billion USD global life sciences leader with over 7000 associates across 40 countries who are dedicated to our mission to help us improve access to life-changing therapies that transform human health. As a trusted partner to customers that range in scale and scope, Cytiva brings efficiencies to research and manufacturing workflows, ensuring the development, manufacture and delivery of transformative medicines to patients.

As part of the Danaher family of companies, our work at Cytiva is supported by a global science and technology innovator. In addition to Danaher’s unrivaled leadership training and professional development programs, our relationship also provides expanded career opportunities across industries and brands. Together, we are united by a shared purpose: Helping Realize Life’s Potential.",http://www.indeed.com/rc/clk?jk=58db6b003599ec17&fccid=c46411dafcae5d08&vjs=3
Senior Data Engineer,GoodRx,"Santa Monica, CA 90401",,"At GoodRx, we believe that all Americans should have access to convenient and affordable healthcare. As a nation, we spend about $3.5 trillion annually on our healthcare, but too many Americans don't get the care they need, and prices just keep rising. We started with prescriptions, and we've helped over 100 million Americans save over $15 billion to date. Now, we're aiming to tackle all of healthcare. GoodRx is a profitable business funded by top-tier investors; we're based in Santa Monica with additional offices around the country. We're a low-key and tight-knit group that likes to find new ways to fix problems. If you share our belief that you can do well by doing good, let's talk.

About the Role
GoodRx is looking for extremely smart and curious Senior Data Engineers, who are deft at working with a wide variety of languages, such as Python and SQL, a variety of raw data formats, such as JSON and CSV, in a fast-paced and friendly environment. Previous work with Python-based ETL solutions, such as Luigi or Airflow, is a huge plus.

Responsibilities:

Analyze, design, develop, test and implement data warehouse and business intelligence solutions with emphasis on data quality
Design highly scalable ETL processes with complex data transformations
Gather and document business requirements and translate into technical architecture/design
Ability to understand and document data flows in and between different systems and map data from a data source to target tables in a data warehouse
Work closely with other engineers to enhance infrastructure, improve reliability and efficiency
Make smart engineering and product decisions based on data analysis and collaboration
Act as an in-house data expert and make recommendations regarding standards for code quality and timeliness

Skills & Qualifications:

Degree in Computer Science or a related field or 5+ years of professional experience in developing ETL and data warehouse solutions
In depth knowledge of how to write and optimize SQL statements
Deep familiarity with distributed processing (Map Reduce, MPP, etc.)
3+ years experience with schema design (logical and physical)
Strong experience with data integration tool sets
Experience with cloud solutions (AWS, Redshift, Snowflake, other) is a must
Strong programming (Java/C# or related) and scripting skills (Python/Javascript) is a plus
Experience with workflow management tools (Airflow, Luigi etc) helpful
Ability to quickly learn complex domains
Strong attention to detail with excellent analytical, problem-solving, and communication skills

About GoodRx
GoodRx is the country's leading marketplace for affordable and convenient healthcare. The company offers the most comprehensive and accurate resource for prescription medications in the U.S., gathering pricing information from thousands of pharmacies coast to coast. More than 12 million consumers use GoodRx each month to find current prices and discounts for their medications. Since 2011, Americans with and without health insurance have saved more than $15 billion using GoodRx – more than $5 billion in 2019 alone. With GoodRx Care, Americans can get an online medical visit with a skilled physician for fast and easy treatment, prescriptions, and lab tests for routine medical issues. GoodRx is the #1 medical app on the iOS and Android app stores and tens of thousands of doctors recommend GoodRx to their patients. For more information, visit
www.goodrx.com [http://www.goodrx.com/].",http://www.indeed.com/rc/clk?jk=0f90e625825cef9a&fccid=663350f2630dae21&vjs=3
Data Engineer,"Resurgent Capital Services, LP","Cincinnati, OH 45249",,"Building Bridges, Moving Ahead

Work hard. Play hard. Breathe Easy. That’s a nutshell description of the professionals who thrive at Resurgent. Regardless of their position, our people are ambitious and entrepreneurial, attracted to the fresh point-of-view of an evolving, growing company. They are personable and patient, attracted to the collaborative nature of our company. And they are centered, understanding the balance needed to achieve success at work and harmony at home.
As a Data Engineer, you will be responsible for all aspects of the software development lifecycle, including design, coding, integration testing, deployment and documentation. You will create and maintain new data applications relying heavily on experience and judgment to plan and accomplish goals. Prior experience designing and developing production solutions is expected.
Design & Develop custom data warehouse solutions that enable leadership and general users to make informed data driven decisions and address the high demand for data availability in the enterprise.
Responsible for creating work estimates, technical project plans, and implementation plans
Research emerging development technologies, products, and processes
Work collaboratively within an agile project team
Follow best practices and coding standards
Grow your personal skillset as well as the skills of the team
Qualifications/Skills:
Experience designing data warehouse solutions with strong working SQL knowledge
Knowledge of databases, data structures, data management, and data manipulation
Experience creating data models, and data pipelines for acquisition, cleansing, and integration
Proficient with Microsoft SQL Server
Experience with C# and/or PowerShell
Familiar with distributed architecture a plus
Demonstrated experience in IT concepts and practices
Understands and has used software development lifecycles
Experience working in a team-oriented, collaborative environment
Good communication skills with a customer support orientation
Excellent problem-solving skills
Familiar with application lifecycle management tools and source control
Additional Desired Skills:
SSIS or equivalent ETL tool
Azure / AWS
R or Python
Educational Requirements:
College degree preferred; or a combination of education and experience

We would be honored if you applied to join our team! We are an equal opportunity employer,offering a fantastic work environment, challenging career opportunities and competitive compensation.",http://www.indeed.com/rc/clk?jk=32ca1f5c8f831094&fccid=32800844fc4d2553&vjs=3
Data Engineer,Ace-stack LLC,"Chandler, AZ",,"Job Details
Position : Data Engineer
10+ years of overall experience
3+ years’ experience with Big Data ( HADOOP platforms) –Hive, Spark ( needs to be currently hands-on on Hadoop cluster)
5+ years of ETL (Extract, Transform, Load) - Scoop, INFA RDBMS Teradata, Oracle
Experience in Python
Reproduce issues faced by Data Scientists
Knowledge of Agile is a must",http://www.indeed.com/rc/clk?jk=702c3cc50f675f66&fccid=d7bd51c63266d60a&vjs=3
Data Engineer,Google,"Mountain View, CA",,"Note: By applying to this position your application is automatically submitted to the following locations: Mountain View, CA, USA; Boulder, CO, USA
Minimum qualifications:

Bachelor's degree in Computer Science, related technical field or equivalent practical experience.
Experience with one general purpose programming language (e.g., Java, C/C++, Python).
Experience in data processing using traditional and distributed systems (e.g., Hadoop, Spark, Dataflow, Airflow).
Experience designing data models and data warehouses and using SQL and NoSQL database management systems.

Preferred qualifications:

Advanced degree in engineering or technical/scientific field of study.
Experience designing data models and data warehouses and with non-relational data storage systems (NoSQL and distributed database management systems).
Experience writing and maintaining ETLs which operate on a variety of structured and unstructured sources.
Experience in large scale distributed data processing.
Experience with Unix or GNU/Linux systems.
Excellent communication, organizational, and analytical skills.
About the job
At gTech’s Users and Products team (gUP), our mission is to help users get the most out of Google. We represent the voice of Google's users and many of our partners globally, sharing insights with the larger Google organization to enable exceptional customer and product experiences.


gUP builds innovative solutions that take user experience and engagement with Google to the next level, supporting users across products, countries, cultures, incomes, and identities. We advocate for users through partnerships with product areas at Google (and some Alphabet businesses), supporting Google’s consumer products ecosystem and enabling numerous launches for Google’s consumer products each year.


We are committed to building an ever more diverse, equitable, and inclusive gUP, and consider this the foundation upon which individual, team, and user success are built. We're also committed to innovation not only in the content of our work, but in the way we work. Check out this blog post on our Chameleon program.

As a Data Engineer, you’ll design and develop data systems and reporting tools to ensure that the Users and Products team members have the product, support, and operations data they need to make crucial business decisions. You’ll have the opportunity to design innovative data solutions and solve challenging problems using Google’s large-scale production data infrastructure.
Google creates products and services that make the world a better place, and gTech’s role is to help bring them to life. Our teams of trusted advisors support customers globally. Our solutions are rooted in our technical skill, product expertise, and a thorough understanding of our customers’ complex needs. Whether the answer is a bespoke solution to solve a unique problem, or a new tool that can scale across Google, everything we do aims to ensure our customers benefit from the full potential of Google products.

To learn more about gTech, check out our video.
Responsibilities
Design, develop and support data pipelines, warehouses and reporting systems to solve business operations, users and product problems.
Create extract, transform, and load (ETLs) and reporting systems for new data using a variety of traditional as well as large-scale distributed data systems.
Collaborate and influence Users and Products stakeholders and support engineers to ensure our data infrastructure meets constantly evolving requirements.
Work closely with analysts to productionize various statistical and machine learning models using data processing pipelines.
Write and review technical documents, including design, development, and revision documents.
At Google, we don’t just accept difference—we celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form.",http://www.indeed.com/rc/clk?jk=158df5fddacfd3aa&fccid=a5b4499d9e91a5c6&vjs=3
Senior Software Engineer,LTCG,"Eden Prairie, MN 55344",,"The nation's leading administrator of long term care insurance services is looking for YOU. This is your opportunity to join a company with a culture that promotes respect for people, integrity, learning and initiative.


WE ARE THE KIND OF EMPLOYER YOU DESERVE.
LTCG is a leading provider of business process outsourcing for the insurance industry, managing over 1.3 million long-term care policies for the nation's largest insurers. We also provide clients with unique risk management insight built upon our proprietary long term care databases.
A SQL Data Engineer is responsible for the development and maintenance of large applications, data conversions, and report development along with their design, test, and implementation, following an SDLC. This role is for an expert-level data engineer, who is a major contributor to the Data Services Center of Excellence, providing thought leadership and ""raising the bar"" for the standard of software being created in the department.


Major contributor to LTCG's Data Engineering Center of Excellence, with a focus on leading the continuous improvement work.
Provides technical advice and consultation for problems requiring advanced techniques.
Conducts a full range of programming tasks including program design, program coding, debugging and documentation for a variety of general applications programs including data manipulation, input and output routines reflecting a variety of equipment configurations.
Participates in peer code reviews / inspections, bringing knowledge of techniques such as: reuse, performance, interoperability, defensive programing, security, safety, etc.
Manages full software development lifecycle including testing, implementation, and auditing.
Partners with QA to prepare and conduct comprehensive system and programming tests.
Works under minimal supervision on complex projects and may assist less experienced peers.
Has wide latitude for independent judgment.
Bachelor's degree in Computer Science, Management Information Systems (MIS), Mathematics, Science, a related field, and 4 or more years of increasingly complex business programming experience in a business environment
Preferred
Expertise in:
SQL / PLSQL, ETL / SSIS, SSRS, etc.
Database and application design and modeling experience.
.Net and/or PowerBuilder
Microsoft certification

LTCG values diversity and is committed to providing an environment of mutual respect. LTCG is an Equal Opportunity Employer (EOE/AA) and participates in E-Verify. LTCG will not discriminate in its employment and employment-related decisions against any applicant or employee based on age, race, gender, creed, religion, national origin, disability, marital status, covered veteran status, sexual orientation, status with respect to public assistance, membership or activity on a local commission, or any other characteristic protected under state, federal, or local law.",http://www.indeed.com/rc/clk?jk=37d521948c9cd860&fccid=fdde0efa2890df13&vjs=3
"Big Data Engineer - AWS, Dynamo","PRIMUS Global Services, Inc","Miami, FL",,"We have an immediate opportunity in the Miami, FL area for a Big Data Engineer role.

For this role, the responsibilities will consist of building processes supporting data transformation, data structures, metadata, dependency and workload management. (Preferably in Python of Spark). Must assist with assembling and optimizing large, complex data sets that meet functional / non-functional business requirements along with other essential duties.

The ideal candidate must possess hands-on deep working knowledge of build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using NoSQL and SQL AWS 'big data' technologies ( Dynamo, Kinesis, S3, HIVE/Spark). Experience building and optimizing 'big data' data pipelines, architectures and data sets. (HiveMQ, Kafka, Cassandra, S3, Redshift). Must be advanced in working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement is necessary.

For immediate consideration, please contact:
Ayush
PRIMUS Global Services
(972) 753-6500 x408
jobs@primusglobal.com",http://www.indeed.com/rc/clk?jk=6792adf6245da1e2&fccid=a1c580f8e420853d&vjs=3
Data Engineer,Arthur Grand Technologies,"Baton Rouge, LA 70801",,"Tasks

Position: Data Engineer

Location: Baton Rouge, LA

Duration: Full Time Permanent


Data Domain Modeling and Logical modeling, Data profiling and Quality Assessment
Creating data Flow Diagram, optimal design and integration with app design and flow
Helping App engineer with design of data heavy processes Technical Skills:
Designing optimal SQL and NoSQL storage variations (Columnar, Key-value pair,
Object/Document (JSON) based on the situation
Design Event Stream and Schema (JSON) -Experience with designing data systems with TBs of throughput
Provide domain expertise on storage, big data platform services, serverless architectures, Hadoop ecosystems, RDBMS, DW/DM, NoSQL databases, cloud data solutions

Requirements

expertise on storage, big data platform services, serverless architectures, Hadoop ecosystems, RDBMS, DW/DM, NoSQL databases, cloud data solutions",http://www.indeed.com/rc/clk?jk=72ccce4f900d1375&fccid=0ddee73c57c63ea5&vjs=3
Oracle Data Engineer,eSystems Inc.,"Durham, NC",,"NC FAST requires an Oracle Data Engineer to support the development and implementation of North Carolina Families Accessing Services through Technology (NC FAST).

The Department of Health and Human Services (DHHS) requires an Oracle Data Engineer to provide technical oversight and development of the redesign of the Data Warehouse Reporting environment based on the Cúram application schema. This position will provide Oracle database development, technical support such as resolving performance issues and serve as a mentor. This role will identify and refine data requirements, database design, database migration and archival planning and implementation, construct configurable ETL frameworks, and ensure adherence to defined development standards. In addition to reporting duties, this position will work closely with the NC FAST Quality Control (QC) team to assist in all data related matters when audits and evaluations requiring reports are needed. This QC assignment will require face to face meetings with State and Federal auditors where requirements are gathered, and reporting data is explained. Business requirements must be interpreted into logical queries and written to provide the data for reports that are provided for the audits. Requirements and design documentation must be created and maintained as part of this reporting and QC work..

Required skills:

Extensive experience with Oracle Database architecture and design
Extensive experience in planning and executing Oracle database migration and archival process for large scale applications
Extensive experience in developing ETL frameworks using PL/SQL
Extensive experience in fine tuning complex queries and resolving of performance issues
Extensive experience in leading and mentoring large teams with group of report developers and database architects
Experience in working with State and Federal auditors in meeting their requirements
Familiarity with Cúram application schema

eSystems (the Company ) is an equal opportunity employer and makes employment decisions on the basis of merit and business needs. The Company will consider all qualified applicants for employment without regard to race, color, religious creed, citizenship, national origin, ancestry, age, sex, sexual orientation, gender identity, genetic information, physical or mental disability, veteran or marital status, or any other class protected by law. To comply with applicable laws ensuring equal employment opportunities to qualified individuals with a disability, the Company will make reasonable accommodations for the known physical or mental limitations of an otherwise qualified individual with a disability who is an applicant or an employee unless undue hardship to the Company would result",http://www.indeed.com/rc/clk?jk=a2534a16615769d4&fccid=f5bc88a985976dd0&vjs=3
Oracle Data Engineer,Fidelity TalentSource,"Boston, MA 02210",,"Fidelity TalentSource is your destination for discovering your next temporary role at Fidelity Investments. We are currently sourcing for an Oracle Data Engineer to work in Fidelity’s Asset Management Technology in Boston, MA.
Asset Management Technology (AMT) is looking for an Oracle Data Engineer focused on our data tier to support as we design, build and advance our Managed Accounts capability. We are looking for individuals who continually strive to advance engineering excellence, agile delivery, and technology innovation in a highly collaborative environment.
The Expertise We’re Looking For
Expertise with Oracle 12c, data movement technologies, Spotfire, and proficiency in designing solutions
Excellent Design & Analysis skills with a demonstrated ability to align to long term strategies through interim states
Experience working on delivering solutions for globally distributed, large scale Agile software development teams

The Purpose of Your Role
You will serve as an engineer and thought leader within our Engineering team. You will interface directly with business partners to understand problems & opportunities and recommend solutions. You will be a key player as we scale our platform to support forecasted growth.
The Skills You Bring
You consistently drive strong collaboration, open communication, and reach across functional borders
You are able to understand business problems and able to design scalable solutions
You have a relentless commitment to quality and engineering excellence
You have an ability to design and build performant solutions that scale and support stringent SLAs
You are able to work successfully in an environment that encourages autonomy in the work that you do
You are motivated, an excellent communicator, can take initiative to solve problems, and can make decisions based on the value of the solutions we build.
You understand engineering best practices and have an aptitude to coach and mentor others on the team

The Value You Deliver
As a data engineer, you will play a key role in shaping how our products are designed and developed
Bring creativity and innovation, and experiment where needed, to provide solutions that help us deliver for the business.
Position the organization for growing the Managed Accounts business

How Your Work Impacts the Organization
Fidelity Asset Management Technology provides worldwide technology and support to all the Portfolio Management, Research, Trading and Investment Operations functions. Asset Management Technology is an integral partner for Asset Management to deliver innovative, scalable, industry-leading investment tools that enables the business to achieve competitive advantage globally.
Company Culture
At Fidelity, you can find it all here. We reward ambitious, passionate individuals with a work environment that fosters diversity, teamwork and collaboration as well as encourages innovative ideas and fresh thinking. We recognize the value that employees’ individual differences can contribute to the bright and strong future of our company.
Company Overview
Fidelity TalentSource, formerly Veritude, is the in-house temporary staffing provider for Fidelity Investments, one of the largest and most diversified global financial services firms in the industry. We recruit individuals from a variety of backgrounds, including technology and customer service, to fill assignments across Fidelity’s U.S.-based regional and investor center locations. If you would like to experience Fidelity’s diverse and inclusive workplace while expanding your skillset and developing your professional network, consider a role with Fidelity TalentSource.
For information about working at Fidelity TalentSource, visit FTSJobs.com.",http://www.indeed.com/rc/clk?jk=90df12e035532354&fccid=7df8513443c7134a&vjs=3
"Data Engineer, Enterprise Data Engineering",ZoomInfo,"Vancouver, WA",,"Are you looking for an opportunity to challenge yourself? At ZoomInfo our employees work hard to ‘define new possibles’, and they are driven by winning. ZoomInfo is a company that got to where it’s at today on the backs of heroic efforts, over the years, by our employees and we are looking for more people to contribute to those efforts. At our company you’ll see that collaboration is second nature, and you’ll be greeted by a team of incredibly smart, talented, and motivated individuals who will help you define your new best. You’ll be presented with opportunities to both personally and professionally develop as you build your career. We believe that our employees love to work and love to work here, and that you will like coming to work because of the sense of accomplishment you get from being a part of what we’re building. You are a fit for our team if you refuse to lose, you seek challenges, and you love to win. We welcome you to join our team of difference makers who are people working with a passion to win together.

This team is responsible for ingesting, transforming, storing, and maintaining data for business intelligence, analytics, data quality, and data science usages.

Responsibilities
Analyze large data sets to inform data pipeline design
Build data pipelines to move data from a variety of sources into our data lake and data warehouse
Consolidate/join/transform datasets to create consumable, performant, and consistent information
Look for ways to automate processes currently performed manually to improve efficiency
Support end users and teammates on code-related questions and issues
Create and maintain documentation
Qualifications and Experience:
Proficient in SQL
Experience with Python or another programming language
Experience with Spark, EMR and/or Databricks
Experience developing and maintaining ETL code
Familiar with relational databases and semi-structured data
Experience working with third party APIs for data collection
Experience with orchestration tools such as Airflow
Experience with AWS and/or Google Cloud
Experience with Snowflake Data Warehouse is a plus
Ability to communicate effectively with, and provide excellent customer service to stakeholders at all levels of the organization.
Self-motivated; able to work independently to complete tasks and collaborate with others to identify and implement solutions
Bachelor's Degree in Computer Science, Information Systems, Data Science, or related field and 1+ years of experience in data engineering, or an equivalent combination of education and experience

Built over 20 years ago, ZoomInfo Powered by DiscoverOrg has become the go-to-market standard for over 13,500 companies worldwide. Designed to be the single source of truth, the ZoomInfo platform offers best-in-class technology paired with unrivaled data coverage, accuracy, and depth of contacts, companies, and opportunities essential to empower sales, marketing and recruiting professionals to hit their numbers. Deeply embedded into business workflows and technology stacks- including integrations with the leading CRM, Sales Engagement, Marketing Automation, and Talent Management applications - ZoomInfo is capable of delivering more predictable, accelerated, and sustainable growth than any stand-alone solution.",http://www.indeed.com/rc/clk?jk=611b085b9900a34e&fccid=56c25448bab54e90&vjs=3
Data Engineer,ICF,"Fairfax, VA 22031",,"Job Description: We’re looking for a SQL Server Integration Services (SSIS) Developer, someone who thrives not just developing, but owning the full development lifecycle to create and maintain solutions which work with a wide variety of data sources to create robust ETL solutions for ingesting, processing, archiving, and sending large quantities of data using reusable and scalable data solutions, both on premise and in the cloud.
What you’ll be doing:
• Design, develop, and test a wide variety of custom SSIS packages, with maximum focus on reusability and scalability.
• Provide technical assistance to Business Analysts and Project Managers by reviewing their requirements to ensure they can be translated into ETL solutions.
• Provide quick turnaround technical and analytic support, including managing multiple tasks, to a wide variety of business owners who have rapidly evolving client demands.
• Maintain data integrity across a wide variety of Energy Efficiency programs, including troubleshooting data quality issues and communicating their impacts.
• Help the larger team define and implement best practices to improve processes and outputs.
Basic Qualifications:
• Bachelor's degree in a technical field (e.g., Computer Science, Engineering or related discipline)
• 3+ years of experience with Microsoft SQL Server Technologies and applying it to the software development process
• 2+ years of experience working in a data warehousing environment creating data pipelines with ETL tools such as SSIS and SSMS (2012 or higher)
• 1+ years of database development experience using T-SQL on stored procedures
• Analytical thinking, looking into logic-based details while problem-solving for the overall big picture
Preferred Skills/Experience:
• Exposure to the utility, energy, and/or energy efficiency sectors a plus
• Experience with Power BI, SSRS, or Tableau.
• Experience with working in SQL Server in Azure
Professional Skills:
• Excellent listening, written, and oral communication skills paired with an excellent sense of humor
• Ability to exercise independent judgment while effectively prioritizing and executing tasks while under pressure
• Self-motivated team player with the ability to work in a fast-paced environment
Working at ICF
Working at ICF means applying a passion for meaningful work with intellectual rigor to help solve the leading issues of our day. Smart, compassionate, innovative, committed, ICF employees tackle unprecedented challenges to benefit people, businesses, and governments around the globe. We believe in collaboration, mutual respect, open communication, and opportunity for growth. If you’re seeking to make a difference in the world, visit www.icf.com/careers to find your next career. ICF—together for tomorrow.
ICF is an equal opportunity employer that values diversity at all levels. (EOE – Minorities/Females/ Protected Veterans Status/Disability Status/Sexual Orientation/Gender Identity)
Reasonable Accommodations are available for disabled veterans and applicants with disabilities in all phases of the application and employment process. To request an accommodation please email icfcareercenter@icf.com and we will be happy to assist. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. Read more about non-discrimination: EEO is the law and Pay Transparency Statement .
Fairfax, VA (VA01)",http://www.indeed.com/rc/clk?jk=f6557d241ef06233&fccid=cc35f9c14f8799a9&vjs=3
Database/Data Engineer,NCI Information Systems Inc.,Remote,,"Responsibilities:
As a Database/Data Engineer, you are responsible for developing and managing database solutions and for working closely with development and engineering teams on overall development strategy and data ingestion. You provide support to product deployment strategy, metrics, and measures for automated scaling. You apply Agile best practices to collaborate and participate in creating user stories for business functionality, technical requirements and defining acceptance criteria to ensure the delivery of data solutions. In assuming this position, you are a vital contributor to meeting NCI's mission: To deliver innovative, cost-effective solutions and services that enable our customers to rapidly adapt to dynamic environments as well as to expand our AI solutions.
RESPONSIBILITIES
Lead development of material management database, migrating from an Oracle instance into a modern cloud DB solutions.
Provide database server administration support and incident management and service request responses
Meet both technical and consumer needs.
Manage and implement database technology transition, including the sunset of older database technologies.
Execute disaster recovery and continuity of operations support.
Be available for off-hours support as needed.
Work across development and operational environments.
Stay abreast of database technologies and best practices.
Skillful of multitasking and managing multiple simultaneous high priorities a must.
Qualifications:
REQUIREMENTS
DoD secret security clearance (or interim secret)
Bachelor’s degree in Computer Science or Engineering discipline.
4-9 years of database development in Defense or secured Government Installations.
Experience with Oracle DBA, MS SQL MSCA, or MSCE, Enterprise DB (EDB) preferred.
Knowledge in Database development and administration in cloud solutions preferred.
Familiar with leading data migrations from Oracle Databases.
Working experience architecting, designing, and implementing databases as well as implementing and executing ETL tools.
Experience with NAVSEA financial systems, such as CSAS, or MSE PROD is preferred.
Experience transforming large, government programs to the cloud.
Strong written and oral communication skills.
PHYSICAL REQUIREMENTS:
This position requires the ability to perform the below essential functions:
Sitting for long periods
Standing for long periods
Ambulate throughout an office
Ambulate between several buildings
It is the policy of NCI to provide equal opportunity in recruiting, hiring, training, and promoting individuals in all job categories without regard to race, color, religion, national origin, gender, age, disability, genetic information, veteran status, sexual orientation, gender identity, or any other protected class or category as may be defined by federal, state, or local laws or regulations. In addition, we affirm that all compensation, benefits, company-sponsored training, educational assistance, social, and recreational programs are administered without regard to race, color, religion, national origin, gender, age, disability, genetic information, veteran status, sexual orientation, or gender identity. It is our firm intent to support equal employment opportunity and affirmative action in keeping with applicable federal, state, and local laws and regulations. NCI is a VEVRAA Federal Contractor.",http://www.indeed.com/rc/clk?jk=f362fb70339c6f3a&fccid=fd5b58008c9f15f4&vjs=3
Data Engineer,First Republic Bank,"San Francisco, CA 94111",,"Â :
At First Republic, we care about our people. Founded in 1985, we offer extraordinary client service in private banking, private business banking and private wealth management. We believe that personal connections are everything and our success is driven by the relationships we form with our colleagues and clients. You’ll always feel empowered and valued here.
Incredible teams doing exceptional work, every day
In Technology, we support First Republic’s employees and clients through the acquisition, integration and management of the Bank’s information technology systems and services. We drive innovation and explore emerging technologies so our people can be productive and focus on what matters most – providing extraordinary service.
Want to help a great team protect a fantastic Bank monitor potentially fraudulent client activity in a supportive, collaborative environment?

ETL developer with strong technical skills to understand requirements and build quality data solutions. Work closely with business and technology teams to define, test, develop and deploy code to satisfy requirements and prevent application/system outages.
Â :
What you’ll do as a Data Engineer for the Actimize team:

You will support and create the ETL solutions for the BSA/AML group. This includes, transforming business requirements into data solutions via technical tools and gathering domain knowledge about the BSA/AML supported ETL jobs and data sets. Eventually, you will be a Subject Matter Expert on the data and BSA/AML related applications and systems.
Â :
You could be a great fit if you have:

Self-starter with strong technical skills in ETL, scripting, database and data tools. Experience using Informatica, SSIS, Python and SQL scripting. Excellent communication skills with internal team as well as with business partners and management; team player with accountability to own your own work, but also support a collaborative work environment.

Own your work and your career — apply now
Are you willing to go the extra mile because you love what you do and how you can contribute as a team? Do you want the freedom to grow and the opportunity to take charge of your own career? If so, then come join us.

We want hard working team players. You’ll have the independence to learn, lead and drive change. A culture of extraordinary service, empowerment and stability — that’s the First Republic way.

First Republic is subject to federal laws that restrict the employment of individuals with certain types of criminal histories, including FDIA Section 19 and FINRA. To the extent not inconsistent with our obligations under those federal laws and regulations, First Republic will consider qualified candidates with criminal histories in a manner consistent with the Los Angeles and San Francisco ban-the-box laws.",http://www.indeed.com/rc/clk?jk=ecde5ac6e75b1062&fccid=e228a3c78d0f7f13&vjs=3
Data Engineer,Universal Electronics,"Santa Ana, CA 92707",,"Overview-We will consider Junior/Mid-level and Senior Level
Our vision is beyond a connected home, rather a smarter home where technology is your friend and not an obstacle. Consumer electronics is one of the fastest growing industries in the world. Trends in Technology change every season and new devices are making way into the homes of people faster than ever. Interacting with these devices is a challenge.

Our team is focused on next generation distributed platforms for the connected home ecosystem; we solve real life problems and bring improvements to the masses. We are infatuated by technology; however only see it as the means and not the goal itself. We accept no boundaries and no problem should remain unresolved.

Here you will design products and technologies that are touched by well over 450 million people every week, and we’re just getting started! We design & developed an extraordinary number of products for the connected home, backed by a complete ecosystem of data driven software solutions & cloud services for connected devices from leading brands in mobile, gaming and consumer electronics segments!

Visit our links for more insight: https://www.youtube.com/user/ueicorporate https://www.instagram.com/nevolabs/ https://twitter.com/nevolabs
Responsibilities
This role has responsibility to lead the overall technical architecture and development of data infrastructure and cloud services to enable a range of new data driven high performance applications.
Work with key individuals to identify, prioritize, manage and track outstanding development tasks.
Build and refine the infrastructure, data architecture, data models, and integration architecture while also ensuring the solutions supports user-driver, self-service analytics.
Design and develop tools to process large data sets with statistical algorithms, machine learning, data mining and predictive simulations.
Design, evaluate and optimize database structures (tables, views, and functions) while developing methods / scripts for monitoring database capacity, usage and performance.
Design and optimize database schema, architecture, queries, and complex stored procedures, for OLTP, OLAP and unstructured data services.
in a team environment to design, implement, extend, and maintain both internal as well as customer facing web services.
Desired Skills and Experience
BSCS preferred, may consider alternative education
Possess a strong technical background and able to learn and apply new topics quickly and efficiently.
Superior verbal and written communications skills.
Proficiency in backend Microsoft technologies.
Must have a focus on Data Engineering and Operations
Ability to implement modern Data tools and concepts such as Data Lakes, Data Warehouses, NoSQL, Data Distribution
Experience working within a multi-country, multi-timezone fast moving team
Performance analysis and tuning of data access at scale is a big plus
Experience with replication, disaster recovery
Experience working within a MicroSoft environment
Fluency in modern data architectures (e.g. NoSQL, Cosmos, Hadoop, Data Warehouse)
Familiar with Data Modeling disciplines and advanced data patterns (ie. Document based storage / dimensionalized schemas and containerized data models).",http://www.indeed.com/rc/clk?jk=1318f9d37913f3f9&fccid=2cfd7ba40e131adb&vjs=3
Data Engineer Consultant (838509),Systemart LLC,"Newark, NJ",,"Basic qualifications

Strong Computer science background required. A Bachelor’s degree or higher in computer science or equivalent is required
10+ years of experience in a Data Warehouse (DWH) environment with data integration/ETL of large and complex data sets
Design and coding skills in a scripting language (e.g. Python/Perl/shell scripting) on Unix/Linux Platforms.
Proficiency in SQL and database technologies such as AWS Redshift
Data modeling skills such as Star/Snowflake schema design for DWH
Expertise in performance tuning and scaling in a DWH environment
Hands on experience with recent advances in distributed computing such as MapReduce, MPP architectures, NoSQL databases.
Familiarity with Business Intelligence (BI) platforms such as MicroStrategy, OBIEE or equivalent
Good interpersonal and communication skills. Ability to work with different teams for sourcing of data.
Ability to learn fast, work independently with little supervision and deliver on time quality products

Preferred qualifications

Extensive knowledge of BI platforms such as MicroStrategy, OBIEE or equivalent
Experience working with Agile methodologies in a DWH/BI environment
. Skillset Required: Basic qualifications

Strong Computer science background required. A Bachelor’s degree or higher in computer science or equivalent is required
10+ years of experience in a Data Warehouse (DWH) environment with data integration/ETL of large and complex data sets
Design and coding skills in a scripting language (e.g. Python/Perl/shell scripting) on Unix/Linux Platforms.
Proficiency in SQL and database technologies such as AWS Redshift
Data modeling skills such as Star/Snowflake schema design for DWH
Expertise in performance tuning and scaling in a DWH environment
Hands on experience with recent advances in distributed computing such as MapReduce, MPP architectures, NoSQL databases.
Familiarity with Business Intelligence (BI) platforms such as MicroStrategy, OBIEE or equivalent
Good interpersonal and communication skills. Ability to work with different teams for sourcing of data.
Ability to learn fast, work independently with little supervision and deliver on time quality products

Preferred qualifications

Extensive knowledge of BI platforms such as MicroStrategy, OBIEE or equivalent
Experience working with Agile methodologies in a DWH/BI environment

",http://www.indeed.com/rc/clk?jk=d5b969faeea1edda&fccid=f9dd3166cf821eca&vjs=3
Network Data Engineer,Finite State,"Columbus, OH 43215",,"At Finite State, we are leveraging massive amounts of data to solve the next generation of security problems generated by the Internet of Things (IoT). We are seeking a Network Data Engineer with special interest in firmware analysis. If you are a self-starter who enjoys working in a fast-paced, collaborative environment, then we want to talk to you!

Primary responsibilities for this position include:

Manage the ingestion, flow, and processing of network data through our analytics pipeline.
Develop new modules for parsing and analyzing network protocols and communications.

Candidates at a minimum must have experience in the following:


Python Development
Strong understanding of the TCP/IP network stack and common protocols.
Experience with large scale and fast moving data sets
AWS Cloud capabilities and features
NoSQL and SQL database technologies
Source control (Github)

It’s preferred (but not required) that candidate have familiarity and experience with:


CI/CD tooling
Docker
Python Alembic
Django
WireShark
PCAP Analysis
ETL frameworks such as Apache NiFi or Pentaho
Unified Query Layers such as Apache Drill

About Finite State

Built on two decades of cybersecurity experience serving the Fortune 50 and the U.S. Intelligence Community, our team of experts understands the hidden risks in today’s enterprise networks, where IoT vulnerabilities are quickly becoming the entry point of choice for cyber attacks.

Finite State gives cyber defenders a tactical advantage by identifying the devices running on the network and proactively analyzing firmware buried inside the IoT devices for hidden vulnerabilities. We have a sense of duty to protect the critical infrastructure we rely on including medical devices, power grids and telecommunication networks. We were founded in 2017 in Columbus, Ohio.

At Finite State, we are dedicated to hiring a diverse workforce and are proud to be an equal opportunity employer. We offer competitive salary, equity, full benefits (medical, dental, vision, disability and life-insurance), 401k plan and unlimited PTO, because we believe it is important to unplug and recharge.

Come help us solve one of the biggest problems in cyber security!",http://www.indeed.com/rc/clk?jk=9924851e3d24b140&fccid=f8bbcff726a39180&vjs=3
Maps Evaluation Software Engineer,Apple,"Santa Clara Valley, CA 95014",,"Summary
Posted: Jul 22, 2020
Weekly Hours: 40
Role Number:200158049
Maps Evaluation is looking for a senior maps engineer, one with an eye for quality and a passion for automation and spatial analysis. The ideal candidate will be one with substantive professional experience working in a Maps data or Maps QA role, specifically one that has worked with 3D spatial data and has a deep understanding of geospatial applications, techniques, and transformations.
This team supports an R&D project that is still going through prototyping stages, meaning that there will be a lot of ad hoc analysis and feedback required among our team, data teams, project managers, and content specification teams. The successful candidate will help to lead those efforts, ensuring that our hard work is communicated to key stakeholders to help shape a successful (yet-to-be-released) Maps product.
Key Qualifications
6+ years of experience of applied spatial analysis in a professional setting, working in a medium-to-large scale mapping enterprise (comfortable working with big data)
6+ years of frequent practical application of Python and Scala programming languages
5+ years of experience writing complex SQL, PostGIS and Hive queries
5+ years experience working with 3d data and analyzing its spatial fidelity
5+ years experience working with remote sensing technologies (imagery, LiDAR, etc), to include: a comprehensive understanding of projections, transformations, sensor limitations and resolutions, absolute vs. relative accuracy, and the intricacies of working with high quality topographic data
A strong understanding of remote sensing technologies (imagery, LiDAR, etc) would be a bonus
Excellent written and oral communication skills
Good collaborative and presentation skills
Strong understanding of map data QA methodologies
3+ years of experience in a Test Engineering is a bonus
1-2 years of experience working with Tableau (preferred) or a similar dashboard reporting solution is a bonus.
Description
- Develop and implement test plans for high-resolution spatial data
- Identify and execute improvements to ETL pipelines
- Comfortable working on R&D projects, where the only constant is that things will change
- Comfortable working under vague direction and leading more junior engineers and maps analysts
- Foundational knowledge of statistics allows the candidate to design and implement meaningful
 spatial statistics
Education & Experience
- B.S or advanced degree in Geography, GIS, Computer Science, or related field
- Prior experience with Github or other source control systems
- Shell scripting and Unix-based system administration",http://www.indeed.com/rc/clk?jk=67b6fd27585faa85&fccid=c1099851e9794854&vjs=3
Associate Data Engineer,KIPP Foundation,"Washington, DC 20566",,"ORGANIZATIONAL OVERVIEW
At KIPP DC schools, students develop the knowledge, skills, and confidence to become Washington DC’s next generation of leaders. Equipped with a KIPP DC education, our alumni are empowered to be successful in college, careers, and life.

KIPP DC schools educate and support students in the District of Columbia who have historically had limited access to quality educational options. We are grounded in a commitment to excellence, equity, and justice. Our central headquarters team supports KIPP DC’s 18 schools, 6,800 students and families, and 1,000 staff members—ensuring KIPP DC remains the highest performing PreK – 12 school system in the District of Columbia.

POSITION OVERVIEW
The Data Engineer is a key member of the KIPP DC Data and Analytics team that supports the automated delivery of data between student data systems. This work enables the organization to perform timely data analyses and provide automated access to school software. This role is an entry-level position supporting the development and maintenance of sustainable data integration pipelines. The Data Engineer reports to the Director of Data Strategy.

KEY RESPONSIBILITIES
Support user management processes that automatically provision staff and student accounts for school software directly and through middleware applications such as Clever and Okta
Assist in the development and maintenance of automated data integration processes related to student data and software access management
Lead troubleshooting efforts related to ETL (extract, transform, load) processes and data quality issues
Proactively monitor data for completeness and accuracy and communicate with impacted stakeholders when issues are identified
Manage KIPP DC’s student data warehouse and reporting platform
Develop, test and maintain database architectures to ensure data integrity standards are met.
Maintain KIPP DC’s data dictionary which describes the contents, format, and structure of the data warehouse and the relationship between its elements
Support Director of Data Strategy in long-term strategy efforts to expand the data domains held in the warehouse to other departments (i.e. Operations, HR, Finance, etc.)
Perform maintenance and support tasks on the reporting platform, Tableau Server.
Work with data team to increase capacity for data analysis
Respond to requests from data team to resolve any issues related to integration failures or errors
Assist data analysts in developing SQL queries for reporting and analysis
Support in identifying, designing, and implementing internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.

QUALIFICATIONS
Bachelor's degree
0-3 years of professional experience
Experience with SQL query development is required.
Experience with Python or one other scripting language (R, Javascript, etc.)
Experience with the above in an educational context is a plus.

QUALITIES OF TOP CANDIDATES
Ability to perform a variety of professional activities involved in the research, collection, organization, analysis, processing, interpretation, and reporting of academic and operational data
Outstanding project management and organizational skills, and extraordinary attention to detail
Works effectively with others to achieve shared goals through cooperation, sharing knowledge, joint problem-solving, and celebrating success
Excellent communication and presentation skills in order to share recommendations with colleagues
Creative problem-solving skills and critical thinking
Ability to work within a diverse, global workforce that is oriented around customer satisfaction
Ability to continually develop and improve one’s skill and knowledge to perform effectively and adapt to change in the workplace and external landscape
Ability to work in a fast-paced environment under tight deadlines
Familiarity with the K-12 education field is a plus
Unquestioned integrity and commitment to KIPP DC’s mission
Flexibility, tenacity, high quality work, resourcefulness, teamwork, and a sense of humor

TO APPLY
Please email careers@kippdc.org to complete an online application (including submission of a resume and cover letter) for the position. The start date for this position is immediate. Salary and benefits are competitive, commensurate with qualifications and experience.",http://www.indeed.com/rc/clk?jk=f778b2b41af4835a&fccid=7db14b470ed12322&vjs=3
Data Engineer,The New York Times,"New York, NY",,"The New York Times is seeking inventive and motivated data engineers at all levels of experience to join the Data Engineering group. In this role, you will build critical data infrastructure that surfaces data and insights across the company.
About Us
Our Data Engineering teams are at the intersection of business analytics, data warehousing, and software engineering. As Maxime Beauchemin wrote in “The Rise of Data Engineering”, ETL and data modeling have evolved, and the changes are about distributed systems, stream processing, and computation at scale. They’re about working with data using the same practices that guide software engineering at large. A strong data foundation is essential for The New York Times and we’re responsible for it. We use our data infrastructure to power analytics and data products and to deliver relevant experiences to our customers in real-time. We enable our company to validate strategic decisions, make smarter choices, and react to the fast changing world. We are part of a New York based technology organization with a remote-friendly workplace that includes engineers around the world. We value transparency and openness, learning, community, and continuous improvement. Check out the Times Open blog, which is written by engineers and other technical team members, and follow @nytdevs on Twitter to see what we’re up to.
About the Job
We focus on the software engineering related to data replication, storage, centralized computation, and data API’s. We provide customers and partners with data tools, shared frameworks, and data services. These are the foundational core of our group which enables ourselves and others to work with data from a common underpinning. Our tools and services enable our group to scale and avoid blocking others. We reduce data redundancy by creating systems and datasets that serve as sources of record. We enable discovery and governance of our data. We support key business goals like growing our digital subscriber base, understanding how our customers use our products, and retaining our print subscribers.
As a data engineer, you will:
Run and support a production enterprise data platform
Design and develop data models
Work with languages like Java, Python, Go, Bash, and SQL
Build batch and streaming data pipelines with tools such as Spark, Airflow, and cloud-based data services like Google’s BigQuery, Dataproc, and Pub/Sub
Develop processes for automating, testing, and deploying your work
About You
To thrive in this role, you are excited about data and motivated to learn new technologies. You are comfortable collaborating with engineers from other teams, product owners, business teams, and data analysts and data scientists. You are own and shape your technical domain area and move the related business goals forward. You are eager to resolve upstream data issues at the source instead of applying workarounds. You analyze and test changes to our data architectures and processes, and determine what the possible downstream effects and potential impacts to data consumers will be.
Benefits and Perks:
Make an impact by supporting our original, independent and deeply reported journalism.
We provide competitive health, dental, vision and life insurance for employees and their families
We support responsible retirement planning with a generous 401(k) company match.
We offer a generous parental-leave policy, which we recently expanded in response to employee feedback. Birth mothers receive 16 weeks fully paid; non gestational parents receive 10 weeks, also fully paid.
We are committed to career development, supported by a formal mentoring program and $8,000 annual tuition reimbursement.
We have frequent panel discussions and talks by a wide variety of news makers and industry leaders.
Join a community committed to the richness of diversity, experiences and talents in the world we cover, supported by a variety of employee resource groups.
This role may require limited on-call hours. An on-call schedule will be determined when you join, taking into account team size and other variables. On-call hours are unpaid, unless informed otherwise by your manager.
#LI-AM1
The New York Times is committed to a diverse and inclusive workforce, one that reflects the varied global community we serve. Our journalism and the products we build in the service of that journalism greatly benefit from a range of perspectives, which can only come from diversity of all types, across our ranks, at all levels of the organization. Achieving true diversity and inclusion is the right thing to do. It is also the smart thing for our business. So we strongly encourage women, veterans, people with disabilities, people of color and gender nonconforming candidates to apply.
The New York Times Company is an Equal Opportunity Employer and does not discriminate on the basis of an individual's sex, age, race, color, creed, national origin, alienage, religion, marital status, pregnancy, sexual orientation or affectional preference, gender identity and expression, disability, genetic trait or predisposition, carrier status, citizenship, veteran or military status and other personal characteristics protected by law. All applications will receive consideration for employment without regard to legally protected characteristics. The New York Times Company will consider qualified applicants, including those with criminal histories, in a manner consistent with the requirements of applicable state and local ""Fair Chance"" laws.",http://www.indeed.com/rc/clk?jk=c30c3f753af35a48&fccid=1b50fcfb150b1b48&vjs=3
AWS Data Engineer,Capgemini,Pennsylvania,,"Short Description
About Capgemini

A global leader in consulting, technology services and digital transformation, Capgemini is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50-year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. It is a multicultural company of over 200,000 team members in more than 40 countries. The Group reported 2018 global revenues of EUR 13.2 billion (about $15.6 billion USD at 2018 average rate).
Visit us at www.capgemini.com. People matter, results count.
Job Responsibilities
Title: AWS Data Engineer
Location: Horsham, PA

Understanding of software engineering processes and system development life cycles
Strong problem solving skills and capability to understand and set direction for complex technology integration
Good interpersonal written and oral communication skills
Strong teamwork skills and capability to lead teams
Experience with developing data pipeline using Python Spark ETL Informatica and Certified AWS Developer is highly preferred
What we offer
Your career matters to you and is important to us too. Because your goals and needs are constantly evolving, we offer visibility, leeway and support to help you grow and progress in your career. This approach builds notably on our comprehensive competency framework, our personal development, training and career management programs, and our University innovative and business-focused learning curriculums.
We promote a culture of diversity. We believe working with talented individuals from different backgrounds and points of view is a strategic advantage and an ongoing opportunity. Diversity enriches our creative solutions and adds value for our clients.
With the digital tech sector growing at a rapid pace and women significantly underrepresented in the industry, we are determined to inspire and recruit more women into technology and build diverse teams that reflect the clients we serve.
Our Shared values have been at the heart of the group since our formation. They are honesty, boldness, trust, freedom, team spirit, modesty and fun. These values influence the way we meet client needs while respecting the regulatory requirements of each country in which we operate, and the way we promote ethically sound practices within Capgemini and in our partnerships.
Capgemini is committed to building a workforce of employees with diverse backgrounds and work experiences. We strongly encourage women, veterans and active military service personnel to apply.
Disclaimer
Capgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.
This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.
Click the following link for more information on your rights as an Applicant - http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law
Applicants for employment in the US must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in the US by Capgemini.",http://www.indeed.com/rc/clk?jk=4b6fcb188cb8ea96&fccid=105ecfd0283f415f&vjs=3
Data Engineer I,Oath Inc,"Sunnyvale, CA 94089",,"A Little About Us
Oath has the most trafficked destinations on internet, including Yahoo, Aol, Huffington Post, TechCrunch, and many other well known brands. The Oath Advertising team is responsible for delivering market-leading advertising and audience products, solutions, and services. Our advertising products deliver billions of ad impressions to hundreds of millions of users everyday, enabling hundreds of thousands of advertisers to effectively connect with the right audience at the right time across devices and across the globe. Our audience analytics products analyze multi-terabytes of data everyday and deliver insight on the preference, intent, interest, and behavior of users to help Yahoo and its customers drive user growth, engagement and value.
A Lot About You
You are an exceptional data engineer with rich experience in big data processing, excellent analytical skills, sound knowledge about statistics and experimental design, and proven ability to communicate analytical findings. You are always curious, self-motivated, and eager to learn learning new domain knowledge and analytics tools. You are an out-of-the-box thinker, a believer in data driven approaches, and a quick learner. You enjoy to work with a strong, cross-functional, and sometimes cross-geography team of engineers and data scientists, and you are passionate in working with our business and product teams to turn data into actionable insights. You always think positive, have the can-do attitude, and focus on “getting stuff done” with quality. People like to work with you because you’re a valuable contributor, and a responsible team player.
Your Day
• Build a centralized data warehouse, automated data pipelines and dashboards to provide concrete metrics for various internal users, including business, product and engineers
• Work closely with engineers, data scientists, business and ad operations to track, monitor, and report on ad platform health, and identify and resolve potential issues related to the ad serving systems
• Analyze large data sets to find structures and obtain actionable insights for improving the overall performance of the end-to-end advertising process
• Design and conduct experiments to evaluate new advertising algorithms and serving logics
Requirements
• Advanced degree in Statistics, Applied Mathematics, Computer Science, or a related field
• Proficient programming skills in at least one of the following languages: Python, R, and Java, and familiar with Hadoop and SQL
• Excel in statistical thinking while deeply grounded in solid business judgment
• Results driven, great attention to detail, and a team player
• Excellent communication and presentation skills
• Skilled in interpersonal communication and relationship. Ability to clearly explain analytical findings to business partners, researchers and engineers
Verizon Media is proud to be an equal opportunity workplace. All qualified applicants will receive consideration for employment without regard to, and will not be discriminated against based on age, race, gender, color, religion, national origin, sexual orientation, gender identity, veteran status, disability or any other protected category. Verizon Media is dedicated to providing an accessible environment for all candidates during the application process and for employees during their employment. If you need accessibility assistance and/or a reasonable accommodation due to a disability, please submit a request via the Accommodation Request Form ( https://www.verizonmedia.com/careers/contact-us.html ) or call 408-336-1409. Requests and calls received for non-disability related issues, such as following up on an application, will not receive a response.
Currently work for Verizon Media? Please apply on our internal career site.",http://www.indeed.com/rc/clk?jk=3bfbea4b4778569e&fccid=ec7026b814653f27&vjs=3
Data Engineer Intern,"Gotion, Inc.","Fremont, CA",,"Responsibilities

Develop and maintain data platform (ETL) for electrical vehicle battery
Develop and maintain battery visualization dashboards
Working closely with algorithm team and embedded software teams to improve the platform

Qualifications

Able to start presently or Jan 2021. Please do not apply to this listing if looking for summer intern.
BS in Engineering or Computer Science/ Graduate degree preferred.
Proficient in Python, SQL
Familiarity with AWS (or equivalent)
Experience with front-end development is a plus
Experience with time-series database is a plus
Experience with Matlab is a big plus

About Gotion:

Gotion, Inc. is based in Silicon Valley in California, with R&D centers in Ohio, China, Japan and Europe. We innovate in the next generation electric vehicle and energy storage technologies (lithium batteries and related systems) with the aim to accelerate electrified transportation and achieve sustainable development. Gotion is powered by a leading power battery technology company that provides solutions for vehicles including the world's first mass commercial e-bus route.

Gotion is a career destination- we are not simply attempting to just fill another job, but to pursue a dream of global green energy together! We offer outstanding opportunities to individuals seeking an exciting and challenging working environment. Everyone is highly valued and plays a vital role in the growth of our organization.",http://www.indeed.com/rc/clk?jk=a88895421bf1e3a8&fccid=1bb5cd7a8a1cdea4&vjs=3
Data Engineer,Degreed,Remote,,"Degreed is the upskilling platform that connects learning to opportunities. We integrate everything people use to learn and build their careers—skill insights, LMSs, courses, videos, articles, and projects—and match everyone to growth opportunities that fit their unique skills, roles, and goals.

The Data Engineer provides business analysts, data scientists and reporting and analysis tools with timely and accurate data. Degreed amasses a high volume of structured and unstructured data in multiple production systems. In this role, you’ll take ownership of bringing that data together in a data warehouse to enable reporting and analysis activities. In addition, you’ll assist the Data Science team in accessing and making sense of data in its raw form.
RESPONSIBILITIES
Develop data pipelines to extract, transform, and load data using SQL and Python
Design, deploy, and maintain services in our growing Azure-based data infrastructure
Partner with our data analysts to research and develop requirements for new features
Research systems and APIs to find the best way to connect to third-party datasets
Design database schemas and queries to ensure performance
Write automated tests to monitor and ensure end to end data quality
Work with data scientists to experiment with and deploy machine learning models
Consult with teams across Degreed to provide expertise, guidance, and support using data
Other duties as assigned
REQUIREMENTS
2+ years experience writing performant, maintainable, and scalable Python services
Experienced deploying and maintaining high-availability services in production
Experience with one or more data pipeline platforms like Airflow, Stitch, or others
Proficiency with automated testing using tools like pytest
Familiarity with one or more cloud platforms such as Azure, AWS, GCP, etc.
Interest or practical experience with data analysis and visualization an asset
Practical experience with software development processes and tools such as Scrum, code reviews, GitHub, Jira, etc.
Familiarity and/or an interest in distributed systems
Strong verbal and written communication skills
Pragmatic and scrappy, with a passion for startup-up environments
Experience working remotely desired
Lifelong learner, excited to learn new things, with a desire to make it easier for others to do the same!
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

See Degreed Jobs for more details on Degreed and why you should come work with us!",http://www.indeed.com/rc/clk?jk=036b1fc575085d21&fccid=d226dfd6fbcae3b9&vjs=3
Data Engineer US,New Signature,"Washington, DC 20005",,"Join a team of passionate thought leaders in a dynamic and collaborative environment! New Signature's Data & AI team is growing fast and we're looking for our next Data Engineer to join us.

ROLE DESCRIPTION
----------------

What's the story?

As we continue to scale we're looking for the market's best Azure Data & AI specialists to help us grow our business' fastest growing practice, AppDev & Data. You'll be working with the industry's biggest players, delivering innovative greenfield Data Platform builds, Data Integration programmes and implementing bespoke High-Level Data Architectural designs.

Who we're looking for:

Strong experience using the Microsoft Azure BI Stack (ADFv2 , Azure SQL DB, Azure SQL Datawarehouse, Azure Data Lake, Azure Databricks ...)
Strong experience with Azure Databricks or Databricks
Excellent knowlegdge of Apache Spark ecosystem (SPARK 2.3x)
Strong programming skills in Python 3
Writing Spark applications using Python
Build distributed in-memory applications using PySpark & Spark SQL
Knowledge of C# highly desirable
Experience with Power BI
Agile methodolgy experience essential
CI/CD, Azure DevOps experience, highly desirable

Why do people like working here?


Remote working
Flexible hours
Training – 80 funded hours a year
Almost endless variety of projects
Paid travel expenses to customer site
Tier 1 Clients & Partners
Funky Warehouse London Bridge offices
Free breakfast
Top of the range kit – i7 laptop and Jabra Evolve headset
Paid charity days
Paid for trips to industry events

Who are New Signature?

We are a Microsoft house, born in the Cloud. The 2017 Acquisition of Paradigm Systems & Dot Net Solutions by New Signature accelerated a suite of capabilities to support the world's most prestigious and recognisable brands, helping them to become digital organisations powered by the Cloud.

We have over 500 people across the UK, US, Canada, South Africa, the Philippines and Australia, with our UK office growing over 70% YoY and headcount more than tripling.

How has this been possible?

Our values of being Generous, Authentic, Innovative and most importantly, Human, has enabled a unique approach to provide outstanding customer experiences, drive transformational results for clients across all company sizes & successfully deliver pioneering solutions that challenge the status quo. We've quickly established ourselves as a recognized expert at the forefront of Microsoft's technology stack with exceptional services to empower our customers, colleagues, and community.

Join us today and be part of the success story!

OUR CORE VALUES
---------------

Our employees are driven by our values and know that they make a positive difference every time that they help a customer to solve their challenges. Our focus on delivering great customer experiences empowers our people to build rewarding relationships that contribute to our positive work environment. You can learn more about our culture here: New Signature Culture ( https://newsignature.com/about/company/ )

Human
-----

We use our hearts and minds to collaborate for success.

We harness technology to drive business, but we never let that replace our human connections. We use our hearts and minds to collaborate for success and instill confidence in our customers through relationships forged from trust.

Generous
--------

We are giving and respectful.

With our efforts to always be generous, we elevate our service level with empathetic and considerate communications and actions. We always find a way to support our customers and colleagues by giving of our time and talent and equally respecting the time and talent of others.

Authentic
---------

We tell it as it is, with positive intent.

Being authentic helps to nurture our strong and trusted relationships. We are honest, transparent, and reliable. When you partner with New Signature, you are partnering with a group of purposeful, outcome-driven and results-oriented professionals.

Innovative
----------

We push the boundaries at the intersection of people, process and technology.

For us, there are no limit to our dreams. We continually innovate and push boundaries at the intersection of people, process, and technology to bring our customers and colleagues the best solutions first.

EQUAL EMPLOYMENT OPPORTUNITY
----------------------------

As a Global Cloud Transformation Consultancy business, New Signature understands diversity and inclusion in the workplace brings benefits to our customers, our business and most importantly, our people. We are committed to being an inclusive employer and we provide equal employment opportunities to all employees and applicants for employment.

New Signature prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other factors protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including all aspects of the recruiting and employment life-cycle at New Signature.

EMPLOYMENT ELIGIBILITY
----------------------

New Signature requires candidates to prove eligibility to work in the UK. Offered candidates may be asked to complete a background check as permitted by applicable employment regulations. Depending on the requirements of the job, these record checks may include any or all of the following education verification, employment verification, drug screening, and criminal record check.",http://www.indeed.com/rc/clk?jk=60110816e6b051b1&fccid=f537209340bad710&vjs=3
Data Engineer,"TalentMovers, Inc.","Mountain View, CA",,"Position Title: Data Engineer
Location: Mountain View, CA
Duration: Long Term
Due to Covid situation client has agreed to onboard the candidate on remote basis for now but once everything restore consultant is required to work from client office
Responsibilities:
Partner with members of the team to develop a deep understanding of what & how data is used.
Collaborate with others in building innovative data capture and real-time customer data analytic capabilities needed by the business (e.g. requirements identification, design specification, prototype testing)
Work side-by-side with cross-functional team including other members of the SAS community, SBSEG Analytics, and partner DBAs to develop the most optimal data experience.
Rewrite/rebuild processes existing in SAS using SQL (AWS EMR Hive)
Solid communication skills: Demonstrated ability to explain complex technical issues to both technical and non-technical audiences
Educates and provides guidance to business stakeholders on how best to harness available data in support of business needs, makes recommendations, and provides alternatives to meet business needs
Creates complex software programs and applications for management of massive quantities of data (big data) using high level programming languages
Develop and test automated data extractions and data feeds to our e-mail vendors in support of trigger-based e-mail marketing campaigns.
Develop and test ad hoc data extraction queries in support of one-time e-mail marketing campaigns and market research requests.
Automate repeat data requests to create sustainability and efficiencies
Extract and aggregate data for business analysts to enable measurement of key performance indicators.
Ensure all automated data routines run as scheduled with expected results and troubleshoot as necessary when outages occur.
Partner with cross-functional data teams to identify and implement new data capture and aggregation mechanisms to enable more efficient data processing.
Partner with immediate team to improve process, documentation, and data ingestion tools
.
Qualifications:
5+ years relevant experience
Advanced SQL skills to get the data you need from a warehouse (Vertica, Hive, SparkSQL, etc)
Advanced SAS skills
Experience with AWS EMR
Strong ETL experience
Experience using Github and Tidal
Ability to Clean/transform data from raw data inputs
Ability to deep dive into the data to meet stakeholders requirements Outstanding communication skills with the ability to influence decision makers and build consensus with teams
Development and execution of data movement tools using scripts in languages such as SQL, HQL, SAS
Familiar with Software engineering and programming methodologies (e.g., Agile)
Familiar with Vertica environment
Proficient in Microsoft Excel
Strong communications skills with both technical and non-technical audiences
Strong time and project management skills
Ability to prioritize own workload
Ability to work in a fast paced environment with changing priorities
Experience with Alteryx a plus
Experience with marketing automation email systems such Eloqua, Pardot, etc., a plus
BS, MS, or PhD (or equivalent experience) in an appropriate technology field (Computer Science, Statistics, Applied Math, Operations Research)
Sid
TalentMovers, Inc.
Cell # +1 703-349-5365",http://www.indeed.com/rc/clk?jk=d2af3cc9db9cf2a6&fccid=01267275e4614eb0&vjs=3
Data Engineer,NetApp,"Research Triangle Park, NC 27709",,"Job Summary
You will be part of Enterprise Data & Analytics team responsible for supporting all the mission critical systems/services to ensure high Availability and Reliability at Scale. Data Systems Engineer will work closely with key stakeholders both IT and Business to turn data into critical information and knowledge that can be used to make sound business decisions. The individual must have an in-depth understanding of the Data platforms, and business environment and an interest in going beyond the obvious, aptitude for new tools/technologies, and obsession for customer success. Design, build and use the various tools that would help in managing, scaling and monitoring the cutting-edge technology. You must be able to triage complex technical issues in collaboration with various teams
Primary Job Duties:
Develop tools and framework to improve operational efficiency and automation
Design, prototype, implement, test and troubleshoot deployment strategies
Provide support for Data Warehouse and Business Intelligence (BI) solutions and platforms
Participate in design, architecture review and deployment of Data Warehouse data models and solutions.
Automate common, repeatable tasks at large scale to streamline operational procedures
Work with developers on ETL and Reporting framework enhancements that build quality into the development process
Use and maintain version control for application infrastructure
Job Requirements
Experience with Enterprise level Data Analytics Platforms including Data warehouse and Business Intelligence systems
In-depth knowledge of System platforms, and operating systems including Linux & Windows
Experience in one (and preferably more) of the following languages: Java, Python, Shell, Go or Ruby
Exposure to Big Data Analytics (data and technologies), Data Sciences, predictive analytics, modelling, machine learning, in-memory applications
Strong Big data platform experience
Strong Cloud and modern platforms experience
Understanding of Data Analytics application stack - ETL and Reporting tools
Education
A minimum of 5 to 8 years of experience with Bachelor of Science Degree in Computer Science, Management Information Systems, or Business, or related field is required",http://www.indeed.com/rc/clk?jk=fa6055d0dbd532e7&fccid=77cec2f25f9bd7ed&vjs=3
Data Engineer,BlackLine,"Pleasanton, CA",,"Responsibilities:

Responsible for building and maintaining the machine learning data and development platform.
Build, integrate and deploy machine learning solutions into the BlackLine application in collaboration with product management, cloud, engineering and data science teams.
Create and maintain scalable data pipeline in the cloud (AWS and GCP).
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement processes automation and data delivery.
Build infrastructure for optimal extraction, transformation, and loading of data from a wide variety of data sources.
Execute extract, transform and load (ETL) operations on large datasets including data identification, mapping, aggregation, conditioning, cleansing, and analyzing.
Build analytics tools to provide actionable insights into business and product performance.
Keep data separated, isolated and secured.
Assist data scientists in implementing achine learning algorithms and contribute to building and optimizing our product into an innovative industry leader.
Participate in establishing best practices while team is transitioning to new technologies, tools and infrastructure. Maintain specifications and metadata; follow the best practices.
Recommend and implement process improvements.
Maintain specifications and metadata; follow and develop best practices.
Coach and technically train data analysts, if needed.
Qualifications:

5+ years as a data engineer.
Experience with SQL, Python, R languages.
ETL experience using Python.
Experience with Hadoop, Spark, Hive. Presto is a plus.
Practical experience with GIT version control.
Strong familiarity with GCP, AWS, SQL Server.
Comfortable working with open source tools in Unix/Linux environments.
Data warehousing experience, data modeling and database design.
Experience with machine learning packages and various ML algorithms.
Experience with predictive and prescriptive analytics, modeling, and segmentation.
Experience with data analytics, big data, and analytics architectures.
Comfortable handling large amounts of data.
Experience ensuring data and modeling accuracy, cleanliness, reliability.
Works independently without the need for supervision.
Experience translating business requirements into functional, and non-functional requirements.
Strong sense systems and data ownership.",http://www.indeed.com/rc/clk?jk=7f2ee8dfb70a35f5&fccid=e2c3b3361dcb3632&vjs=3
Data Engineer,Horizontal,"Plano, TX",,"*candidates must complete a background check upon offer*

JOB DESCRIPTION:
This is a mixed team of analysts and engineers.

Requirement:
Python
Spark/Scala is also a requirement
SQL
Reporting and dashboarding, analysis and data mining
Some development of small tools; Calculator or data processing
Web Tech - JavaScript, HTML
GitHub experience is useful.

Horizontal is proud to be an Equal Opportunity and Affirmative Action Employer. We seek to provide employment opportunities to talented, qualified candidates regardless of race, color, sex/gender including gender identity and/or expression, national origin, religion, sexual orientation, disability, marital status, citizen status, veteran status, or any other protected classification under federal, state or local law.

In addition, Horizontal will provide reasonable accommodations for qualified individuals with disabilities. If you need to request a reasonable accommodation in order to complete the application or interview process, please contact hr@horizontal.com.

All applicants applying must be legally authorized to work in the country of employment.",http://www.indeed.com/rc/clk?jk=e8035ccff1e3f53e&fccid=8902ec4b71211d48&vjs=3
Data Engineer II / Business Intelligence Engineer II,Khan Academy,"Friendly, MD",,"About Khan Academy

Khan Academy is a nonprofit on a mission to provide a free, world-class education to anyone, anywhere. We already reach millions of students every month and are growing rapidly. We’re building a library of high-quality instructional and practice resources that empowers learners and the teachers who support them. Whether they’re studying metaphors, mitosis, Marbury v. Madison, or multivariable calculus, we want to offer students the resources to realize that they can learn anything.

About the Data Engineer II / Business Intelligence Engineer II role

Khan Academy is looking for a passionate Data Engineer / BI Engineer to help change the world – join us on our mission to provide a free, world-class education for anyone, anywhere. In service to that mission, we are strengthening our Data Engineering (DE) capabilities to enable the organization to use data to inform the decisions we make. As the second hire in our DE team, you’ll have ownership of our enterprise data model and the core data pipelines that power our top line metrics and critical analyses. You’ll work on projects that improve the quality and reliability of our existing data and you’ll also enable entire new areas of the organization with new core data sources and DE solutions.

We’re a small team with big dreams and we’re only just getting started. We have some of the richest educational data in the world, and we want to leverage that data to develop a clearer picture of who our users are, how they are using the site, and how we could better serve them on their educational journey. Your work will enable answering critical and meaningful questions like ""how do students learn most effectively?"" and ""how can we improve our content and product?"".
Job Responsibilities

Systematically build out our enterprise data model and warehouse:

Design, build, and productionize our ever-improving suite of core pipelines and data tables to support standardized reporting and analysis
Collaborate with engineers on the infrastructure team to improve our data technology stack (logging, instrumentation, ETL, security). You may also pitch in to help them bring new data into our warehouse
Partner with other members of the analytics team, the research team, and the broader product and business teams to design and standardize business rules and metric definitions. When needed, you may also assist them in dashboard building for our business audiences
Implement EDW standards and robust monitoring/QA processes to ensure we continue to improve the quality and reliability of our data

Empower every team with data:

Identify, pilot, and deploy whichever tools, datasets, and processes are best suited to increase access to and usage of data across Khan Academy, so that key decisions we make are backed up with solid data and analysis
In addition to supporting members of the analytics team, work with the product, content, philanthropy, marketing teams, and others to bring data to their fingertips, ideally with solutions that allow them to self-serve
You will also build infrastructural data solutions to facilitate reporting to external partners and will ensure the highest standards of data accuracy, reliability, and security

Help instill a ‘data driven’/’data informed’ culture:

Shepherd our Metrics and Data Documentation wiki
Train team members on data skills and tooling
Find creative and insightful ways to report and promote how we’re performing on key metrics
You Need
3+ years experience in the data engineering or data warehousing field; or in a business intelligence field with a strong emphasis on the data modeling and pipeline work. Also ideally in a consumer facing internet business or education setting
Advanced SQL skills (window functions, creating UDFs, DML/DDL commands, etc…)
Experienced in recognizing repeated, inconsistent SQL query patterns and creating solutions that are more performant and cheaper
Proficiency in writing and maintaining data pipelines and data quality monitors in a workflow management tool for productionized solutions, with source control and code review
Proficiency in computer science and software engineering fundamentals, including at least one scripting language (e.g. Python) preferred
Experience across the entire data lifecycle: instrumentation, logging, data modeling, ETL, Business Intelligence and visualization tools, etc.
Excellent communication skills (verbal, written, visual)
Empathy for learners around the world. You love learning and are excited about helping others learn to love learning. You’re motivated to learn new things and share what you learn with the world
Excitement about helping Khan Academy bring a free, world-class education to the world
Benefits

We may be a non-profit, but we reward our talented team extremely well!

Highly competitive salaries and annual bonuses
Ample paid time off as needed – we are about getting things done, not face time
Generous parental leave
Flexible work and time-off schedules to encourage work-family balance and holidays
Delicious catered lunch daily plus lots of snacks and beverages
Great location: short walking distance to Caltrain and downtown Mountain View. We are also open to remote (US + Canada) candidates!
Awesome team events, on-sites and off-sites, company parties and BBQs, and weekly board game nights
A fun, high-caliber team that trusts you and gives you the freedom to be brilliant
The ability to improve real lives and the opportunity to work on high-impact software and programs that are already defining the future of education
Affinity groups where parents, Black and Latinx, women and gender minorities, and LGBT+ identified folks support one another
And we offer all those other typical benefits as well: 401(k) + 4% matching & comprehensive insurance including medical, dental, vision, and life
How to Apply
At Khan Academy, we believe that reaching all learners requires an analytics team that is diverse in every respect, and we are looking for individuals who will help us fulfill our mission by adding to the diversity of our team's experiences, perspectives, and mindsets. With that in mind, tell us briefly how your experiences and perspectives— whether personal, professional, academic, or otherwise— could contribute to the diversity of our team.

Please answer the next two data engineering questions with full details, as if you were verbally answering them in your first interview with the hiring manager:

#1 - Why are you passionate about a career in Data Engineering, and explain why it resonates more than being a Data Infrastructure Engineer (building data tools) or a Data Analyst/Scientist (generating and storytelling insights)?

#2 - Describe a past, specific data engineering solution with major business impact where your main contributions were between the infrastructure team that provided the raw data and the analytics or business team that generated and delivered the insights.


Learn more

Sal’s TED talk from 2011
Sal’s TED talk from 2015
You Can Learn Anything: https://www.khanacademy.org/youcanlearnanything
Our team: http://www.khanacademy.org/about/the-team


We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, or Veteran status.",http://www.indeed.com/rc/clk?jk=d9bee3797f1301fc&fccid=5a41b08a1f7f1794&vjs=3
Enterprise Data Engineer,University of Utah,"Salt Lake City, UT 84112",,"This position is focused on developing and supporting the Enterprise Data Management Layer to support analytical applications across our Teaching and Learning, Finance, Human Resources, and Facilities/Ancillary Services environments. This position will be responsible for the development of functional specifications to fulfill the data requirements for delivering comprehensive business intelligence solutions, data mart design, reporting and analytics. Strong data modeling, SQL skills and knowledge of 3rd party integrations is required.

Located in Salt Lake City, in the foothills of the Wasatch Mountains, the University of Utah is the flagship institution of the State of Utah’s system of higher education and a member of the PAC-12 Conference. Salt Lake City combines the amenities of a major metropolitan area of more than one million people with the friendliness and ease of living of a small, Western city. Seven major ski resorts are within an hour’s drive from campus, and opportunities to pursue activities from biking to hiking to fishing abound. Salt Lake is also home to the Utah Symphony and Opera, the Utah Ballet, several professional sports teams, and a wide range of other cultural and recreational activities.

University Information Technology, the central IT service provider for campus, reports to the Chief Information Officer and is responsible for many of the University of Utah’s most critical common IT resources including the campus network; the Campus Information Services (CIS) portal; UMail, telephone, and online collaboration services; high performance and research computing; information security; teaching and learning technologies; software licensing; and a host of other systems and applications. For more information about UIT visit http://www.it.utah.edu
Responsibilities
Primary responsibility to support customer data needs and requests often involves maintaining large, complex data sets that meet business requirements.Participates in all phases of data warehouse implementation. Identifies pertinent issues and prepares comprehensive design specifications for database design, testing, conversion, and implementation
Translates and documents the results of requirements gathering into a standard format to be used to create the appropriate Business Intelligence (BI) solutionMaintain existing data pipelines and accommodate CDC as required.Delivery of data often pulled using APIs.Analyzes user data to determine business rules and creates data modelsDevelops and delivers BI solutionsWorks with end user to gather reporting requirementsImplements and supports Business Objects/Tableau and other reporting applicationsDevelops strategies and updates the data warehouse in response to changes in reporting requirementsApplies industry standards to the technical architecture of a Business Intelligence solution (Stars, Cubes, Extract Transform and Load (ETL)) to solve business problems or increase business efficiencyIdentifies and recommends methods to normalize and maintain data from disparate systems. Works with other internal UIT teams and external systems support staff to understand the source systems used for the warehouse
Collaborates with users and negotiates to identify and develop additional data sources for the data warehouse consistent with business rules and customer needsCoordinates with Data Warehouse Architects to create and support Business Intelligence environment. Identifies and works with appropriate staff to resolve technical issuesConducts and attends team meetings, and communicates (verbally and in writing) team and project issues to appropriate staff and customers. Presents findings, recommendations, and specifications both verbally and in writing.

This job description is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to the job.

Work Environment and Level of Frequency typically required
Nearly Continuously: Office environment.
Physical Requirements and Level of Frequency that may be required
Nearly Continuously: Sitting, hearing, listening, talking.
Often: Repetitive hand motion (such as typing), walking.
Seldom: Bending, reaching overhead.
Minimum Qualifications
Requires a bachelor’s degree in area of specialty or equivalency and 4-6 years of experience in the field or in a related area.

Department Specific Requirements:
A bachelor’s degree in Computer Science, Information Systems, or a related field, or equivalency required. (2 years related work experience may be substituted for 1 year of education).
4-6 years progressively responsible experience in business intelligence/ETL.
4-6 years of experience in Physical data modelling and business intelligence technologiesAdvanced knowledge of SQL, preferably Oracle
Experienced in use of ETL development tools such as (Informatica, Talend, ODI etc.)
Expertise in REST and SOAP APIs. Demonstrated data integration experience from multiple cloud based vendors (Workday, Salesforce, SuccessFactors etc.)

Applicants must demonstrate the potential ability to perform the essential functions of the job as outlined in the position description.
Preferences
Knowledge of the University’s data requirementsWorking experience in integration with 3rd party vendors using APIs
Good knowledge of maintaining ETL/ELT pipelines and optimization.Strong background in data modeling techniques and methodologiesKnowledge of relational database and advanced query concepts including Performance Tuning.Ability to analyze and develop business requirements and translate them into a data warehouse dimensional modelAbility to multitask and meet negotiated timelinesSkill in explaining data warehouse operations to technical and non-technical usersExperience with Oracle database development, SQL and relational database designHigher Education experience in one or more functional lines of business
Type Benefited Staff Special Instructions Summary",http://www.indeed.com/rc/clk?jk=3a3ab4b855aa426b&fccid=6328b27691d3fdc3&vjs=3
Data Engineer Sr,Save-A-Lot,"Saint Ann, MO 63074",,"The Data Engineer is responsible for designing and developing solutions and interfaces for the Data Platforms and Data Insights teams. This includes various data interfaces to and from databases, applications, and API’s to ingest data into the Cloud data environment, the landing zone, the Enterprise Data Warehouse, any downstream applications, as well as any data quality or metadata solutions. In addition, the Data Engineer will be responsible for data profiling, creating ETL (extract, transformation, and load) scripts within the data warehouse, designing data models using Entity Relationship modeling tools, and loading data into various data platforms using batch, stream, and bulk utilities. The Data Engineer will also be responsible for scheduling jobs and workflows as well as versioning and documenting their designs and data flows. The Data Engineer will use agile and iterative methodologies and will provide support as necessary.
Create data interfaces and scripts to load the enterprise data warehouse, data lake, data marts and other analytics environments to support enterprise-wide data consumption.
Build an enterprise data pipeline to improve access to real/near-real-time data across the enterprise.
Design and develop ETL (Extract, Transform, and Load) jobs within the data warehouse and other data platforms.
Create templates and engineering patterns to reduce the time-to-deploy new data assets or changes to an existing data model or analytics solution.
Act as a technical expert on the different data interface solutions (expertise in SQL, Python, Azure Data Lake, Azure Data Factory, and SQL Server Integration Services recommended).
Assist in optimizing and tuning data interfaces, jobs, and workflows and look for ways to improve efficiencies and effectiveness of existing solutions.
Partner with key business teams to understand their data needs and assist them in building the appropriate data interfaces to meet their business needs.
Partner with the security and risk teams to build appropriate security and compliance into the data platforms.
Partner with the enterprise technology function to ensure effective and efficient operation of all data environments.
Foster continuous process improvement within the data & insights organization and functions.
Cultivate strong relationships with all stakeholders of the data & insights team.
Minimum Requirements

Bachelor's degree in computer science, engineering or related field of study
5+ years IT experience
5+ years of experience delivering high-profile projects in a complex enterprise environment
3+ years developing and delivering data warehouses
Experience with SQL and scripting tools like Power Shell, Multi-Parallel Processing databases like Azure SQL DW, Teradata, or RedShift, ETL tools like Boomi, Azure Data Factory, or SSIS, and integration tools like Azure Logics Apps.
Experience integrating data in diverse technical environments.
Strong planning and organizational skills.
Experience in measuring and communicating the value of data platforms and tools.
Experience in multiple enterprise environments, industries and development methodologies
Experience in designing, delivering, and optimizing data integration and data warehouse solutions on Multi-Parallel Processing environments (Azure SQL DW, Teradata, etc.) and using integration tools like Azure Data Factory, Boomi, Informatica, or SQL Server Integration Services.
Experience profiling, modeling, and writing data interface scripts to load data into platforms like an Enterprise Data Warehouse, Azure Data Lake, Power BI, Azure Logic Apps, etc.
Experience working on large portfolios of inter-related projects to deliver an enterprise data ecosystem, achieving target outcomes and business value within budget and timeline.
Expertise across data related disciplines and environments.
Experience in a variety of work environments and industries, with demonstrated ability to be effective and deliver on the defined responsibilities in these varying environments. Able to quickly adapt techniques to the target environment and stakeholders. Experience in a retail environment preferred.
Demonstrated experience building and maintaining strong relationships with business and IT senior leaders and executives.
Excellent communication skills, both written and verbal, with ability to communicate effectively at all levels of the organization.

The above statements are intended to describe the general nature of the work performed by the employees assigned to this job. All employees must comply with Company policy and applicable laws. The responsibilities, duties and skills required of personnel so classified may vary within each department and /or location.",http://www.indeed.com/rc/clk?jk=d67517ed77b8a197&fccid=1bb1e19207a4ec89&vjs=3
Data Engineer,B-Stock Solutions,"Belmont, CA 94002",,"THE COMPANY
B-Stock is the world’s largest online marketplace for returned, excess, and other liquidation merchandise. Our customers range from SMB to the world’s largest brands and retailers (including nine of the top 10 U.S. retailers). Led by eBay veterans, B-Stock completes over 175,000 transactions per year, selling 90 million items annually, making us a clear leader in the space.

The amount of inventory that is returned or unsold each year is growing very rapidly; in 2018, the value of this merchandise was estimated at $500 billion. Much of it ends up being liquidated for pennies on the dollar; some of it is even destroyed or landfilled. We believe there is tremendous value in and demand for this inventory - no matter the category, condition, or location. The B-Stock platform gives buyers a simple and direct way to buy valuable products, and offers sellers a trusted replacement for traditional liquidation and a critical boost in operational efficiency.

Backed by top investors including Spectrum Equity, True Ventures, and Susquehanna Growth Equity, B-Stock runs lean, fast, and shows no signs of slowing down. Our core values (teamwork, honesty, humor, and the passion to build something great) have shaped the company we are today and will certainly drive our success for many years to come.

For more information, visit www.bstock.com/careers/

JOB SUMMARY
B-Stock is looking for a Data Engineer to help design, build, scale and maintain the next generation of the company's SaaS infrastructure. You will partner closely with cross-functional teams, including Data Science, Engineering, and Product / Business Technology, to build data infrastructure, processes, and tooling.

ESSENTIAL JOB DUTIES AND RESPONSIBILITIES

Manage and optimize core data infrastructure
Build monitoring infrastructure to give visibility into the pipeline’s status
Monitor all jobs for impact on cluster performance
Run maintenance routines regularly
Tune table schemas (i.e. partitions, compression, distribution) to minimize costs and maximize performance
Develop custom data infrastructure not available off-the-shelf
Build and maintain custom ingestion pipelines
Support data team resources with design and performance optimization
Build non-SQL transformation pipelines

MINIMUM QUALIFICATIONS, JOB SKILLS, AND ABILITIES

EDUCATION:

Bachelor's degree in a technical and/or quantitative field of study—e.g., computer science, math, physics or statistics, or equivalent and/or appropriate experience

EXPERIENCE:

3+ years of experience working with distributed data technologies
Experience working with server-side concepts such as containers, micro-services, caching, performance monitoring, and API design
Experience with cloud technologies such as AWS, Azure, and Google Cloud
Experience using Python, preferred
Experience with databases such as MySQL, and PostgreSQL, preferred
Experience with highly scalable ETL/ELT/Data Lake technologies, nice to have

OUR VALUES
Be honest. We do the right thing because it’s right.

Have passion for building something great. We empower employees to “think like an owner” so we dare to try. Let’s find new ways to grow B-Stock together.

Humor. Take whatever you are doing very seriously but do not take yourself too seriously.

Teamwork. Our successes are achieved because we work in stride, leveraging each other’s strengths as a unified effort.

Respect. We show consideration for each other and recognize the power in our diversity.

EMPLOYEE BENEFITS

Competitive compensation packages including bonus and options
Medical, dental, and vision benefits
Paid Time Off, telecommuting and flexible schedule options
Support for continuing education
Team off-sites, social events and extracurricular activities are a staple
Snacks, drinks, and the occasional box of donuts

No applicant will face discrimination/harassment based on: race, color, ancestry, national origin, religion, age, gender, marital domestic partner status, sexual orientation, gender identity, disability status, or veteran status. Above and beyond discrimination/harassment based on “protected categories,” B-Stock also strives to prevent other, subtler forms of inappropriate behavior (e.g., stereotyping) from ever gaining a foothold in our office. Whether blatant or hidden, barriers to success have no place at B-Stock.

US Work Authorization required.",http://www.indeed.com/rc/clk?jk=27450e140e254abf&fccid=0f5a55d977a6a496&vjs=3
Data Engineer,GalaxE.Solutions,"Detroit, MI 48226",,"What You Will Do:
Full lifecycle application development
Design, code and debug software
Perform software analysis, risk analysis, reliability analysis
Participate in software modeling and simulation
Integrate new software solutions with existing systems
Perform migrations

Perform regular status reviews of problems/issues
Participate in the development or refinement of proactive services and/or data repositories
Query database to provide data extracts
Perform ETL processes

Skills and Experience You Will Need:
Required
Experience with SSIS and Apache Airflow (or similar)
Experience with relational databases and data modeling
Experience with ETL development with SQL backend for stored procedures
Experience with cloud development ( AWS, S3, Lambda)
Experience performing migrations to cloud
Proficiency in XML
Desired
.NET development experience
Who We Are:
GalaxE.Solutions

Celebrating 30 years of excellence, GalaxE has pioneered the use of automation to achieve enterprise business transformation and mission-critical change for some of the largest companies in the world.


We are always looking for passionate, entrepreneurial-minded innovators and disrupters; game-changers that take ownership in the work they produce and bring it each and every day. Working with like-minded team members you will get a chance to discover, develop and use cutting-edge technologies to transform the way we deliver creative business solutions.


Sound like you? Join us, and find out for yourself what it means for you, and your career, to be part of the GalaxE team. Let’s build something, together. #WeAreGalaxE, #CoolAutomation

Equal Opportunity Employer/Veterans/Disabled",http://www.indeed.com/rc/clk?jk=db9286d4ab663fb0&fccid=5b75a1df86adb527&vjs=3
"Data Engineer, Infrastructure Strategy",Facebook,"Bellevue, WA",,"How would Facebook scale to the next billion users? The Infrastructure Strategy group is responsible for the strategic analysis to support and enable the continued growth critical to Facebook’s infrastructure organization.


We are looking for a Data Engineer to not only build data pipelines but also extend the next generation of our data tools. As a Data Engineer, you will develop a clear sense of connection with our organization and leadership - as Data Engineering is the eyes through which they see the product.


This is a partnership-heavy role. As a member of Infrastructure Strategy Data Engineering, you will belong to a centralized Data Science/Data Engineering team who partners closely with teams in Facebook’s Infrastructure organization. Through the consulting-nature of our team, you will contribute to a variety of projects and technologies, depending on partner needs. Projects include analytics, ML modeling, tooling, services, and more.
Data Engineer, Infrastructure Strategy Responsibilities
Partner with leadership, engineers, program managers and data scientists to understand data needs.
Design, build and launch extremely efficient and reliable data pipelines to move data across a number of platforms including Data Warehouse, online caches and real-time systems.
Communicate, at scale, through multiple mediums: Presentations, dashboards, company-wide datasets, bots and more.
Educate your partners: Use your data and analytics experience to ‘see what’s missing’, identifying and addressing gaps in their existing logging and processes.
Broad range of partners equates to a broad range of projects and deliverables: ML Models, datasets, measurements, services, tools and process.
Leverage data and business principles to solve large scale web, mobile and data infrastructure problems.
Build data expertise and own data quality for your areas.
Minimum Qualifications
5+ years of Python development experience.
5+ years of SQL experience.
3+ years of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, digdag.io, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M).
3+ years experience with Data Modeling.
Experience analyzing data to discover opportunities and address gaps.
5+ years experience in custom ETL design, implementation and maintenance.
Experience working with cloud or on-prem Big Data/MPP analytics platform(i.e. Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar).
Preferred Qualifications
Experience with more than one coding language.
Designing and implementing real-time pipelines.
Experience with data quality and validation.
Experience with SQL performance tuning and e2e process optimization.
Experience with anomaly/outlier detection.
Experience with notebook-based Data Science workflow.
Experience with Airflow.
Experience querying massive datasets using Spark, Presto, Hive, Impala, etc.
Facebook's mission is to give people the power to build community and bring the world closer together. Through our family of apps and services, we're building a different kind of company that connects billions of people around the world, gives them ways to share what matters most to them, and helps bring people closer together. Whether we're creating new products or helping a small business expand its reach, people at Facebook are builders at heart. Our global teams are constantly iterating, solving problems, and working together to empower people around the world to build community and connect in meaningful ways. Together, we can help people build stronger communities — we're just getting started.
Facebook is committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at accommodations-ext@fb.com.",http://www.indeed.com/rc/clk?jk=6df874857a54f5d5&fccid=1639254ea84748b5&vjs=3
Data Engineer,Facebook,"Seattle, WA",,"At Facebook, we have many opportunities to work with data each and every day. In this role as a Data Engineer on the Analytics team, your primary responsibility will be to partner with key stakeholders, data scientists and software engineers to support and enable the continued growth critical to Facebook's Data Center organization. You will be responsible for creating the technology that moves and translates data used to inform our most critical strategic and real-time decisions. You will also help translate business needs into requirements and identify efficiency opportunities. In addition to extracting and transforming data, you will be expected to use your expertise and provide meaningful recommendations and actionable strategies to partnering data scientist for performance enhancements and development of best practices, including streamlining of data sources and related programmatic initiatives. The ideal candidate will have a passion for working in white space and creating impact from the ground up in a fast-paced environment. This position is part of the Infrastructure Data Center team and located in Fremont, CA.
Data Engineer Responsibilities
Apply proven expertise and build high-performance scalable data warehouses
Design, build and launch efficient & reliable data pipelines to move and transform data (both large and small amounts)
Securely source external data from numerous partners
Intelligently design data models for optimal storage and retrieval
Deploy inclusive data quality checks to ensure high quality of data
Optimize existing pipelines and maintain of all domain-related data pipelines
Ownership of the end-to-end data engineering component of the solution
Collaboration with the Data Center SMEs, Data Scientists, and Program Managers
Support on-call shift as needed to support the team
Design and develop new systems in partnership with software engineers to enable quick and easy consumption of data
Minimum Qualifications
BS/MS in Computer Science or a related technical field
7+ years of SQL (Oracle, Vertica, Hive, etc.) experience and relational databases experience (Oracle, MySQL)
7+ years of experience in custom or structured (i.e. Informatica/Talend/Pentaho) ETL design, implementation and maintenance
7+ years’ experience in data engineering, experience in applying DWH/ETL best practices
7+ years of Java and/or Python development experience
2+ years experience in LAMP and the Big Data stack environments (Hadoop, MapReduce, Hive)
2+ years experience working with enterprise DE tools and experience learning in-house DE tools
Facebook's mission is to give people the power to build community and bring the world closer together. Through our family of apps and services, we're building a different kind of company that connects billions of people around the world, gives them ways to share what matters most to them, and helps bring people closer together. Whether we're creating new products or helping a small business expand its reach, people at Facebook are builders at heart. Our global teams are constantly iterating, solving problems, and working together to empower people around the world to build community and connect in meaningful ways. Together, we can help people build stronger communities — we're just getting started.
Facebook is committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at accommodations-ext@fb.com.",http://www.indeed.com/rc/clk?jk=6681d606e5f94fee&fccid=1639254ea84748b5&vjs=3
Data Engineer,DataDog,"New York, NY",,"About Datadog:

At Datadog, we’re on a mission to build the best monitoring platform in the world. We operate at high scale—trillions of data points per day—and high availability, providing always-on alerting, visualization, and tracing for our customers' infrastructure and applications around the globe.


The team:

We are building a first-class Internal Analytics team composed of Data Engineers and Data Analysts. If you’re excited to work on a fast-moving team with cutting-edge open-source data collection, transformation and analysis tools, we want to meet you.


You will:

Collect data from a wide range of sources: AWS S3, Redshift, PostgreSQL, and various APIs
Build data ETL pipelines using Spark, Luigi and other open-source technologies, with programming languages like Scala, Python, and SQL
Tune Spark jobs to improve performance
Work closely with product managers, designers, and engineers in order to collect the right data that will help them better understand our customers, product usage, or our own operations
Work with Data Analysts to build the right analytics reports
Have a meaningful impact on many teams at Datadog thanks to data
Join a tightly knit team solving hard problems the right way
Grow with the company


Requirements:

You are fluent in several programming languages such as Python, R, or Scala
You have 2+ years of work experience in building ETL pipelines in production
You value code simplicity and performance
You have work experience with data storage such as AWS S3, Redshift or similar.
Being a SQL expert is a minimum for this position
You are fluent with command line
You enjoy wrangling huge amounts of data and exploring new data sets
You have a natural curiosity and investigative mindset - driven to know “why”.
You can explain complex datasets in very clear ways
You want to work in a fast, high-growth startup environment and thrive on autonomy


Bonus points:

You are familiar with Spark and/or Hadoop
Experience with AWS Redshift and S3",http://www.indeed.com/rc/clk?jk=e4fe644e237fa985&fccid=448951d0ddf03e0c&vjs=3
Data Engineer,FutureSoft IT,"Sunnyvale, CA 94043",,"**Please Read**


Local candidates only. This opportunity does not provide Visa sponsorship. No corp to corp applicants please. Candidate must be available to work on our W2.


Data Engineer


Data applications are critical to our success, powering many aspects of our marketplace and supporting products. We are looking for data engineers who will build, migrate and maintain data pipelines. In this role, you’ll expand and refactor the data sets that generate and transform data into applications, insights, and experiences for our users.


The work includes:
? Refactoring existing and build new data pipelines
? Migrating existing data sets into next-gen reporting frameworks and tools
? Using existing data tools and frameworks to configure reports and metrics
? Developing and automating large scale, high-performance data processing systems to drive our business growth and improve the product experience
? Building and refactoring scalable data pipelines on top of Hive and Spark leveraging Airflow scheduler/executor framework


We are looking for engineers with:
? Demonstrated ability to analyze large data sets to identify gaps and inconsistencies, provide data insights, and drive effective product solutions
? Experience designing and deploying high performance systems with robust monitoring and logging practices
? Experience building high performance data pipelines
? Nice to have: proven ability to think critically about team direction and use analysis to inform that
? Experience using machine learning is a plus, but not required.
? Excellent communication skills, both written and verbal",http://www.indeed.com/rc/clk?jk=c2d066606e0a58c7&fccid=b6b9755638f54ed0&vjs=3
Data Engineer 3 - Contract,The Church of Jesus Christ of Latter-day Saints,"Riverton, UT",,"Posting Dates: 04/01/2020 - 04/04/2020
Job Family: Information Technology
Department: Information and Communication Services Department
PURPOSES
This is a contract position that is part of the Business Intelligence team, this individual works with multiple departments throughout
the organization to take their data and transform it into information that will allow them to make better decisions. The data
engineer is responsible for gathering requirements, design, creation and support of the data warehouse.

This individual works with divine guidance to provide or support technology that furthers the mission of the Church and reflects
the eternal impact of the gospel.
RESPONSIBILITIESPossess and utilize broad knowledge, specific to the data field, to complete significant assignmentsMaintain a strong understanding of the supported business processesGather and document requirements for the data warehouseAssist in designing Star Schema data modelsMaintain and support ETL jobs, pulling data from various source systems and loading data into the data warehouseAssist in designing semantic layer to support end-user self-serviceBuild complex reports using SQL Server Reporting Services (SSRS)Create complex dashboards using Microsoft Power BI or TableauAnalyze data and trends, and create reports that highlight areas in need of performance improvementInteract with customers as a technical resource to troubleshoot problems with the delivered BI solutionsMaintain production documentation
QUALIFICATIONS
Education:Bachelor's degree in related field or equivalent professional experience. Master’s degree preferred.
Work Experience:4+ years of data warehouse experienceWorking knowledge of industrial grade experience in data science, including machine learning and NLPPrevious experience training peers and system usersExperience working on multiple data science projects end to end, from idea generation to implementation in production
systems (warehouse, or applications)Previous professional experience in data analysis and report design/developmentExperience in presentation/interface creation
Demonstrated Skills & Abilities:Strong communicator; both written and verbalProven troubleshooterCapable of working under pressure to resolve complex problemsGeneral knowledge of engineering best practicesOperational understanding and discipline
Ability to resolve security issues and requests and implement improvements
· Proficient in dimensional data modeling · Ability to quickly learn new tools and technology
Strong problem solving, analytical, and diagnostic skills
Good documentation, presentation, and communication skills
Refined skills in developing ETL code, can manage the ingestion and cleansing of large sets of structured and unstructured data
Working knowledge of the algorithms used for regressions, clustering, classification, forecasting, and constructing graphs
Familiar with Bayesian inference
This job operates in a professional office environment
To successfully perform the essential functions of the job there may be physical requirements which need to be met such as sitting for long periods of time and using computer monitors/equipment
WORTHINESS QUALIFICATION
Must be a member of The Church of Jesus Christ of Latter-day Saints and currently temple worthy.
POSTING NOTICE/MORE INFO.
Please Note: All positions are subject to close without notice.",http://www.indeed.com/rc/clk?jk=f9c80867331ce9c9&fccid=7e408d96768a4a43&vjs=3
Data Engineer,StrategyWise,"Birmingham, AL 35233",,"Position Summary:

The Data Engineer is responsible for the maintenance, improvement, cleaning and manipulation of internal and external data. The Data Engineer will also play a key role in expanding and optimizing our data architecture, flow and collection on big data platforms.


Responsibilities:

Prepare raw data for manipulation by Data Scientists and Analysts and ensure optimal and consistent data delivery architecture throughout projects
Build infrastructure required for optimal extraction, transformation and loading of data from a wide variety of data sources on Azure using related “big data” technologies
Create databases optimized for performance, implement schema changes and maintain data architecture standards
Develop and implement scripts for database maintenance, monitoring and performance tuning
Perform thorough testing and validation in order to support the accuracy of data transformations and data verification to use in machine learning models
Research industry trends and best practices; advise senior management on new and improved data engineering strategies that will drive departmental performance
Detect and correct errors in work, monitor and troubleshoot operational or data issues in the data pipelines
Ensure work remains backed up and readily accessible to coworkers

Required Skills / Experience:

2+ years’ experience in data wrangling and data pipeline building, working with cross-functional teams in a dynamic environment
Comfortable supporting the data needs of multiple teams, systems and products
Working SQL knowledge and experience working with relational databases, performing root cause analyses to answer specific business questions
Experience working with web APIs and their related file formats (json, csv, parquet, etc)
Hands on experience with any of the following public clouds (Azure, AWS, or GCP)
Experience working on both Linux and Windows servers and systems.
Bachelor’s degree in Computer Science or related field
Strong conceptual knowledge of Power BI, Tableau, or other BI dashboarding products
Strong ability to effectively communicate with both business and technical teams
Hands on experience coding and working within the Python language
Experience working with code version-control systems like Git

Preferred Qualifications:

Proven real-world experience working on data engineering projects.
Passion for about continued education in Data Engineer or Comp Sci space.
Experience with any of the following tech products considered a plus; MS SQL, Hadoop, Docker, Kubernetes",http://www.indeed.com/rc/clk?jk=d6d4be3cfdbfba58&fccid=c19bcc6d30efbcb0&vjs=3
Data Engineer,Centriam,"Minneapolis, MN 55447",,"As a Data Engineer, you will play a key role in designing and building reliable, scalable, and performant data solutions in support of our growing analytics practice. If you are passionate about the data analytics space and are excited by the opportunity to build innovative solutions in a fast-paced environment, this may be the role for you!
Key Responsibilities:
Build high quality data processing solutions using a variety of technologies
Implement complex data projects with a focus on collecting, parsing, managing, and analyzing large sets of data to turn information into insights
Solve problems that span multiple interconnected systems
Automate infrastructure while accounting for a large number of interdependent processes
Translate business requirements into technical requirements, and refine existing technical requirements as needed
Collaborate with cross-functional teams on various initiatives
Mentor, pair, and delegate work to encourage the growth of those around you
Design and implement scalable, low-latency, high-availability, and performant applications
Assist in other analytics and/or development work outside of the traditional data engineering role
Experience & Skills:
Proficient in Python
Strong SQL skills
Experience with cloud engineering on AWS
Expertise with Linux command line tools
Experience with RESTful APIs
Strong commitment to well designed and well maintained unit tests, BDD, TDD
Strong interest in building big data applications and solutions
Strong interest in learning new technologies, languages and skills
Excellent communication skills and technical knowledge-sharing habits
2+ years of relevant experience
Bonus Skills:
Data analysis
Solution architecture
Database performance tuning and optimization
Data visualization and charting frameworks experience
Bonus Technology Skills
Luigi
AWS Redshift, Lambda, API Gateway, ECS, Glue
Docker
Pandas
Document database technology (CouchBase, MongoDB, DynamoDB)
Why Work at Centriam?
Small analytics company focused on delivering excellence and value to our clients by providing high quality analytical and data-driven solutions.
Fun & collaborative culture; you will wear many hats and play an integral part in projects.
Exposure to a wide variety of data analytics, cloud, and open source technologies.
 “Take what you need” vacation policy.
401k with generous match, vested immediately.
Free drinks, coffee, beer, and snacks.
Downtown Minneapolis office, connected to skyway.",http://www.indeed.com/rc/clk?jk=bd585a8b8370ad9a&fccid=1d2bef48e6fe1cfc&vjs=3
Data Engineer,Anthem,"Nashville, TN 37219",,"Description
SHIFT: Day Job

SCHEDULE: Full-time
Your Talent. Our Vision. At CareMore and Aspire, proud members of the Anthem, Inc. family of companies specializing in providing senior Americans a complete and proactive health care experience, it’s a powerful combination. It’s the foundation upon which we’re creating greater access to care for our members, greater value for our customers and greater health for our communities. Join us and together we will drive the future of health care.
The data science and advanced analytics team at Aspire is focused on building models to identify patients whose care we can impact, to maximize our impact on these patients, and to measure that impact. As a data engineer in this role, you will build the high-performance delivery systems for data from millions of patients to train our models, make predictions and evaluate results. You will be part of a collaborative team, with direct line of sight to our scientific work and high impact on the models that we build. This is an exceptional opportunity to do innovative work that is meaningful to you and those we serve.
Role: Sr. Data Engineer or Data Engineer – Patient Health
Our group is responsible for clinical machine learning and advanced analytics. We are the strategic and operational leads for identifying the most critical patients for service and clinical focus.

Write fluently in at least 1 programming language (Python, Java, or Scala preferred)
Query/modify SQL databases
Use cloud computing environments (e.g. AWS) and *nix shells (e.g. bash)
Work independently and quickly to build high-performance, well-documented code
Test and validate output to ensure that data bugs do not become model bugs
Communicate well with team members to understand and clarify specifications

Preferably, have experience:
With modern data storage formats (e.g. Parquet) and tools (e.g. Spark)
Tuning up Deep Learning applications with GPUs
Your work will:
Be at the cutting edge of machine learning and deep learning in health care
Have the opportunity for significant impact on our team, company, and mission
Impact the care of thousands of patients






AnEqualOpportunityEmployer/Disability/Veteran
Qualifications

Job Requirements:

Sr. Data Engineer
Requires BA/BS in Computer Science, Mathematics, or related quantitative discipline; 3-5 years’ experience with programming languages such as Python, Java or Scala; Experience with SQL databases; or any combination of education and experience which would provide an equivalent background.
Data Engineer
Requires BA/BS in Computer Science, Mathematics, or related quantitative discipline; 2 years’ experience with programming languages such as Python, Java or Scala; Experience with SQL databases; or any combination of education and experience which would provide an equivalent background.
Anthem, Inc. is ranked as one of America’s Most Admired Companies among health insurers by Fortune magazine and is a 2018 DiversityInc magazine Top 50 Company for Diversity. To learn more about our company and apply, please visit us at careers.antheminc.com. An Equal Opportunity Employer/Disability/Veteran",http://www.indeed.com/rc/clk?jk=e7f3fad5031c9a4d&fccid=2a4da7fa99f4b9ae&vjs=3
Data Engineer (U.S. remote),Railroad19,Remote,,"We are looking for a savvy Data Engineer to join our growing team of analytics experts. The hire will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.
Responsibilities for Data Engineer
Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Qualifications for Data Engineer
Understanding of concepts such as Change Data Capture, Event Sourcing, and CQRS patterns using event based systems
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. They should also have experience using the following software/tools:
Experience with stream-processing systems: Kafka, Nifi, Storm, Spark-Streaming, etc.
Strong knowledge of object-oriented/functional programming with Java 8+ or other JVM languages (Scala, Clojure, Kotlin, Groovy)
Hands-on experience with ETL techniques and frameworks like Apache Spark or Apache Flume.
Strong understanding of data serialization formats like Apache Avro, Parquet, Protobuf, Apache Thrift.
Experience with relational SQL and NoSQL databases, including Postgres and Cassandra, MongoDB, ElasticSearch.
Use of AWS cloud services: EC2, EMR, RDS, Redshift, S3, Lambda, Kinesis.
Experience with integration of data from multiple data sources.
Understanding of the importance of CI/CD, unit/integration testing, build tooling (maven, gradle, sbt), dependency management.
About RR19
We develop customized software solutions and provide software development services. We’re a specialized team of developers and architects. As such, we only bring an “A” team to the table, through hard work and a desire to lead the industry — this is our company culture — this is what sets Railroad19 apart.
At Railroad19, Inc. you are part of a company that values your work and gives you the tools you need to succeed. We are headquartered in Saratoga Springs, New York, but we are a distributed team of remote developers across the US.
As a Railroad19 employee, you will be part of a company that values your work and gives you the tools you need to succeed. Our Executive headquarters is in Saratoga Springs, New York, but this position is remote. Railroad19 provides competitive compensation and excellent benefits~ Medical/Dental/Vision vacation and 401K.
Working at Railroad19:
Competitive salaries
Excellent Health Care, Dental and Vision benefits
3 weeks vacation, 401K, work life balance
No Agencies***
This is a non-management position

We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender, gender identity or expression, or veteran status. We are proud to be an equal opportunity workplace.",http://www.indeed.com/rc/clk?jk=caad3edf2c4a54e4&fccid=34bdcb7b64c0a98c&vjs=3
Sr Data Engineer (ETL),EXPRESS,"Columbus, OH 43230",,"Overview:
The Brand that Gets You to What’s Next
Express is the vibrant, confident lifestyle brand for ambitious people, providing the latest fashion for style-obsessed men and women since 1980. Our mission is to provide inspiration and confidence through fashion to help people get to what's next in their day, and their lives. With more than 600 retail and outlet stores throughout the United States, Puerto Rico and Latin America, and a best-in-class online/mobile shopping experience at www.express.com, Express brings city-inspired style to customers across the globe.

A Workplace To Match
We think you'll like it here.
We offer a competitive compensation and benefits package, generous associate discount, and casual work environment. Working at Express is much more than the 9 to 5. It is an opportunity to connect and engage with some of the smartest individuals in the fashion business doing work they are passionate about. This is the Express Life and we’re always looking for talented leaders at all levels to join our team; if this sounds like you, we'd love to chat!
Responsibilities:
The ""Enterprise Data Warehouse and Business Intelligence"" team is the technology team responsible for defining, storing, managing and provisioning the data structures required to support the enterprise with consumption through various Business Intelligence platforms in a fast-paced and fluid environment. Individuals on this team:
Lead Technology design, development, implementation, and support efforts to establish solutions for providing the business with consumption capabilities of structured Enterprise Information across all Functional Areas of the business
Monitor and manage performance of the associated technology implementation
Provide stable, scalable, and recoverable solutions
Discover and Analyze opportunities for continuous improvement
Communicate insights to business leaders
Work cross-functionally with all other areas of IT and the business
Role:

This particular individual will –
Participate in full project lifecycle to understand business requirements and then complete the design, development, testing, implementation and post-production support of data engineering solutions
Assist end users in resolving and identifying system issues by providing application knowledge and technical expertise
Have high capacity for data analysis, data modeling, problem solving, accuracy and attention to detail
Have good understanding of multi-channel fashion retail business processes , data and reporting needs
Coordinate with ETL lead for escalation of support related issues
 Responsibilities –
Works with solution engineer and ETL lead to design and develop data engineering solutions
Provides support and troubleshooting for all related systems and technologies. This includes being a point of contact for business users
Participate in 24/7 on-call support activities
Operates with minimal supervision; self starter
 Technical Skills:

Required –
Bachelor's degree in Information Systems, Computer Science, Computer Engineering or related degree or equivalent experience
3+ years of proven hands-on experience with data engineering toolsets like Unix shell scripting, ODI, SSIS, Python etc.
Data modeling experience in designing the logical and physical data models using ERWIN, ER Studio or similar data modelling tools
Experience with at least one of the ETL tools between ODI or Ab Initio
Hands on experience with MPP databases like Teradata, Netezza or Redshift
Hands on experience with transaction databases like Oracle, SQL Server
Proficient in SQL
Experience in Data Warehousing architectures, techniques, and methodologies including: Star Schemas, Snowflake Schemas, Slowly Changing Dimensions, Aggregation Techniques, etc.
 Preferred –
Experience in end-to-end implementation of data engineering projects, especially ETL involving sourcing data from disparate systems, reconciling and transforming data to load into consumable, scalable and recoverable data model at varied frequency
Experience with one of the OO languages (JAVA, C#, C++)
Experience of integrating one or more systems like ERP, POS, Order Management and Hadoop with Data Warehouse
Knowledge of retail industry
Closing:
As an equal opportunity employer, Express does not discriminate in hiring or terms and conditions of employment on the basis of any federal, state, or locally protected class. Express only hires individuals authorized for employment in the United States.

Notification to Agencies: Please note that Express does not accept unsolicited resumes or calls from third-party recruiters or employment agencies. In the absence of a signed Master Service Agreement and approval from HR to submit resumes for a specific requisition, Express will not consider or approve payment to any third-parties for hires made.",http://www.indeed.com/rc/clk?jk=78f9698ddcbc1043&fccid=0fa1d6f1f7b2b6a5&vjs=3
Data Engineer,HCI Group,Pennsylvania,,"Duties:
1. Exhibits the ability to assist in client requirements assessment, solution set designs, coding, testing and implementation.
2. Demonstrates advanced SQL knowledge, relational and multidimensional models, and business intelligence delivery tools.
3. Demonstrates the ability to modify existing architecture to solve complex problems.
4. Recommends and establishes conventions and standards for all technical areas related to data storage, transformation and aggregations.
5. Participates in selection of new technologies, and consults on requirements.
6. Acts as a technical escalation point or SME for a particular aspect of the environment, assisting with complex problems and solutions.
7. Has an advanced understanding of technical environment and integration points, including all software, hardware, and supporting environments.
8. Demonstrates basic knowledge of project management concepts and may act as an implementation lead for department initiatives.
9. Demonstrates the ability in creating detailed documentation, including project plans, requirements status reports and operations documentation.
10. Exhibits ability to clearly articulate problems, issues, requirements and potential solutions to team members and clients.
11. Works with analysts to identify and understand source data systems
12. Demonstrates the ability to serve as a resource to cross- functional work teams
13. Exhibits the ability to guide associate Information Architects and provide teaching support to clients, Operations, and Help Desk as needed.
14. Knowledgeable in Research Administration (Finance, Pre/Post Award, Compliance) workflow including Project Accounting, Time & Effort & supported technologies

Skills:
Information Security Requirements
1. Understand and comply with all enterprise and IS departmental information security policies, procedures and standards.
2. Support the integration of information security in the development, design, and implementation of Hospital Technology Resources that process, transmit, or store client information.
3. Support all compliance activities related to state, federal regulatory requirements, healthcare accreditation standards, and all other applicable regulations that govern the use and disclosure of patient, financial, or other confidential information.

General
1. Experience in the development or implementation of structured operational processes, conformance with SLAs, and metrics based reporting.
2. Intermediate knowledge in Change Control Mgt. processes
3. Experience with process documentation and communication tools including MS Word, Project, Excel, Visio and PowerPoint.
Moderate to advanced experience and proven use of one or more of the subject areas listed below:
SQL and Database Knowledge – Understanding SQL, Relational and Multidemensional Databases and Designs
1. Knowledge of relational database structures (tables, data types, data model schemas), SQL Syntax & SQL Functions, develop Views and SQL Optimization
Analytics
1. Cube dimensions (creating/maintaining translations, attribute relations, hierarchies)
2. Dimension usage: reference dimensions, many to many relationships, fact relationships, role-playing relationships granularity
3. Creating and maintaining data source views and reporting models
4. Hypothesis development, design test/experiments, & developing actionable recommendations
5. Statistical modeling techniques (logistic regression, log linear regression, etc...)

Advanced experience and proven use of one or more of the subject areas listed below:
Tableau, Qliksense, Power PI, or any other data visualization application.
Data Warehouse Support and Design
Creating/Maintaining Tables, views, & indexes

Education:
Proficiency in appropriate Business Intelligence/Data Warehousing technology or subject domain.Bachelor’s degree in computer/Analytics/Data Science related field.
3-6 years of Business Intelligence/Data Warehousing experience, preferably in a healthcare & research environment.",http://www.indeed.com/rc/clk?jk=a792700425f4543e&fccid=a2c955c0e33976e4&vjs=3
Data Engineer,vidIQ,"San Francisco, CA",,"Imagine a product that reached over a million users without a sales team. That same product is at the edge of where careers are headed, where every person becomes their own brand with limitless growth potential ahead. That's the opportunity at vidIQ – an infinite market, a large and highly engaged customer base, and the chance to help build and scale vidIQ's data engine that drives insights for millions of creators.
Intro
Why this Role? Why vidIQ?

Join a truly global, remote team: Work from anywhere! Have co-workers all around the world. Get the opportunity to travel for events and company meet-ups.
Leave better than you came in: We are always learning at vidIQ. We learn by doing. We learn from each other — and we are incentivized to attend conferences, obtain certifications, and take training courses.
Build the future with us: In today’s ever-changing world of technology, video is coming in fast and hard to dominate both the entertainment and marketing space. With multiple devices to choose from — from mobile to tablet, desktop to streaming video on our televisions, more and more people are not only using video to make purchasing decisions, but also changing the way they receive their entertainment.
Tackle our most interesting and impactful problems: We are setting precedents and coming up against challenges no one has seen before. You will need to be resourceful and creative. You will not be bored!
Right time, right place: We are small enough that you will have true ownership and the feel of a close-knit team. But, we are established enough to have hit profitability and product-market fit, which gives us a fun and challenging field to play on!

Company Mission
We want to empower Creators. We help creators on their journey to being better video creators through tools and training.
Just about every single human on this planet loves to listen to stories, to experience them, and some to tell them. Because of the opportunity the internet gives us where people are able to build businesses while in the comfort of their own home, a lot of people are seeking this opportunity and many of them, with amazing stories, are giving up too fast. There's too much bad information out there on how creators become successful, how they build their audiences. vidIQ challenges this status quo by giving creators the tools and knowledge needed to grow their audiences faster by enabling them to uncover their own opportunities by just using vidIQ.
We believe that by equipping people with the best tools and education to solve their own problems, we can tackle the whole world's problems.
The Product
The best way to understand vidIQ is to play with the product: www.vidiq.com/extension
We've heard vidIQ described many ways. It can be the tool that you use to manage your YouTube channel, making deep analytical insights accessible that saves dozens of hours a week. When someone attends any of our live streams or academy, it's the education every creators need to be successful. We're also know as the best video keyword research tool available to many folks. At vidIQ's core, it's a tool that gives creators what they need to navigate toward the success they want to have because of the tools and education made readily available.

So what will you do at vidIQ in this Data Engineer role?

vidIQ is seeking a highly-motivated Senior Data Engineer with 3+ years of hands-on data engineering experience to join our growing team. The ideal candidate will be a go-getter with the ability to work independently. In this role, you will have oversight of partitioning data, building an ETL pipeline, data compaction, and AWS optimization.

You must be highly collaborative and a self-starter who is able to work in a fast-paced environment. Strong communication skills are essential in this role, as it will be integral in communicating to the back-end team where and how to implement data integration and persistence. You will also communicate to management the volumes of data we are gathering, as well as communicate the data access points and how to use this data, to the team and management.



You might be a fit if...

You have

3+ years experience using Python for internal data pipelines (moving data inside AWS account)
numpy, pandas
Additional experience with DynamoDB, Lambda, Athena, S3, AWS GlueFamiliar with Spark preferred
Hands-on experience with data workflow orchestration (Airflow)

FAQ
What benefits can I expect?
This is a 100% remote position, work from anywhere you like.
A flexible work schedule where you decide which hours to work. We expect an average commitment of 40 hours per week.
We offer a generous vacation policy of taking time when you need it.
Most team members take 4–5 weeks of time off per year.
Team retreats every year! Past trips have been to Spain, Portugal, and other amazing places.
Work with amazing people around the world.
Huge impact in the Creator Ecosystem.
Matched or exceed market salary in the country you live in.
Support your professional development and will pay for relevant courses and conferences
Apply
If you’re excited about this, we’d love to talk to you. Use the “Apply for this job” button below to get in touch with us.",http://www.indeed.com/rc/clk?jk=7727f5d9f2acb782&fccid=85021dfa4578f124&vjs=3
Data Engineer L2,Capgemini,"Universal City, CA",,"Duration: 9+ Months

Job Description:
Functional Title: AWS Support Engineer

Must Skills: AWS
Plus Skills: Scripting
Degrees, certifications/training: Certified in AWS
Industry expertise:4 to 6 years of experience in Cloud, AWS
Detailed job responsibilities: Experienced in operational support for AWS services, troubleshoot EC2, S3 bucket, VPC etc.; Knowledge of Terraform, Cloud DevOps, ITIL processes
Other soft skills/aptitude: Good problem solving and communication

Job Details:
1. Knowledge of AWS Services
2. Certified in AWS
3. Experienced in operational support for AWS services
4. Troubleshooting EC2, S3 bucket, VPC etc.
5. Knowledge of Cloud DevOps
6. Knowledge of ITIL processes
7. Knowledge of Terraform is a plus
8. Good problem solving skills
9. Good Communication Skills

The Capgemini Freelancer Gateway is enabled by a cutting-edge software platform that leads the contingent labor world for technology innovation. The software platform leverages Machine Learning and Artificial Intelligence to make sure the right people end up in the right job.

A global leader in consulting, technology services and digital transformation, Capgemini is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50 year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. It is a multicultural company of over 200,000 team members in more than 40 countries. The Group reported 2018 global revenues of EUR 13.2 billion.",http://www.indeed.com/rc/clk?jk=a62738c8411f2318&fccid=105ecfd0283f415f&vjs=3
Data Engineer,xentity corporation,"Denver, CO",,"Our Government and Large Commercial high-profile clients are high-tech organizations with programs in science, technology, engineering and math. For these positions, they are asking for us to provide data analysts that are passionate about transforming and making data usable for new services, business models, and to help economic development. We are looking for people that believe data is the new gold.
We are looking for data analysts, data wranglers, data scientists with excellent leadership, technical, and subject matter expertise qualities. We have projects lining up developing research-grade science data algorithms from in-situ sensors to bringing together data sources from disparate sub-agencies into enterprise platforms to make available on open-data platforms. We have projects that are creating data and bigdata prototypes whether it be on CartoDB geospatial, D3 Sankeys and various libraries, feeding and harvesting RDF Triplets into catalogs, or integrating into SEO environments. Admittedly, we have some less sexy data wrangling and janitor tasks that will require more ETL skills to hone in on.
To boot, we want our analysts to be natural change agents and passionate about change while empathetic to the clients environment on how they leverage, mature, and incorporate data products, services, and new capabilities. We want leaders who can both support the influence of the right change direction while managing the technical and business analysis and design, and are skilled and self-motivated with solid domain/subject matter expertise.
Our analysts will be on teams that, through facilitated analysis, work shoulder-to-shoulder with teammates to come up with the conceptual and logical design and architecture. Analysts will also be working very closely with client staff or system integrators to rapidly implement changes or agile release. Furthermore, we devise and craft strategies and communications solutions to broadcast and brag about their change efforts and results. This is what we do – we bring transformations to life.
Position Requirements:
You will be expected to rapidly ramp-up on client lingo, proactively make observations of patterns, anomalies, problems, and be customer service focused. You will be expected to be highly self-motivated and understand you will be held accountable to commitments. We look for decisive individuals able to rapidly respond to change requests and able to communicate, track, and escalate risk. We expect you to be proactive, efficient, and ready to learn quickly in response to all client and team member needs. This is a bootcamp-type position setup for growth.
We want you to not only gain technical skills, but also grow your interactive and client facing skills. All roles will require strong communication and interactive skills - oral, written, visual especially for triaging conflict, ideation barriers, mitigating risk, foster thought diversity and team environment. We expect all our roles to have a mastery of their technical level at their role whether that be in architectural methods, languages, work products, consulting techniques, and client culture. If they are not, they need to demonstrate how they are VERY fast learners.
For the technical prowess, we will want you to demonstrate your data science nerd-dom and technology stack as part of normal vernacular in one or many of these stacks (well, technologies in these stacks depending on the project). Of course, by no means do we expect all of the technologies, but prowess in one of the stacks:
Data Transformation – ETL, perl, python, SQL, FTP, Informatica, SAFE/FME, Kettle, GeoKettle
- Machine Learning - Markov or Markov Chain, Naive Bayes, N-Grams, Levenshtein distance or Damerau-Levenshtein distance, Fuzzy Search, NLP,
Algorithm Development and Visualization – R, Octave, MatLAB, OpenCV, Viola-Jones Haar-Cascade
Geospatial Transformation – GEOJson, CartoDB, K-Means, Nearest Neighbor, Anselin Local Moran's, Monte Carlo Simulation, Mantel Index, Standard Deviational Ellipse, GeoServer, ESRI, ESRI/Hadoop, PostGIS
Web BI – NodeJS, PHP, Web JavaScript libs like jQuery, ExtJS, D3JS, R Project, HTML5, CSS3, Many more.
NoSQL – MongDB, Hadoop, CouchDB, Solr, ElasticSearch
From a skillset of functions, our data science analysts would need to have a strong focus in one or more of these core areas:
- Open Data User Experience - Someone who has gathered public data and used it in a project (and/or application), is aware that there is an industry wide 'current debate' about open data, and has filed a CORA/FOIA request to gather data.
- Analysis - Someone who can 'read' a dataset and 'tell its story' - top points for ""food desert analysis"", ""restaurant inspections analysis"", ""bike trails routing analysis"" - or any other specific ""human geography"" and/or ""land use"" analysis. Ideally this person can use tools like GIS/RS, Tableau, Carto, D3, JavaScript, Python, Adobe Photoshop, Adobe Illustrator.
- Manual Data Entry - Has an eye for detail and has patience to meticulously check and double check others' data entry, and a desire to work with metadata. Can work in Excel and Google Sheets.
- Data Wrangling - Can manipulate and verify transformations on data, also has general knowledge of coding languages, can read/edit JavaScript, SQL, Python, Ogr2Ogr, GDAL.
- Database Administration - Has a basic familiarity with relational database and geodatabase structures, organizing and maintaining data, metadata.
Finally, our data science analysts will need to meet the following:
1 year of consulting experience – higher compensation for additional 3 more years in related analytical work products and additional 2 more years in subject matter
Could pass ad-hoc technical and whiteboard test given various data ETL and other patterns of real-time, large data, data cleanup, etc. scenarios
For public sector work, our work is traditionally unclassified, but will require certain amount of background, reference, and other checks
Travel will be maximum 20%
We emphasize a balance of work and life and target 40-50 hour weeks with ample times to refresh with great paid-time off.

Opening expected: Summer:
We review our requirements quarterly and this could change. We like to plan ahead in finding amazing talent.:
About Xentity:
We are a fast-growing data consulting and support services firm - focused on large data programs in data types such as geospatial, open, big, and IoT data. Check out www.xentity.com to learn about our focus, services, clients, missions, values as well as our excellent benefits package and career information.
We have high profile clients and projects that our staff really delivery for, as well enjoy knowing they make a large difference.
Our President has a vision to continue to focus on solutions that transform the Next Generation. Using data integration, knowledge solutions, and amazing increases in computing to impact energy, geosciences, land management, we can bring quality and simplifications to existing and new data flow! Imaging being on a team that brings advanced concepts like high performance computing, AI, data science, fuzzy logic, changing interfaces human-computer points mobile or augmented reality and many more disruptions. This truly can put the I back in IT and GIS.... by concentrating on pragmatic knowledge-first data designs, leadership and management, and the all too forgotten focus on outreach and engagement strategies and solutions.

More can be found at careers.xentity.com",http://www.indeed.com/rc/clk?jk=50a4b012650c6b36&fccid=d7dee2b3330da2cc&vjs=3
GCP Data Engineer,Virtusa,"Fremont, CA",,"JOB DESCRIPTION
Skill: Kafka Developer
Role: T3, T2
Do you thrive working in innovative environments using state of the art technology? Are you looking for a place where you can show off your skills? Consider working at Virtusa!
As a Kafka Developer, you will play a critical role in building real-time streaming services to support a range of client business issues. These solutions will leverage advanced technologies in big data to provide cutting-edge solutions and drive new business innovation.

Key responsibility:

 Creating the requirements analysis, making the platform selection, designing the technical architecture, designing the application, plus testing and deployment of the solution.
 Developing workflows and queries to obtain data required for Tableau development.
 Working with business requirements and stakeholders to establish metrics requirements.
 Providing best practices and industry standards to ensure a consistent design and/or approach for analytics.
 Partnering with other technical teams to incorporate data security within Tableau.
 Developing roadmaps and implementation strategy around data science initiatives including recommendation engines, predictive modeling, and machine learning.
 Translate complex functional and technical requirements into detailed design.

Qualifications
 Bachelor’s degree or equivalent experience in a related field.
 7+ years of software engineering and scripting experience.
 3+ years or experience working with Big Data technologies.
 3+ years hands-on expertise with Apache/Confluent distribution of Kafka.
 Minimum 4+ years of experience in development and support of stream processing solutions in Hadoop technologies.
 Minimum 10+ years of software industry and integration solutions development experience.
 Expert level knowledge of Kafka and related technologies (Hive, Hadoop, Spark, Storm, Nifi, Zookeeper, Ambary, Ranger).
 Experience with stream processing using Kafka and Kafka Connect.
 Strong decision-making skills in data analysis, design and integration.
 Ability to architect large data.
 Strong skills in database design and data integration.
 Exposure to Big Data technologies and strong understanding of Datawarehouse concepts.
 Ability to share ideas among a collaborative team and drive the team based on technical expertise and learning, sharing best practices.
 Experience in a data-driven, fast-paced environment.
 Strong self-led, work prioritization skills.
 Demonstrated team player and solid communicator.
 Expertise in creating technical documentation.

About Virtusa
Teamwork, quality of life, professional and personal development: values that Virtusa is proud to embody. When you join us, you join a team of 21,000 people globally that cares about your growth — one that seeks to provide you with exciting projects, opportunities and work with state of the art technologies throughout your career with us.
Great minds, great potential: it all comes together at Virtusa. We value collaboration and the team environment of our company, and seek to provide great minds with a dynamic place to nurture new ideas and foster excellence.
Virtusa was founded on principles of equal opportunity for all, and so does not discriminate on the basis of race, religion, color, sex, gender identity, sexual orientation, age, non-disqualifying physical or mental disability, national origin, veteran status or any other basis covered by appropriate law. All employment is decided on the basis of qualifications, merit, and business need.
Learn more at www.virtusa.com.


Primary Location: US-CA-Fremont
Schedule: Full Time
Job Type: Experienced
Travel: No
Job Posting: 29/01/2020, 1:34:24 PM",http://www.indeed.com/rc/clk?jk=dbfdca1e651cc606&fccid=146443e77d8c0778&vjs=3
Data Engineer,NS8,New York State,,"Who we're looking for:

As a Data Engineer at NS8, you will join a team of passionate engineering and data professionals focused on building cutting edge data tools that empower our 10k+ e-commerce merchants to provide a frictionless experience for real users and to block fraudulent ones. Because we are entering a new stage of growth, we are looking for data engineers that are excited to build NS8's data lake, data warehouse and production data-flows for v2 of our scoring and optimization engines. This means we want people who can quickly understand our data requirements and design and execute a vision that scales with our organization.

What you'll do
Write and maintain data pipelines critical to NS8's data lake, data warehouse and production systems
Build and support ML workflows in conjunction with ML Eng and Data Science teams
Stream data from Kafka + legacy data stores and ensure we have a data lake rather than a data swamp
Work with production developers to ensure new applications are consistent with our data model and that new application data is persisted
Think deeply about the problem we are solving and propose novel data-driven solutions that we don't currently see
Experiences you need:
Streaming data (Kafka, RabbitMQ, etc…) and stream querying/processing (Apache Beam)
Building ETLs for data warehouses like Snowflake, Redshift or BigQuery
Experience with SQL and NoSQL data storage: Mongo, MySQL, Dynamo
Masters in CS, EE or equivalent experience
4+ years developing software
Experience running cloud infrastructure a bonus
Who we are:

Founded in 2016, NS8 began with the goal of empowering businesses to better fight the growing epidemic of online fraud. Our software combines advertising protection, order protection, and global monitoring into a single solution that safeguards merchants against ever-evolving digital threats.

Born from data orchestration and early-stage detection, NS8's fast and accurate risk-scoring technology provides better insight into real customers and allows businesses to filter out malicious activity before it starts.

Benefits we provide:
Laid-back office environment with casual attire
Occasional catered lunches, plus kitchen stocked daily with drinks and a variety of snacks
Competitive salaries
Paid time off—holidays, vacation and volunteering days
Paid sick time
Employer-paid health insurance package
Voluntary life and AD&D insurance
Work-from-home days
Physical Demands:
This is largely a sedentary role. Must be able to remain in a stationary position for a long period of time.
Must be capable of bending and kneeling, reaching and lifting, and squatting for short periods of time.

NS8 Inc provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.

This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.",http://www.indeed.com/rc/clk?jk=77cf1b0355b62efa&fccid=fec8583f8fa276d8&vjs=3
Data Engineer Intern,WEX Inc.,"Portland, ME 04102",,"WEX Inc. (NYSE: WEX) provides B2B payment processing and information management solutions. From our roots in fleet card payments beginning in 1983, we have expanded the scope of our business to a multi-channel provider of corporate payment solutions in fleet, virtual travel, and healthcare markets.
Our innovative technology, payment, and data solutions are working to enable our customers and business partners to focus on what they do best: achieve their business growth objectives.
WEX is more than just a corporate payment processing company and a job. We are an agile and innovative technology community, where our curious and collaborative people look to bring the future of commerce to the present.
Our Program
The WEX Summer Internship offers a 12-week summer experience for student engineers and developers interested in Information Security (Cyber Security), Cloud Architect and Operations, Mobile WEB and App Development, UX/UI, Software QA, and Software Development.
Our internship program is designed to provide interns hands-on, practical experiences while working alongside some of our industry’s smartest teams; as well as providing immediate value to their teams and our leaders.
As an intern, you will be challenged and offered the opportunity to make an impact across the business and be involved in the company’s most critical business decisions. We are looking for ambitious and curious students, who are interested in growing professionally and developing their skills to become the next generation of leaders in technology.

What you will be doing in this role:
The Corporate Payments Data Engineering team is looking for an intern with an Engineering or Computer Science background to work on a project involving data movement and transformation using cloud technologies.
Java or .NET knowledge (C#) with a basic understanding of OOA&D (Object Oriented Analysis and Design).
Basic knowledge of Python.
Basic SQL. Knowledge on how to insert, update, or retrieve data from any major RDBMS.
Basic understanding of cloud technologies, such as AWS.
A knowledge of pySpark is a huge plus, but not required.
Must be able to work independently and, above all, be able to work in a team setting with a diverse background.
The candidate must also have a passion for technology, be a self-motivated learner, and have a very inquisitive mind.
You should also expect :
You should expect to be collaborative and challenged as you work with our diverse, passionate and talent technology teams.
Engage and interact with senior leadership
Train and develop your skills in your area of work with some of the best technology experts in our industry
Who we are looking for:
At a minimum, you should be a rising junior, senior, or masters-level student, in a degree/certificate-seeking accredited program
We know there first years out there, rising sophomores, with incredible talent. You too can apply but be ready to shine.
Note: the following represents a list of the technologies and languages used at WEX in the development. While direct experience is not required, any exposure or hands-on experience is considered a plus
Strong programming skills or experience in one or more of the following areas: Java, .net, asp.net, PHP, Python, Objective C, C#, C/C++, Perl, XML, JSON, UML, JavaScript, Visual Basic, HTML, SQL, PL/SQL, Shell scripts, AWS, UNIX.
Experience or exposure with JavaScript frameworks Angular 2, Typescript. Angular, Ember; Backbone, RequireJS, jQuery Mobile.
Package managers and build tools such as Bower, npm, Gulp and Grunt
Equal Opportunity Employer/Vets/Disability",http://www.indeed.com/rc/clk?jk=844d989797d36567&fccid=c9538b927313f8e0&vjs=3
Data Engineer,Microsoft,"Redmond, WA",,"The Azure Data team, which builds Microsoft’s industry-leading data platform products including SQL Server and Azure services such as SQL DB, SQL DW and Cosmos DB, is looking for a Data Engineer. You’ll be joining a team of passionate data professionals focused on reporting and analytics to support all aspects of our business. Our team builds, curates, and consumes data for reporting, deep data analysis as well as advanced data science. We develop insights that are used in scenarios spanning increasing customer satisfaction, defining and tracking key business metrics and informing the future roadmap for the Data business.
As a Data Engineer on the Azure Data team, you are an authority, familiar with all data warehousing technical components, infrastructure, and their integration. You are an expert in both high level design and experience with Star Schemas, Data Cubes and Dimensional Models as well as deeply technical in building durable data pipelines with the ability to scale elegantly with data volume growth. You will be responsible for designing, developing, and maintaining data pipelines and back-end services for real-time decisioning, reporting, optimization, data collection, and related functions. The code you write will enable our users to get data in a timely manner. You'll work on a variety of tools and systems, most of which are Cloud-based applications or data-platform components (e.g., data pipelines, processing, Visualization, reporting, etc.). In this role, you will be working in Agile development method for faster, quick-wins with the quality of design, development and operating the BI components you develop.
We are a highly collaborative team that strives to build lasting relationships with stakeholders across the company from product management to engineering, finance, marketing and more. Our team includes a diverse set of roles and as such, we value the diversity of skills we each bring to the team and apply towards our common goals. We work together to build an inclusive environment that values a variety of perspectives and backgrounds.
Responsibilities
In this role, you’ll partner with program managers, engineers and leaders across the Azure Data and broader Azure teams to enable timely and actionable insights aligned with the business’s key strategic programs as well as perform deep analyses to understand customer usage patterns and behaviors in conjunction with our broader analytics and data science team. More specifically, you will:
Design, architect, implement, and support key datasets that provide structured and timely access to actionable business information with the needs of the end customer always in viewBuild ETLs/ELTs to take data from various telemetry streams, data lakes and supporting data sources and craft a unified dimensional or star schema data model for analytics and reportingDevelop a deep understanding of vast data sources (existing on the cloud) and know exactly how, when, and which data to use to tackle particular business problemsDesign efficient data structures and database schemasWrangle large-scale data setsUtilize a variety of data stores including Azure Data Lakes, SQL Database, SQL Data Warehouse, and Azure Analysis ServicesRetrieve and analyze data using SQL, Excel, Power BI and other data management systems
To be successful in this role, you must have strong skills in written and oral communications, a can-do attitude and the willingness to tackle hard problems in innovative ways. You also thrive in a team environment that values cross team collaboration and building on the success of others.
Qualifications
Basic Qualifications
Bachelor’s degree in computer science or engineering, database systems, mathematics, business administration, economics, or in place of 5+ years of internship or industry experience in a data engineering or database administration-focused role5+years’ hands-on data engineering or database administration experience with proven quantitative orientation
Preferred Qualifications/Skills

Master’s degree in computer science or database systemsAdvanced hands on experience with SQL Server, Analysis Services and Microsoft cloud data platform offerings including SQL Database and SQL Datawarehouse7+ years of experience with data warehouse technical architectures, ETL/ELT, and reporting/analytic tools5+ years of experience designing and building data warehouse solutions5+ years of experience building data pipelines2+ years of experience with production BI implementations in the CloudExperience building Power BI, Excel, and Reporting Services dashboards and reportsExceptional problem solving, technical and data analysis skills
Great written and verbal communication and presentation skills
Be self-driven, and show ability to deliver on ambiguous projects with incomplete or dirty data
Ability to work in a team environment that promotes collaboration
Experience with Data Lake infrastructures (Cosmos, Hadoop)

AZDAT #ENGGJOBS
Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.
Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.",http://www.indeed.com/rc/clk?jk=6c7b78643ca392e6&fccid=734cb5a01ee60f80&vjs=3
Data Engineer,BlueVoyant,"San Francisco, CA",,"Data Engineer
BlueVoyant is seeking a Data Engineer to join our Professional Services Team to help implement/support specific technology platforms used to deliver incident response and cyber forensics capabilities. This position will enable a talented individual to work hand-in-hand with some of the top security and data science experts in the business. You will be asked to apply existing knowledge and learn new skill sets to develop and populate a new data pipeline. The sky's the limit as you help us evolve our technologies, processes, and capabilities to counter sophisticated and adaptive adversaries.
The individual will be based in our San Francisco office.
Qualifications for the Role:
Deep interest in data, data modeling, and data transformation.
Experience with parsing and analyzing large data sets.
Exceptional analytical skills to visualize how to transform unstructured data into actionable information.
Ability to audit and examine data pipelines.
Experience creating and maintaining ETL pipelines a plus.
Comfortable working with G Suite, Atlassian (Jira/Confluence), and gitlab.
Proficiency in SQL, Python, JSON, bash, GCP, BigQuery and Airflow.
BS/BA in Computer Science, Engineering or relevant field experience.
What you will do as a Junior Data Engineer:
Work with security engineers to extract and normalize data into a big data platform.
Use multiple technologies and methods to import new data sources into big data platforms.
Work with other security geeks.
Support our cyber forensics and incident response teams in data mining exercises related to new and ongoing investigations.
General responsibilities include:
Work with cross-functional teams to proactively improve on existing integration and automation workflows.
Maintain up-to-date knowledge of technology standards, industry trends, emerging technologies, and software development best practices.
Ensure technical issues are quickly resolved and help implement strategies and solutions to reduce the likelihood of recurrence.
Work with peers to ensure the end-to-end solution provided by BV works seamlessly for our clients.
Ideal candidates will:
Thrive in our small, fast-paced, product-driven environment.
Collaborate with teams from across the organization.
Execute on tight schedules and under pressure.
Present ideas in business-friendly and user-friendly language.
Follow a disciplined workflow driven by well-defined requirements.
Demonstrate ownership of tasks with escalation as needed.
Be a subject matter expert in how a set of technologies work together.
Relentlessly push for successful operational outcomes.
Possess a strong interest or background in cyber security.
About BlueVoyant
BlueVoyant is a global cybersecurity firm that provides Advanced Threat Intelligence, for large companies and a comprehensive Managed Security Service and Professional Services for small businesses, powered by one of the largest commercially available cyber threat databases in the world.
By working with BlueVoyant, companies can gain unique and far-reaching visibility into malicious activity on their networks, in the dark web and across the internet, as well as real-time, automatable remediation services. Through our unique real-time external threat monitoring, predictive human and machine-sourced intelligence, and proactive managed security and incident response, BlueVoyant offers the private sector exceptional cyber defense capabilities.
Co-founded by CEO Jim Rosenthal, former Chief Operating Officer at Morgan Stanley, and Executive Chairman Tom Glocer, former Chief Executive Officer at Thomson Reuters, BlueVoyant has attracted a management team that comes from the world's preeminent intelligence, law enforcement, and private sector organizations. Other leaders include:
Jim Penrose, COO, former EVP at Darktrace with 17 years at the NSA in key leadership roles.
Robert Hannigan, Chairman of BlueVoyant International, former Director of GCHQ.
Gad Goldstein, President BlueVoyant International and Chairman of BlueVoyant Israel, former division head in the Israel Security Agency, Shin Bet.
Austin Berglas, Global Head of Professional Services, former head of the FBI's New York Cyber Branch.
Milan Patel, Chief Client Officer, former CTO of the FBI Cyber Division.
Ron Feler, Global Head of Threat Intelligence and Operations, former Deputy Commander of Unit 8200, the cybersecurity division of the Israel Defense Forces.
Mike Wertheimer, Senior Advisor, former Research Director of NSA
Bill Crumm, Senior Advisor, former NSA SIGINT Director and former Cybersecurity Head, Morgan Stanley.
Jim Bieda, Senior Advisor, former NSA Deputy CTO.

All employees must be authorized to work in the United States or Israel. BlueVoyant provides equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, BlueVoyant complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities.

GlueGWbTmv",http://www.indeed.com/rc/clk?jk=70a4c56699ba3cc6&fccid=95c19d855902beb5&vjs=3
Data Engineer,Hygiena LLC,"Camarillo, CA 93012",,"Since 2001, Hygiena has been on a mission to be the global leader in rapid industrial diagnostic testing. Our world-class team of innovators, leaders, creators and problems solvers has helped Hygiena become the breakaway leader in the markets we serve. In our growing global business, there is always opportunity for talented and passionate individuals to grow with Hygiena.
We are currently recruiting for a Data Engineer to join our team!
In this role you will primarily design, implement, and manage an analytical data infrastructure and work closely with other engineers and scientists to create robust and scalable solutions to flow data from various source systems into the data warehouse and end-user facing applications.
Responsibilities:
Maintain algorithms and build data pipelines including support for new instrument hardware and software.
Test algorithms for ELT annotated and non-annotated reference data.
Benchmark algorithm performances and researches and implements new technologies and/or practices to provide efficient process improvements.
Design data schema and operate internal data warehouse.
Work directly with other engineers and data scientists to flow data from various source systems into the data warehouse.
Monitor and troubleshoot operational or data issues in data pipelines for BAX and Ensure Touch Product lines.
Qualifications:
Bachelor’s Degree in Computer Science, Engineering, Statistics or related field required.
Experience with Statistical modeling, Machine Learning, Data Science or Data Engineering.
4 or more years in Business Intelligence or Business Analytics.
Experience with scripting languages such as;
o MATLAB

o Python

Experience with C++/C# and Windows dll packaging.
Experience with writing SQL queries and ETL.
Experience working on a SCRUM/Kanban team in a CI/CD environment and ETL Skills
Experience with columnar databases and familiarity with statistical modeling and machine learning techniques.

Skills:
Excellent verbal and written communication.
Excellent analytical and quantitative skills.
Ability to handle high call volume.
Excellent attendance and punctuality.
Must be able to use discretion and independent judgement.
Must be able to work in a team environment.
Must be able to pay close attention to details.
Must be able to adapt and flex to a changing environment.

Working Conditions:
Is required to work normal office hours, Monday through Friday in the Camarillo, CA headquarters.
May occasionally work evenings and/or weekends.
May occasionally be required to travel.

Why you’ll want to join our team.

Teamwork as a core value.

At Hygiena, our emphasis on teamwork and cross-functional communication enables us to build stronger bonds within our business.
Be a part of something big.

Hygiena plays a critical role in helping to prevent global health crisis such as foodborne illness, healthcare-associated infections, and other outbreaks.
Giving back to our communities.

Hygiena believes in giving back by supporting local organizations committed to improving the lives of children and youth in our communities.",http://www.indeed.com/rc/clk?jk=16138ca891fbf562&fccid=e7d538bf0fa1dd2c&vjs=3
DATA ENGINEER,Big Bright International,"Irvine, CA",,"Data Engineer at various unanticipated client locations throughout the US to provide design, development, testing and implementation for business computer systems; provide ETL big data integration; utilize Data Stage to populate tables in data warehouse and data marts; design hive schema, create hive tables, and load and analyze data using hive queries.",http://www.indeed.com/rc/clk?jk=3ff49794581b1faa&fccid=bd17e04d65337121&vjs=3
Data Engineer,Home Instead Senior Care,"Omaha, NE",,"Do you have a passion for data? Do you enjoy working in a team-oriented and collaborative environment? Ready to make a difference in the world with the work you do? If so, we have a great opportunity for you as a Data Engineer.

As the Data Engineer, you'll be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross functional teams. The ideal candidate has technical expertise in data modeling and database design, is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up.

The Data Engineer will support our software developers, architects and data analysts on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. You must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company's data architecture to support our next generation of products and data initiatives.

At Home Instead, Inc. (""Home Instead"") we are Changing the Face of Aging®, and we require enthusiastic and collaborative professionals.

As Data Engineer you'll:

Create, design and maintain reusable datasets for analysis by data analyst.
Assess new data sources to better understand availability and quality of data.
Provide governance and best practices of data structures, data integrity, and querying optimization.
Interpret business needs from requests, and rapidly implement effective technical solutions.
Design, implement and enhance ETL (extract, transform and load) processes.
Write SQL queries to answer questions from stakeholders.
Maintain source code repository of scripts (SQL, Python, R) and other data products (dashboards, reports, etc.).
Work with technology teams to understand data capture and testing needs.

Education, Experience and Required Skills:

BA/BS degree in computer science or related technical field preferred and two years of related experience and/or training.
Demonstrable experience with any of the following languages: Ruby, Python, Pearl, JavaScript.
Knowledge of cloud-based data storage, modeling, development, debugging and optimization. Azure experience a plus.
Good understanding of SQL Server internals and underlying hardware.
Extensive knowledge of advanced SQL
Automation to create reports and dashboards for business process management.
Quantitative analysis of reports through various KPIs and translating the data into actionable insights for the clients and the senior management
Implementing data fusion, ETL, information integration, and applying analytics over structured and unstructured client data.
Working on BI projects both at backend and in client facing roles.
Technical familiarity with data models and database design.
Experience with or knowledge of Agile Engineering Practices (Test Driven Development, Continuous Delivery, etc.).
Experience with or knowledge of Scrum or Kanban approaches to work management.
Experience with or knowledge of using Git/GitHub for source code management.

Knowledge, Skills & Abilities:

Understand and uphold the policies and procedures established by Home Instead Senior Care and the related role to the Information Technology Department.
Demonstrate discretion, integrity and fair-mindedness consistent with company standards, practices, policies and procedures.
Demonstrate excellent written and verbal communication skills and the ability to listen intently and effectively.
Ability to establish collaborative working relationships with management, colleagues, franchise owners and their staffs.
Ability to demonstrate effective interpersonal skills essential as well as sound judgment and good decision-making skills.
Ability to work independently and meet deadlines.
Ability to maintain confidentiality of information.
Ability to plan, organize and prioritize daily, monthly and yearly work.
Ability to present a professional appearance and demeanor.
Ability to reach with hands and arms to operate office equipment.
Ability to perform duties in a professional office setting.
Ability to work evenings or weekends as required.

WHO ARE WE AND WHAT DO WE DO?

The Home Instead Senior Care® network provides personalized care, support and education to help enhance the lives of aging adults and their families. Today, this network is the world's leading provider of in-home care services for seniors, with almost 1,100 independently owned and operated franchises that annually provide more than 80 million hours of care throughout the United States and 11 other countries. Local Home Instead Senior Care offices employ approximately 65,000 CAREGiversSM worldwide who provide basic support services that enable seniors to live safely and comfortably in their own homes for as long as possible, serving 90,000 seniors daily. The Home Instead Senior Care network strives to partner with each client and his or her family members to help meet that individual's needs. Services span the care continuum – from providing personal care to specialized Alzheimer's care and hospice support. Also available are family caregiver education and support resources. At Home Instead Senior Care, it's relationship before task, while striving to provide superior quality service. These independently owned and operated franchises achieve service excellence with the support of dedicated Global Headquarters staff of over 200 who provide exceptional service with a personal touch.

OUR EMPLOYEE BENEFITS

To us, it's personal® doesn't just extend to our clients; it extends to our employees, their families, and the benefits they receive. Home Instead, Inc. takes a holistic approach to benefits and our philosophy is to support employees and their families throughout life's journey. We help employees achieve work/life integration, plan for the future, celebrate successes and provide protection in unexpected situations. The Home Instead, Inc. package covers three general areas and includes:

Health & Wellness


Health Insurance – Employees may choose between a high deductible health plan and PPO. Premiums are partially subsidized by Home Instead.
Dental Insurance – Home Instead pays 100% of the premium for employee coverage and subsidizes a portion for dependent coverage.
Vision Insurance – Home Instead pays 100% of the premium for employee coverage and subsidizes a portion for dependent coverage.
The Kitchen Table – Provides an on-site dining experience. Employees enjoy delicious, nutritious meals prepared daily by our personal chef and chef's assistant. Home Instead subsidizes the cost to keep prices affordable. The Kitchen Table gives us the space and time to build relationships through food and fellowship.
Wellness Program – Includes an optional annual health risk assessment, $300 a year for wellness, annual health fair, flu shots, and on-site massages.
Health Savings Account (HSA)
Flexible Spending Accounts (Health; Dependent Daycare/Eldercare)

Financial Wellness


Benefits+ – This program provides funds to help make benefits more affordable for employees and their families. Employees receive $2,000 for 2020 (new employees hired after January 1, 2020 receive a prorated amount based on their benefits eligibility date).
401(k) Plan – Offers a 5% employer match, and free expert financial consulting services.
Tuition Assistance – Home Instead provides employees up to $5,250 each calendar year for continuing education.
Student loans – Employees have the option of using Benefits+ dollars of $2,000 to help pay student loans.
Life Insurance – Employees receive life insurance equal to 1 x salary. In addition, voluntary life insurance is available for employee, spouse and/or children.
Short Term Disability – Premium is 100% employer paid.
Long Term Disability – Premium is 100% employer paid.
Long term care insurance – Available at employee's cost.
Employee Discount Program – Home Instead has relationships with local and national organizations to provide employee discounts on products and services.
Business Travel Coverage – Covers employees while traveling for business and provides coverage for emergency situations including medical evacuation, hospital fees, family travel expenses, emergency travel arrangements, and additional life insurance.
Pet insurance – Our fluffy friends are part of the family; pet insurance is a voluntary benefit and affordable option to help cover out-of-pocket expenses.

Work/Life Integration


Honor PTO – Our Honor PTO program is based on radical trust. We trust employees to be accountable, to get the job done and to work with their teams. There's no accrual of days off and no set number of days. Employees work with their manager to balance work and personal needs.
Professional Development – This program provides learning opportunities related to individual roles, professional development, and personal development.
Employee Assistance Program – Provides free short-term confidential counseling.
Quarterly Socials – We have fun at Home Instead! Our quarterly socials give us the opportunity to connect and enjoy time with each other.

Applicants have rights under Federal Employment Laws:
Family Medical Leave Act (FMLA)
Equal Employment Opportunity (EEO)
Employee Polygraph Protection Act (EPPA)",http://www.indeed.com/rc/clk?jk=501e2f2a5a80c386&fccid=04939308dcb5bc54&vjs=3
Intern Data Engineer/Analyst II,Anthem,"Atlanta, GA 30319",,"Description
SHIFT: Day Job

SCHEDULE: Full-time

Your Talent. Our Vision. At Anthem Blue Cross and Blue Shield, a proud member of the Anthem, Inc. family of companies, it’s a powerful combination, and the foundation upon which we’re creating greater access to care for our members, greater value for our customers, and greater health for our communities. Join us and together we will drive the future of health care. This is an exceptional opportunity to do innovative work that means more to you and those we serve.

The Information Technology Intern II will design and develop technology solutions for enterprise programs. They will interact with business and technical resources to support the delivery of technical enterprise deliverables.



The intern will work as a data engineer/ analyst, assisting with Data profiling and data analysis tasks; leading the tasks to implement AI capabilities in Testing on Bigdata/Cloud platforms; automate processes using DevOps tools. Interns will be working on these two key initiatives under Provider End to End blue chip


AnEqualOpportunityEmployer/Disability/Veteran",http://www.indeed.com/rc/clk?jk=b27ee5719fe282e3&fccid=2a4da7fa99f4b9ae&vjs=3
Python Data Engineer,"OneSource IT, Inc.","Reston, VA",,"Python Data Engineer

We are looking for a Python Data Engineer to join one of our Federal Health IT engagements. Successful candidates are passionate, self-driven problem-solvers who love taking on new challenges using the latest data and cloud technologies. They also love data and keep up with the latest technology trends. They tinker, explore and regularly read to stay in touch with new data trends and are passionate about discovering ways to improve quality, reusability, extensibility, and consistency. Successful candidates should also be multi-faceted with a great mix of technical and interpersonal skills, to succeed in highly collaborative and agile work environments. As a Modern Data Engineer, this person will design and deliver innovative solutions for Postgres and Redshift on Amazon Web Services, using core cloud tools.

Responsibilities:
Display passion for delivering high quality products that meet customers' needs
Solving data-oriented problems in an analytical and iterative fashion
Perform analysis, architecture, design, and development of cloud data solutions
Working with various kinds of data (structured, unstructured, metrics, logs, json, xml, etc.)
Working in various Agile methodologies (Scrum, Kanban, SAFe)

Required Skills:

3+ years of Python Development, with emphasis in ETL Development
5+ years of SQL experience, with emphasis in Data Analysis
Proficiency in relational database design and development
Experienced building and scaling batch/asynchronous systems
Hands-on development using and migrating data to cloud platforms, AWS
Analytical approach to problem-solving; ability to use technology to solve business problems

Desired Skills:

Data pipeline orchestration tools such as Airflow, Amazon Glue
Familiarity with PostGres, Redshift
Cloud platform certification(s) (example: AWS Certified Solutions Architect)",http://www.indeed.com/rc/clk?jk=4e6516e712a05e6c&fccid=b3cdb239148d18e6&vjs=3
Associate Data Engineer,Infotree Service Inc,"Thousand Oaks, CA",,"Company Description

Bio- Pharma

Job Description

We're seeking a technology associate with the passion to drive innovation and turning data into insights. The Associate Data Engineer will be an integral member of a newly formed initiative that will implement and own ground-breaking solutions for managing business execution data. Got a mind for creating a simplified system of interconnected data sources to drive powerful strategical and financial insights? Come join our team and be a part of something new that we can be proud of!

Qualifications

Top 3 Must Have Skill Sets:Proven attention to detail and proactive communicationStrong quantitative skillsSelf-starter with a high-level of comfort with ambiguity and complexityProficiency in the following is a major plus: Python, Django, JavaScript
Additional Information

Day to Day Responsibilities
With guidance, applies knowledge of basic principles, methods and practices to simple and moderately complex assignments as follows:

1. Collect, integrate and manage business execution datasets
2. Contribute to the design and development for ETL solutions to support key partners
3. Collaborate with Application Architects and Business SMEs to design and develop end-to-end data pipelines and supporting infrastructure
4. Build and operationally support new infrastructure and analytics tools in a DevOps model using Python, JavaScript, SQL and AWS
5. Proactively identify & implement opportunities to automate tasks and develop reusable frameworks
6. Participate in efforts to design, build, and develop rapid Proof-of-Concept (POC) solutions and services
7. Utilize analytical tools such as Spotfire, Tableau and others to develop reports and dashboards for an executive audienceWith guidance, applies knowledge of basic principles, methods and practices to simple and moderately complex assignments as follows:",http://www.indeed.com/rc/clk?jk=872739d2dd41878a&fccid=d54d9d4733be6c74&vjs=3
Data Engineer,Central Intelligence Agency,"Washington, DC",,"As a Data Engineer for the CIA, you will focus on the design, implementation, and operation of data management and information systems to meet the CIA's business needs. Your primary goal is to increase discoverability and retrievability, facilitate dissemination, and ensure the delivery of timely and relevant intelligence. This includes designing how the data will be stored, consumed, integrated, and managed by different data entities and digital systems. Data Engineers work together with data consumers and Information and Data Management Officers to determine, create, and populate optimal data architectures, structures, and systems. Data Engineering requires an extensive knowledge of data manipulation, databases, data structures, data management, and best engineering practices.

Data Engineers must also plan, design, and optimize for data throughput and query performance issues. This requires constantly updating expertise in areas such as platform, network and storage technologies, bandwidth management, data bus implications and design.

Additionally, you will play a key role in the selection of backend database technologies (SQL, NoSQL, HPC, etc), their configuration and utilization, and the optimization of the full data pipeline infrastructure to support the actual content, volume, ETL, and periodicity of data to support the intended kinds of queries and analysis to match expected responsiveness.

Domestic and/or foreign travel may be required.

Offices of the CIA – Directorate of Digital Innovation

The Directorate of Digital Innovation (DDI) is at the forefront of defining the future of digital expertise within the CIA. DDI focuses on developing the workforce with cutting-edge skills, investing in IT infrastructure, and modernizing the way the Agency does business. DDI officers help accelerate the integration of innovative methods and tools to enhance the CIA's cyber and digital capabilities on a global scale and ultimately help safeguard our nation. Learn more about the Directorate of Digital Innovation.

See our work in action:

Life at CIA

In addition to a comprehensive benefits package, the CIA offers exciting career opportunities and a dynamic environment. We're on the forefront of world-altering events – as they happen. So working here isn't just a job, it's a mindset and a lifestyle.

US citizenship required (dual-national US citizens eligible). All positions require relocation to the Washington, DC metro area.

Minimum Qualifications:
Bachelor's degree in one of the following fields or related studies:
Archives/Digitization Management
Computer/Data Science
Information/Data/Knowledge Management
Information Technology
Management Information Systems
Mathematics
Engineering
GPA of at least 3.0 on a 4-point scale is preferred but not required
Experience with data manipulation, databases, data structures, data management
Experience in project management
Interpersonal, representational, and negotiation skills
Written and oral communication skills
Ability to effectively collaborate with diverse stakeholders to meet mission needs
Ability to analyze complex information and make/defend independent judgements
Organizational skills and attention to detail
Strong Customer Service Skills
Solid understanding of platform, network and storage technologies, and design
Desired Qualifications:
Master's degree in one of the following fields or related studies:
Archives/Digitization Management
Computer/Data Science
Information/Data/Knowledge Management
Information Technology
Management Information Systems
Mathematics
Engineering
Work experience related to data engineering, information, and data management
All applicants must successfully complete:
A thorough medical and psychological exam
A polygraph interview
A comprehensive background investigation

To be considered suitable for Agency employment, applicants must generally not have used illegal drugs within the last 12 months. The issue of illegal drug use prior to 12 months ago is carefully evaluated during the medical and security processing.",http://www.indeed.com/rc/clk?jk=3d40c0f1c5115590&fccid=e9870e3159e9c6ac&vjs=3
,,,,,http://www.indeed.com/rc/clk?jk=c02a9ee3ed7a769a&fccid=2a4da7fa99f4b9ae&vjs=3
Healthcare Data Engineer,B.well Connected Health,"Austin, TX",,"What You'll Do
Work closely with the various areas of the business to design and implement requirements and develop processes necessary to provide visibility into the data via the data warehouse
Ensure data that is brought into the data warehouse is clean, accurate, available and complete
Architect, develop, implement and test algorithms that consist of value-add routes and build data warehouse infrastructure for automated interpretation of healthcare data
Identify ways to improve data reliability, efficiency and quality. Produce actionable recommendations that address known problems and then implement automated solutions
Assist the development teams with business knowledge of various healthcare data that is ingested from various sources
You will safeguard sensitive data by following policies and training concerning your security and privacy responsibilities
You will safeguard sensitive data by following policies and training concerning your security and privacy responsibilities
Job Requirements:
5+ years of professional SQL programming experience
In depth experience with SQL and NOSQL databases
5+ years working with health plan data
Strong knowledge of healthcare data, specifically health plan (i.e. medical and Rx claims, eligibility, provider data)
Deep understanding with healthcare coding terminologies (CPT, diagnosis, DRG, etc)
Experience in designing and building efficient and scalable solutions for big data
Experience with query development and optimization
Experience with common data warehouse and data lake architecture concepts and best practices
Proven work experience with algorithm design and implementation
Strong problem solving skills
Ability to independently manage all phases of development including requirement documentation, building, configuration, bug tracking, testing, and validation
Strong experience with cloud-based infrastructure
Strong communication skills between business and technical resources

Great to have:
Experience providing database endpoints and/or the creation of RESTful API’s
Previous experience in the Python/Django framework
Previous knowledge of data integration processes and tools (specifically AWS based)
Experience with healthcare data formats (processing 834, 837, X12 file formats)
Experience with health system EHR data
Experience leveraging Redshift and other AWS data pipelines / tools
Advanced degree in Computer Science
An active GitHub profile or other public code portfolio

How to Apply

To apply, email careers@icanbwell.com with your resume, your GitHub account, and why you’d love to help us change the face of healthcare. Please use the subject line: “Apply - Healthcare Data Engineer”",http://www.indeed.com/rc/clk?jk=df81b7479f345f63&fccid=b7066b0b5972b293&vjs=3
Big Data Engineer,The Goal Inc.,United States,,"Big Data Engineer
The Goal is looking to hire a Big Data Engineer to join our team in Rockville, MD.
Job Functions:
Analyze system requirements and design responsive algorithms and solutions
Use big data and cloud technologies to produce production quality code
Engage in performance tuning and scalability engineering
Work with team, peers and management to identify objectives and set priorities
Perform related SDLC engineering activities like sprint planning and estimation
Work effectively in small agile teams
Provide creative solutions to problems
Identify opportunities for improvement and execute

Essential skills:
Experience developing with cloud based Big Data technologies
Proficiency in Hive and Spark SQL
Experience with one or more programming languages like Python, Scala or Java
Ability to push the frontier of technology and independently pursue better alternatives",http://www.indeed.com/rc/clk?jk=0bf02d3eed52c6ed&fccid=355368ca87585f29&vjs=3
Data Engineer,Kite,"San Francisco, CA",,"Programmers spend too much time doing repetitive work — copying and pasting from StackOverflow, fixing simple errors, and writing boilerplate code. We're building an AI code engine that does this work for you. Programming using Kite is faster and more fun.

Kite is well-funded by top investors in Silicon Valley, including the founders of PayPal, Stripe, Palantir, and Dropbox to name a few. We are looking to expand our 16-person startup with talented individuals who are interested in joining an early stage startup. The ideal candidate is excited to help guide the direction of our product and company. They will have a significant amount of ownership of critical technical components. Our team is growing rapidly and we hope you'll grow with us too!

As a Data Engineer you will work on the data pipeline infrastructure and ETL logic at the core of our product. You will be a key part of our machine learning team by providing easy, fast, flexible and reliable access to training data.
What You'll Do
Maintain and iteratively improve the data pipeline infrastructure
Write data transformation logic to scrub and join large datasets, and handle changes in source data
Turn technical requirements into a plan to execute, test, and deliver on time
Become an engineering leader as the team grows, if desired
Write clean, maintainable code
Design and code reviews
What You've Done
Experience building data pipelines, stream processing, and/or big-data messaging systems
Built ETL processes for large, disconnected, and/or un-structured datasets
Track record of working in small teams to build new software from scratch
Ability to learn and evaluate new technologies quickly
Strong ownership instinct and ability to deliver results
Public cloud (AWS, Azure, etc.) automation
Who You Are
Bachelor’s Degree in Computer Science or related field
Minimum of 3+ years of engineering experience
Experience building reliable and scalable systems
Excited to work on a small, growing team in a startup environment
Ability to work daily from our San Francisco office (wonderful office in the bustling Financial District area)",http://www.indeed.com/rc/clk?jk=e405e8f5af893b18&fccid=67232e209deb234c&vjs=3
,,,,,http://www.indeed.com/rc/clk?jk=87a4841750a8c9b5&fccid=d09878b895240545&vjs=3
,,,,,http://www.indeed.com/rc/clk?jk=725a5211fa50d5d0&fccid=c6a1779d65543307&vjs=3
,,,,,http://www.indeed.com/rc/clk?jk=62ac170924282c16&fccid=ea5b883d84734bf8&vjs=3
,,,,,http://www.indeed.com/rc/clk?jk=a486e045a36c384a&fccid=868c560ebf12984c&vjs=3
,,,,,http://www.indeed.com/rc/clk?jk=967933aa6a1f7b35&fccid=f8bbcff726a39180&vjs=3
,,,,,http://www.indeed.com/rc/clk?jk=9d464d073aa87d4a&fccid=ea4bba4ceb36a6c2&vjs=3
,,,,,http://www.indeed.com/rc/clk?jk=f5f8b77f64d469d0&fccid=73600876f0c59a87&vjs=3
,,,,,http://www.indeed.com/rc/clk?jk=81dd143790ae316f&fccid=d5cf2062d2701c6e&vjs=3
,,,,,http://www.indeed.com/rc/clk?jk=e812256c355dce5e&fccid=756aaa91162c8adc&vjs=3
,,,,,http://www.indeed.com/rc/clk?jk=e812256c355dce5e&fccid=756aaa91162c8adc&vjs=3
,,,,,http://www.indeed.com/rc/clk?jk=c92c766ce01c5042&fccid=eedf72ea6f271445&vjs=3
,,,,,http://www.indeed.com/rc/clk?jk=77a49e7b0d4848e3&fccid=51f04b221d649230&vjs=3
,,,,,http://www.indeed.com/rc/clk?jk=7cb662ebd02f2e09&fccid=7b7b0d87eba63ba9&vjs=3
,,,,,http://www.indeed.com/rc/clk?jk=2c39761b933ae8a8&fccid=fc68da685e8aa986&vjs=3
,,,,,http://www.indeed.com/rc/clk?jk=9ecdef6229c17775&fccid=958531310cfc5a5d&vjs=3
,,,,,http://www.indeed.com/rc/clk?jk=6ba3913bf69c3ade&fccid=1c3ef50ebd3f05bc&vjs=3
,,,,,http://www.indeed.com/rc/clk?jk=9952d9a0c1de31fb&fccid=dd616958bd9ddc12&vjs=3
,,,,,http://www.indeed.com/rc/clk?jk=e0347dbb08853dca&fccid=fb2c79d6522d7a32&vjs=3
,,,,,http://www.indeed.com/rc/clk?jk=001deb0644a1d1eb&fccid=de71a49b535e21cb&vjs=3
,,,,,http://www.indeed.com/rc/clk?jk=6eccafc594f75fa1&fccid=1639254ea84748b5&vjs=3
,,,,,http://www.indeed.com/rc/clk?jk=56cc3ce5419331fd&fccid=1639254ea84748b5&vjs=3
,,,,,http://www.indeed.com/rc/clk?jk=986438f92f5883a1&fccid=51f04b221d649230&vjs=3
,,,,,http://www.indeed.com/rc/clk?jk=c92c766ce01c5042&fccid=eedf72ea6f271445&vjs=3
,,,,,http://www.indeed.com/rc/clk?jk=7892a93b07d1d6c9&fccid=bc0dfa955f4e6d72&vjs=3
,,,,,http://www.indeed.com/rc/clk?jk=749de51bf2371f76&fccid=88f5d9a70576ec2a&vjs=3
